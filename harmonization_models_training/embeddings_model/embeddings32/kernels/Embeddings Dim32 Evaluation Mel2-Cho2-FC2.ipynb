{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/.local/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, GRU, concatenate\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# Custom library for the project\n",
    "import sys\n",
    "sys.path.insert(0, '../../src')\n",
    "import harmoutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'harmoutil' from '../../src/harmoutil.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Remove when done with kernel\n",
    "import importlib\n",
    "importlib.reload(harmoutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = harmoutil.load_pickled_data(\"../../data/refined_data.pkl\") # lists of (chord label, melody seqs) by sections\n",
    "augmented_data = harmoutil.transpose_and_augment_data(raw_data)\n",
    "data = [harmoutil.to_sevenths(section) for section in augmented_data]\n",
    "data = [harmoutil.melody_to_octave_range(section) for section in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chords: 334344 | Sample chord: E6\n",
      "Number of melody notes in the data: 2209944 | Sample melody note: 4\n",
      "Unique notes: [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Unique notes: ['A', 'A+', 'A+7', 'A+j7', 'A-', 'A-6', 'A-7', 'A-j7', 'A6', 'A7', 'Ab', 'Ab+', 'Ab+7', 'Ab+j7', 'Ab-', 'Ab-6', 'Ab-7', 'Ab-j7', 'Ab6', 'Ab7', 'Abj7', 'Abm7b5', 'Abo', 'Abo7', 'Absus', 'Absus7', 'Aj7', 'Am7b5', 'Ao', 'Ao7', 'Asus', 'Asus7', 'B', 'B+', 'B+7', 'B+j7', 'B-', 'B-6', 'B-7', 'B-j7', 'B6', 'B7', 'Bb', 'Bb+', 'Bb+7', 'Bb+j7', 'Bb-', 'Bb-6', 'Bb-7', 'Bb-j7', 'Bb6', 'Bb7', 'Bbj7', 'Bbm7b5', 'Bbo', 'Bbo7', 'Bbsus', 'Bbsus7', 'Bj7', 'Bm7b5', 'Bo', 'Bo7', 'Bsus', 'Bsus7', 'C', 'C+', 'C+7', 'C+j7', 'C-', 'C-6', 'C-7', 'C-j7', 'C6', 'C7', 'Cj7', 'Cm7b5', 'Co', 'Co7', 'Csus', 'Csus7', 'D', 'D+', 'D+7', 'D+j7', 'D-', 'D-6', 'D-7', 'D-j7', 'D6', 'D7', 'Db', 'Db+', 'Db+7', 'Db+j7', 'Db-', 'Db-6', 'Db-7', 'Db-j7', 'Db6', 'Db7', 'Dbj7', 'Dbm7b5', 'Dbo', 'Dbo7', 'Dbsus', 'Dbsus7', 'Dj7', 'Dm7b5', 'Do', 'Do7', 'Dsus', 'Dsus7', 'E', 'E+', 'E+7', 'E+j7', 'E-', 'E-6', 'E-7', 'E-j7', 'E6', 'E7', 'Eb', 'Eb+', 'Eb+7', 'Eb+j7', 'Eb-', 'Eb-6', 'Eb-7', 'Eb-j7', 'Eb6', 'Eb7', 'Ebj7', 'Ebm7b5', 'Ebo', 'Ebo7', 'Ebsus', 'Ebsus7', 'Ej7', 'Em7b5', 'Eo', 'Eo7', 'Esus', 'Esus7', 'F', 'F+', 'F+7', 'F+j7', 'F-', 'F-6', 'F-7', 'F-j7', 'F6', 'F7', 'Fj7', 'Fm7b5', 'Fo', 'Fo7', 'Fsus', 'Fsus7', 'G', 'G+', 'G+7', 'G+j7', 'G-', 'G-6', 'G-7', 'G-j7', 'G6', 'G7', 'Gb', 'Gb+', 'Gb+7', 'Gb+j7', 'Gb-', 'Gb-6', 'Gb-7', 'Gb-j7', 'Gb6', 'Gb7', 'Gbj7', 'Gbm7b5', 'Gbo', 'Gbo7', 'Gbsus', 'Gbsus7', 'Gj7', 'Gm7b5', 'Go', 'Go7', 'Gsus', 'Gsus7', 'NC']\n"
     ]
    }
   ],
   "source": [
    "# Isolate relevant data\n",
    "def get_notes_by_chord(beats):\n",
    "    return [note for beat in beats for note in beat]\n",
    "\n",
    "def get_chords_by_section(section):\n",
    "    return [chord_info[0] for chord_info in section]\n",
    "\n",
    "# def check_if_augmented_major(section):\n",
    "#     section_chords = get_chords_by_section(section)\n",
    "#     for ch in section_chords:\n",
    "#         if \"+j7\" in ch:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "# data = [section for section in data if not check_if_augmented_major(section)]\n",
    "# print(\"---Remove sections with augmented major chord---\")\n",
    "# print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections_bf_augmaj7 = [get_chords_by_section(section) for section in data]\n",
    "chords = [chord_info[0] for section in data for chord_info in section]\n",
    "unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords_bf_augmaj7 = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "notes = [note for chord_notes in notes_by_chords_bf_augmaj7 for note in chord_notes]\n",
    "unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "# print(sum([len(section) for section in chords_by_sections]))\n",
    "# print(\"Number of sections: {} | Sample section chords: {}\".format(len(chords_by_sections), chords_by_sections[0]))\n",
    "print(\"Number of chords: {} | Sample chord: {}\".format(len(chords), chords[0]))\n",
    "# print(\"Number of melodies {} | Sample melody: {}\".format(len(notes_by_chords), notes_by_chords[0]))\n",
    "print(\"Number of melody notes in the data: {} | Sample melody note: {}\".format(len(notes), notes[0]))\n",
    "print(\"Unique notes: {}\".format(unique_notes))\n",
    "print(\"Unique notes: {}\".format(unique_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melody note to integer mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, '<pad>': 13, -1: 12}\n",
      "\n",
      "Integer to melody note mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: -1, 13: '<pad>'}\n",
      "\n",
      "Chord label to integer mapping:\n",
      " {'Dbm7b5': 101, 'A-7': 6, 'G-7': 166, 'Db+': 91, 'Bm7b5': 59, 'G7': 169, 'Abj7': 20, '<eos>': 194, 'Do': 108, 'Bb+': 43, 'Gbo7': 183, 'Bb7': 51, 'Db+7': 92, 'D+j7': 83, 'B6': 40, 'D-': 84, 'Bb-': 46, 'Bb-j7': 49, 'Dm7b5': 107, 'C-7': 70, 'G6': 168, 'Gbo': 182, 'A7': 9, 'F-6': 149, 'Db': 90, 'C-6': 69, 'Go7': 189, 'D+': 81, 'NC': 192, 'G+j7': 163, 'Absus7': 25, 'Dj7': 106, 'Dsus': 110, 'C-j7': 71, 'B-j7': 39, 'Eb-': 126, 'A+7': 2, 'Db+j7': 93, 'Esus': 142, 'Gbm7b5': 181, 'Co': 76, 'A-j7': 7, 'Eb+': 123, 'Ebsus7': 137, 'F-j7': 151, 'B+': 33, 'Gb-': 174, 'Co7': 77, 'Fsus': 158, 'G': 160, 'A-6': 5, 'C+j7': 67, 'Eb+7': 124, 'Abm7b5': 21, 'Ab-7': 16, 'Gb-6': 175, 'Gsus': 190, 'Bsus': 62, 'Ab-6': 15, 'C+7': 66, 'B-': 36, 'G+7': 162, 'Bbo7': 55, 'Asus7': 31, 'Ab': 10, 'Eb7': 131, 'Gj7': 186, 'Ao': 28, 'E-7': 118, 'G-6': 165, 'Gbj7': 180, 'Gb-7': 176, 'C-': 68, 'E+7': 114, 'Bbm7b5': 53, 'F+7': 146, 'Bj7': 58, 'Bbsus7': 57, 'E+': 113, 'Bb': 42, 'Go': 188, 'E-6': 117, 'E+j7': 115, 'Fo': 156, 'Ej7': 138, 'Bo7': 61, 'Dbsus': 104, 'Db-': 94, 'Ebo7': 135, 'Fm7b5': 155, 'Db-j7': 97, 'Eb-7': 128, 'B+7': 34, 'D+7': 82, 'Ab7': 19, 'Db-7': 96, 'A6': 8, 'Gb6': 178, 'C': 64, 'Eb-j7': 129, 'E7': 121, 'Cm7b5': 75, 'A+j7': 3, 'Bb+7': 44, 'Abo7': 23, 'D-j7': 87, 'C+': 65, 'Ebm7b5': 133, 'Aj7': 26, 'D7': 89, 'Em7b5': 139, 'Db-6': 95, 'F+j7': 147, 'Bbo': 54, '<bos>': 193, 'Eb6': 130, 'Dbo': 102, 'D-6': 85, 'E-': 116, 'Asus': 30, 'F-': 148, 'Bbj7': 52, 'Ab-': 14, 'Bb+j7': 45, 'Ab+7': 12, 'Ao7': 29, 'Cj7': 74, 'Gsus7': 191, 'A': 0, 'E-j7': 119, 'Ebsus': 136, 'Bb-6': 47, 'D6': 88, 'A+': 1, 'Gm7b5': 187, 'C6': 72, 'B': 32, 'Abo': 22, 'Bb6': 50, 'B+j7': 35, 'B-6': 37, 'Ab+': 11, 'Bo': 60, 'Eb-6': 127, 'Absus': 24, 'F+': 145, 'Csus7': 79, 'E': 112, 'Ebj7': 132, 'Eo7': 141, 'Gb+7': 172, 'Gbsus7': 185, 'G-': 164, 'Fo7': 157, 'Gb': 170, 'Gbsus': 184, 'Ab+j7': 13, 'Bb-7': 48, 'Eb': 122, 'F-7': 150, 'A-': 4, 'C7': 73, 'Db6': 98, 'E6': 120, 'Fj7': 154, 'Db7': 99, 'Ebo': 134, 'G-j7': 167, 'Dbsus7': 105, 'Am7b5': 27, 'Dbo7': 103, 'D': 80, 'D-7': 86, 'Bbsus': 56, 'Eb+j7': 125, 'Csus': 78, 'B7': 41, 'F': 144, 'Ab6': 18, 'B-7': 38, 'F6': 152, 'Gb-j7': 177, 'Fsus7': 159, 'Eo': 140, 'G+': 161, 'Dbj7': 100, 'Gb+': 171, 'Ab-j7': 17, 'Esus7': 143, 'Do7': 109, 'F7': 153, 'Dsus7': 111, 'Gb+j7': 173, 'Bsus7': 63, 'Gb7': 179}\n",
      "\n",
      "Integer to chord label mapping:\n",
      " {0: 'A', 1: 'A+', 2: 'A+7', 3: 'A+j7', 4: 'A-', 5: 'A-6', 6: 'A-7', 7: 'A-j7', 8: 'A6', 9: 'A7', 10: 'Ab', 11: 'Ab+', 12: 'Ab+7', 13: 'Ab+j7', 14: 'Ab-', 15: 'Ab-6', 16: 'Ab-7', 17: 'Ab-j7', 18: 'Ab6', 19: 'Ab7', 20: 'Abj7', 21: 'Abm7b5', 22: 'Abo', 23: 'Abo7', 24: 'Absus', 25: 'Absus7', 26: 'Aj7', 27: 'Am7b5', 28: 'Ao', 29: 'Ao7', 30: 'Asus', 31: 'Asus7', 32: 'B', 33: 'B+', 34: 'B+7', 35: 'B+j7', 36: 'B-', 37: 'B-6', 38: 'B-7', 39: 'B-j7', 40: 'B6', 41: 'B7', 42: 'Bb', 43: 'Bb+', 44: 'Bb+7', 45: 'Bb+j7', 46: 'Bb-', 47: 'Bb-6', 48: 'Bb-7', 49: 'Bb-j7', 50: 'Bb6', 51: 'Bb7', 52: 'Bbj7', 53: 'Bbm7b5', 54: 'Bbo', 55: 'Bbo7', 56: 'Bbsus', 57: 'Bbsus7', 58: 'Bj7', 59: 'Bm7b5', 60: 'Bo', 61: 'Bo7', 62: 'Bsus', 63: 'Bsus7', 64: 'C', 65: 'C+', 66: 'C+7', 67: 'C+j7', 68: 'C-', 69: 'C-6', 70: 'C-7', 71: 'C-j7', 72: 'C6', 73: 'C7', 74: 'Cj7', 75: 'Cm7b5', 76: 'Co', 77: 'Co7', 78: 'Csus', 79: 'Csus7', 80: 'D', 81: 'D+', 82: 'D+7', 83: 'D+j7', 84: 'D-', 85: 'D-6', 86: 'D-7', 87: 'D-j7', 88: 'D6', 89: 'D7', 90: 'Db', 91: 'Db+', 92: 'Db+7', 93: 'Db+j7', 94: 'Db-', 95: 'Db-6', 96: 'Db-7', 97: 'Db-j7', 98: 'Db6', 99: 'Db7', 100: 'Dbj7', 101: 'Dbm7b5', 102: 'Dbo', 103: 'Dbo7', 104: 'Dbsus', 105: 'Dbsus7', 106: 'Dj7', 107: 'Dm7b5', 108: 'Do', 109: 'Do7', 110: 'Dsus', 111: 'Dsus7', 112: 'E', 113: 'E+', 114: 'E+7', 115: 'E+j7', 116: 'E-', 117: 'E-6', 118: 'E-7', 119: 'E-j7', 120: 'E6', 121: 'E7', 122: 'Eb', 123: 'Eb+', 124: 'Eb+7', 125: 'Eb+j7', 126: 'Eb-', 127: 'Eb-6', 128: 'Eb-7', 129: 'Eb-j7', 130: 'Eb6', 131: 'Eb7', 132: 'Ebj7', 133: 'Ebm7b5', 134: 'Ebo', 135: 'Ebo7', 136: 'Ebsus', 137: 'Ebsus7', 138: 'Ej7', 139: 'Em7b5', 140: 'Eo', 141: 'Eo7', 142: 'Esus', 143: 'Esus7', 144: 'F', 145: 'F+', 146: 'F+7', 147: 'F+j7', 148: 'F-', 149: 'F-6', 150: 'F-7', 151: 'F-j7', 152: 'F6', 153: 'F7', 154: 'Fj7', 155: 'Fm7b5', 156: 'Fo', 157: 'Fo7', 158: 'Fsus', 159: 'Fsus7', 160: 'G', 161: 'G+', 162: 'G+7', 163: 'G+j7', 164: 'G-', 165: 'G-6', 166: 'G-7', 167: 'G-j7', 168: 'G6', 169: 'G7', 170: 'Gb', 171: 'Gb+', 172: 'Gb+7', 173: 'Gb+j7', 174: 'Gb-', 175: 'Gb-6', 176: 'Gb-7', 177: 'Gb-j7', 178: 'Gb6', 179: 'Gb7', 180: 'Gbj7', 181: 'Gbm7b5', 182: 'Gbo', 183: 'Gbo7', 184: 'Gbsus', 185: 'Gbsus7', 186: 'Gj7', 187: 'Gm7b5', 188: 'Go', 189: 'Go7', 190: 'Gsus', 191: 'Gsus7', 192: 'NC', 193: '<bos>', 194: '<eos>'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create categorical data mappings\n",
    "note_to_int = dict([(c, i) for i, c in enumerate(unique_notes[1:])])\n",
    "note_to_int[-1] = len(note_to_int)\n",
    "note_to_int['<pad>'] = len(note_to_int)\n",
    "\n",
    "int_to_note = dict([(k, v) for v, k in note_to_int.items()])\n",
    "\n",
    "chord_to_int = dict([(c, i) for i, c in enumerate(unique_chords)])\n",
    "chord_to_int['<bos>'] = len(chord_to_int)\n",
    "chord_to_int['<eos>'] = len(chord_to_int)\n",
    "\n",
    "int_to_chord = dict([(k, v) for v, k in chord_to_int.items()])\n",
    "\n",
    "print(\"Melody note to integer mapping:\\n {}\\n\".format(note_to_int))\n",
    "print(\"Integer to melody note mapping:\\n {}\\n\".format(int_to_note))\n",
    "print(\"Chord label to integer mapping:\\n {}\\n\".format(chord_to_int))\n",
    "print(\"Integer to chord label mapping:\\n {}\\n\".format(int_to_chord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 334344\n",
      "Number of distinct melody notes: 14\n",
      "Number of distinct chord labels: 195\n",
      "Maximum length of melody sequences for one chord: 135\n",
      "Number of past chords given as input: 7\n"
     ]
    }
   ],
   "source": [
    "# Define numerical variables\n",
    "\n",
    "n_samples = len(chords)\n",
    "n_chords = len(chord_to_int)\n",
    "n_notes = len(note_to_int)\n",
    "max_mel_len = max([len(mel) for mel in notes_by_chords_bf_augmaj7])\n",
    "chord_context_len = 7\n",
    "\n",
    "# print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Number of distinct melody notes: {}\".format(n_notes))\n",
    "print(\"Number of distinct chord labels: {}\".format(n_chords))\n",
    "print(\"Maximum length of melody sequences for one chord: {}\".format(max_mel_len))\n",
    "print(\"Number of past chords given as input: {}\".format(chord_context_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [4]]\n"
     ]
    }
   ],
   "source": [
    "mel_by_sections = [mel for section in data for ch, mel in section]\n",
    "print(mel_by_sections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Remove sections with augmented major chord---\n",
      "Number of sections: 28836\n",
      "\n",
      "Sample input melody sequence: [8, 3, 6, '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "\n",
      "Sample input chord sequence: ['<bos>', '<bos>', 'E6', 'Db7', 'Gb-7', 'B7', 'E']\n",
      "\n",
      "Sample target chord: Db-7\n",
      "\n",
      "Input melody: 333480, Input chords: 333480, Target chords: 333480\n"
     ]
    }
   ],
   "source": [
    "# Prepare tensor data\n",
    "\n",
    "\n",
    "def check_if_augmented_major(section):\n",
    "    section_chords = get_chords_by_section(section)\n",
    "    for ch in section_chords:\n",
    "        if \"+j7\" in ch:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "data = [section for section in data if not check_if_augmented_major(section)]\n",
    "print(\"---Remove sections with augmented major chord---\")\n",
    "print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections = [get_chords_by_section(section) for section in data]\n",
    "# chords = [chord_info[0] for section in data for chord_info in section]\n",
    "# unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "# notes = [note for chord_notes in notes_by_chords for note in chord_notes]\n",
    "# unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "\n",
    "\n",
    "def pad_melody(melody, max_len):\n",
    "    return melody + (max_len-len(melody))*['<pad>']\n",
    "\n",
    "def build_input_chord_sequences(chord_seq, context_len):\n",
    "    padded_sequence = context_len*['<bos>'] + chord_seq\n",
    "    formatted_sequences = [padded_sequence[i:i+context_len+1] for i in range(len(chord_seq))]\n",
    "    return formatted_sequences\n",
    "\n",
    "# Melody\n",
    "input_melody_data = [pad_melody(melody, max_mel_len) for melody in notes_by_chords]\n",
    "print(\"Sample input melody sequence: {}\\n\".format(input_melody_data[5]))\n",
    "\n",
    "# Chords\n",
    "formatted_chords_data = []\n",
    "for section_chords in chords_by_sections:\n",
    "    formatted_chords_data += build_input_chord_sequences(section_chords, chord_context_len)\n",
    "    \n",
    "input_chords_data = [ch[:-1] for ch in formatted_chords_data]\n",
    "target_chords_data = [ch[-1] for ch in formatted_chords_data]\n",
    "print(\"Sample input chord sequence: {}\\n\".format(input_chords_data[5]))\n",
    "print(\"Sample target chord: {}\\n\".format(target_chords_data[5]))\n",
    "\n",
    "print(\"Input melody: {}, Input chords: {}, Target chords: {}\".format(len(input_melody_data), len(input_chords_data), len(target_chords_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load embedding vectors\n",
    "\n",
    "num_dim = 32\n",
    "num_ch = 192\n",
    "num_notes = 12\n",
    "\n",
    "# Define embedding training model and load weights\n",
    "input_layer = Input(shape=(num_ch,)) \n",
    "embeddings_layer = Dense(num_dim, activation='linear', name=\"embeddings\")(input_layer)\n",
    "root_output_layer = Dense(num_notes, activation='softmax')(embeddings_layer)\n",
    "interval_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "pitch_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "melody_output_layer = Dense(num_notes, activation='relu')(embeddings_layer)\n",
    "embeddings_model = Model(input_layer, [root_output_layer, interval_output_layer, pitch_output_layer, melody_output_layer])\n",
    "\n",
    "embeddings_model.load_weights(\"../Skipgram & WJD/weights/combined_weights_dim32.h5\")\n",
    "\n",
    "X_chords_embeddings = embeddings_model.layers[1].get_weights()[0]\n",
    "print(X_chords_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embedding vector for each chord: 32\n"
     ]
    }
   ],
   "source": [
    "# Build tensors\n",
    "\n",
    "n_dimensions = X_chords_embeddings.shape[1]\n",
    "print(\"Size of embedding vector for each chord: {}\".format(n_dimensions))\n",
    "\n",
    "X_melody = np.zeros((n_samples, max_mel_len, n_notes), dtype='float32')\n",
    "X_chords = np.zeros((n_samples, chord_context_len, n_dimensions), dtype='float32')\n",
    "Y_chord = np.zeros((n_samples, n_chords), dtype='float32')\n",
    "\n",
    "for i, (input_mel, input_ch, target_ch) in enumerate(zip(input_melody_data, input_chords_data, target_chords_data)):\n",
    "    Y_chord[i, chord_to_int[target_ch]] = 1\n",
    "    for j, chord in enumerate(input_ch):\n",
    "#         X_chords[i, j, chord_to_int[chord]] = 1\n",
    "        chord_index = chord_to_int[chord]\n",
    "        if (chord_index < num_ch):\n",
    "            X_chords[i, j, :] = X_chords_embeddings[chord_index, :]\n",
    "    \n",
    "    for j, note in enumerate(input_mel):\n",
    "        X_melody[i, j, note_to_int[note]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334344, 135, 14)\n",
      "(334344, 7, 32)\n",
      "(334344, 195)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody.shape)\n",
    "print(X_chords.shape)\n",
    "print(Y_chord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset into 80%-10%-10% train-valid-test sets\n",
    "seed = 0\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "\n",
    "for train_index, aux_index in sss.split(X_chords, Y_chord):\n",
    "    X_melody_train, X_melody_aux = X_melody[train_index], X_melody[aux_index]\n",
    "    X_chords_train, X_chords_aux = X_chords[train_index], X_chords[aux_index]\n",
    "    Y_chord_train, Y_chord_aux = Y_chord[train_index], Y_chord[aux_index]\n",
    "    \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)\n",
    "\n",
    "for valid_index, test_index in sss.split(X_chords_aux, Y_chord_aux):\n",
    "    X_melody_valid, X_melody_test = X_melody[valid_index], X_melody[test_index]\n",
    "    X_chords_valid, X_chords_test = X_chords[valid_index], X_chords[test_index]\n",
    "    Y_chord_valid, Y_chord_test = Y_chord[valid_index], Y_chord[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 135, 14)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (None, 7, 32)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_13 (GRU)                     (None, 135, 128)      54912       input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_15 (GRU)                     (None, 7, 128)        61824       input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_14 (GRU)                     (None, 128)           98688       gru_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "gru_16 (GRU)                     (None, 128)           98688       gru_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 256)           0           gru_14[0][0]                     \n",
      "                                                                   gru_16[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 128)           32896       concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 195)           25155       dense_11[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 372,163\n",
      "Trainable params: 372,163\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 276.00 410.00\" width=\"276pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-406 272,-406 272,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140555232460248 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140555232460248</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 125,-401.5 125,-365.5 0,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-379.8\">input_8: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140555232460472 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140555232460472</title>\n",
       "<polygon fill=\"none\" points=\"25,-292.5 25,-328.5 116,-328.5 116,-292.5 25,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70.5\" y=\"-306.8\">gru_13: GRU</text>\n",
       "</g>\n",
       "<!-- 140555232460248&#45;&gt;140555232460472 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140555232460248-&gt;140555232460472</title>\n",
       "<path d=\"M64.4366,-365.313C65.3406,-357.289 66.4383,-347.547 67.45,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"70.9395,-338.858 68.5813,-328.529 63.9835,-338.074 70.9395,-338.858\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140555246615072 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140555246615072</title>\n",
       "<polygon fill=\"none\" points=\"143,-365.5 143,-401.5 268,-401.5 268,-365.5 143,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-379.8\">input_9: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140555232532240 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140555232532240</title>\n",
       "<polygon fill=\"none\" points=\"151,-292.5 151,-328.5 242,-328.5 242,-292.5 151,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196.5\" y=\"-306.8\">gru_15: GRU</text>\n",
       "</g>\n",
       "<!-- 140555246615072&#45;&gt;140555232532240 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140555246615072-&gt;140555232532240</title>\n",
       "<path d=\"M203.321,-365.313C202.304,-357.289 201.069,-347.547 199.931,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"203.388,-338.009 198.659,-328.529 196.444,-338.89 203.388,-338.009\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140555246614232 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140555246614232</title>\n",
       "<polygon fill=\"none\" points=\"33,-219.5 33,-255.5 124,-255.5 124,-219.5 33,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78.5\" y=\"-233.8\">gru_14: GRU</text>\n",
       "</g>\n",
       "<!-- 140555232460472&#45;&gt;140555246614232 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140555232460472-&gt;140555246614232</title>\n",
       "<path d=\"M72.4366,-292.313C73.3406,-284.289 74.4383,-274.547 75.45,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"78.9395,-265.858 76.5813,-255.529 71.9835,-265.074 78.9395,-265.858\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140555232531288 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140555232531288</title>\n",
       "<polygon fill=\"none\" points=\"146,-219.5 146,-255.5 237,-255.5 237,-219.5 146,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191.5\" y=\"-233.8\">gru_16: GRU</text>\n",
       "</g>\n",
       "<!-- 140555232532240&#45;&gt;140555232531288 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140555232532240-&gt;140555232531288</title>\n",
       "<path d=\"M195.29,-292.313C194.725,-284.289 194.039,-274.547 193.406,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"196.893,-265.258 192.699,-255.529 189.91,-265.75 196.893,-265.258\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140555243898248 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140555243898248</title>\n",
       "<polygon fill=\"none\" points=\"50.5,-146.5 50.5,-182.5 218.5,-182.5 218.5,-146.5 50.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-160.8\">concatenate_4: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140555246614232&#45;&gt;140555243898248 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140555246614232-&gt;140555243898248</title>\n",
       "<path d=\"M92.056,-219.313C98.8658,-210.679 107.245,-200.055 114.755,-190.534\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.624,-192.548 121.069,-182.529 112.128,-188.213 117.624,-192.548\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140555232531288&#45;&gt;140555243898248 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140555232531288-&gt;140555243898248</title>\n",
       "<path d=\"M177.702,-219.313C170.77,-210.679 162.241,-200.055 154.598,-190.534\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"157.161,-188.136 148.171,-182.529 151.702,-192.518 157.161,-188.136\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140555242748616 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140555242748616</title>\n",
       "<polygon fill=\"none\" points=\"80,-73.5 80,-109.5 189,-109.5 189,-73.5 80,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-87.8\">dense_11: Dense</text>\n",
       "</g>\n",
       "<!-- 140555243898248&#45;&gt;140555242748616 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140555243898248-&gt;140555242748616</title>\n",
       "<path d=\"M134.5,-146.313C134.5,-138.289 134.5,-128.547 134.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"138,-119.529 134.5,-109.529 131,-119.529 138,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140555243897408 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140555243897408</title>\n",
       "<polygon fill=\"none\" points=\"80,-0.5 80,-36.5 189,-36.5 189,-0.5 80,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-14.8\">dense_12: Dense</text>\n",
       "</g>\n",
       "<!-- 140555242748616&#45;&gt;140555243897408 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140555242748616-&gt;140555243897408</title>\n",
       "<path d=\"M134.5,-73.3129C134.5,-65.2895 134.5,-55.5475 134.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"138,-46.5288 134.5,-36.5288 131,-46.5289 138,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define neual net architecture\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "melody_input = Input(shape=(max_mel_len, n_notes))\n",
    "melody_gru1 = GRU(latent_dim, return_sequences=True)(melody_input)\n",
    "melody_gru2 = GRU(latent_dim)(melody_gru1)\n",
    "\n",
    "chords_input = Input(shape=(chord_context_len, n_dimensions))\n",
    "chords_gru1 = GRU(latent_dim, return_sequences=True)(chords_input)\n",
    "chords_gru2 = GRU(latent_dim)(chords_gru1)\n",
    "\n",
    "concat = concatenate([melody_gru2, chords_gru2])\n",
    "\n",
    "chord_dense1 = Dense(latent_dim, activation='relu')(concat)\n",
    "chord_dense2 = Dense(n_chords, activation='softmax')(chord_dense1)\n",
    "\n",
    "model = Model([melody_input, chords_input], chord_dense2)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Introduce Best-Performance callbacks\n",
    "# es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "filepath = \"models/embeddings32-Mel2-Cho2-FC2_150ep.h5\"\n",
    "bp = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267475 samples, validate on 33434 samples\n",
      "Epoch 1/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.8026 - acc: 0.3635Epoch 00000: val_acc improved from -inf to 0.43886, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 928s - loss: 2.8023 - acc: 0.3635 - val_loss: 2.4350 - val_acc: 0.4389\n",
      "Epoch 2/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.1842 - acc: 0.4784Epoch 00001: val_acc improved from 0.43886 to 0.50030, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 934s - loss: 2.1840 - acc: 0.4784 - val_loss: 2.1483 - val_acc: 0.5003\n",
      "Epoch 3/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.9264 - acc: 0.5363Epoch 00002: val_acc improved from 0.50030 to 0.53945, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 935s - loss: 1.9265 - acc: 0.5363 - val_loss: 2.0015 - val_acc: 0.5395\n",
      "Epoch 4/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.7421 - acc: 0.5796Epoch 00003: val_acc improved from 0.53945 to 0.56966, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 935s - loss: 1.7420 - acc: 0.5796 - val_loss: 1.8910 - val_acc: 0.5697\n",
      "Epoch 5/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.6008 - acc: 0.6128Epoch 00004: val_acc improved from 0.56966 to 0.59015, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 935s - loss: 1.6008 - acc: 0.6128 - val_loss: 1.8004 - val_acc: 0.5901\n",
      "Epoch 6/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.4904 - acc: 0.6386Epoch 00005: val_acc improved from 0.59015 to 0.60223, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 1.4904 - acc: 0.6386 - val_loss: 1.7537 - val_acc: 0.6022\n",
      "Epoch 7/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.4043 - acc: 0.6573Epoch 00006: val_acc improved from 0.60223 to 0.61662, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 930s - loss: 1.4044 - acc: 0.6573 - val_loss: 1.6869 - val_acc: 0.6166\n",
      "Epoch 8/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.3352 - acc: 0.6715Epoch 00007: val_acc improved from 0.61662 to 0.62275, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 930s - loss: 1.3351 - acc: 0.6716 - val_loss: 1.6568 - val_acc: 0.6227\n",
      "Epoch 9/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2803 - acc: 0.6838Epoch 00008: val_acc improved from 0.62275 to 0.63331, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 929s - loss: 1.2804 - acc: 0.6838 - val_loss: 1.6182 - val_acc: 0.6333\n",
      "Epoch 10/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2347 - acc: 0.6931Epoch 00009: val_acc improved from 0.63331 to 0.64126, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 934s - loss: 1.2347 - acc: 0.6931 - val_loss: 1.5820 - val_acc: 0.6413\n",
      "Epoch 11/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1966 - acc: 0.7007Epoch 00010: val_acc improved from 0.64126 to 0.64503, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 932s - loss: 1.1967 - acc: 0.7007 - val_loss: 1.5550 - val_acc: 0.6450\n",
      "Epoch 12/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1642 - acc: 0.7069Epoch 00011: val_acc improved from 0.64503 to 0.65789, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 932s - loss: 1.1642 - acc: 0.7069 - val_loss: 1.5385 - val_acc: 0.6579\n",
      "Epoch 13/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1380 - acc: 0.7121Epoch 00012: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 1.1380 - acc: 0.7121 - val_loss: 1.5317 - val_acc: 0.6573\n",
      "Epoch 14/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1145 - acc: 0.7166Epoch 00013: val_acc improved from 0.65789 to 0.66438, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 935s - loss: 1.1144 - acc: 0.7167 - val_loss: 1.5171 - val_acc: 0.6644\n",
      "Epoch 15/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0943 - acc: 0.7206Epoch 00014: val_acc improved from 0.66438 to 0.66555, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 935s - loss: 1.0944 - acc: 0.7206 - val_loss: 1.5087 - val_acc: 0.6656\n",
      "Epoch 16/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0769 - acc: 0.7238Epoch 00015: val_acc improved from 0.66555 to 0.66848, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 937s - loss: 1.0770 - acc: 0.7237 - val_loss: 1.4952 - val_acc: 0.6685\n",
      "Epoch 17/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0614 - acc: 0.7265Epoch 00016: val_acc improved from 0.66848 to 0.66914, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 933s - loss: 1.0615 - acc: 0.7265 - val_loss: 1.4926 - val_acc: 0.6691\n",
      "Epoch 18/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0496 - acc: 0.7281Epoch 00017: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 1.0497 - acc: 0.7281 - val_loss: 1.4940 - val_acc: 0.6670\n",
      "Epoch 19/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0362 - acc: 0.7314Epoch 00018: val_acc improved from 0.66914 to 0.67431, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 928s - loss: 1.0364 - acc: 0.7314 - val_loss: 1.4710 - val_acc: 0.6743\n",
      "Epoch 20/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0265 - acc: 0.7329Epoch 00019: val_acc did not improve\n",
      "267475/267475 [==============================] - 928s - loss: 1.0266 - acc: 0.7328 - val_loss: 1.4800 - val_acc: 0.6730\n",
      "Epoch 21/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0158 - acc: 0.7345Epoch 00020: val_acc improved from 0.67431 to 0.67949, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 932s - loss: 1.0159 - acc: 0.7344 - val_loss: 1.4671 - val_acc: 0.6795\n",
      "Epoch 22/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0084 - acc: 0.7360Epoch 00021: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 1.0085 - acc: 0.7360 - val_loss: 1.4692 - val_acc: 0.6794\n",
      "Epoch 23/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9996 - acc: 0.7381Epoch 00022: val_acc improved from 0.67949 to 0.68024, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 0.9996 - acc: 0.7381 - val_loss: 1.4680 - val_acc: 0.6802\n",
      "Epoch 24/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9940 - acc: 0.7387Epoch 00023: val_acc improved from 0.68024 to 0.68179, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 930s - loss: 0.9941 - acc: 0.7387 - val_loss: 1.4648 - val_acc: 0.6818\n",
      "Epoch 25/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9882 - acc: 0.7395Epoch 00024: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.9883 - acc: 0.7395 - val_loss: 1.4693 - val_acc: 0.6797\n",
      "Epoch 26/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9820 - acc: 0.7415Epoch 00025: val_acc improved from 0.68179 to 0.68233, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 934s - loss: 0.9819 - acc: 0.7415 - val_loss: 1.4555 - val_acc: 0.6823\n",
      "Epoch 27/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9779 - acc: 0.7411Epoch 00026: val_acc improved from 0.68233 to 0.68278, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 932s - loss: 0.9779 - acc: 0.7411 - val_loss: 1.4523 - val_acc: 0.6828\n",
      "Epoch 28/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9723 - acc: 0.7419Epoch 00027: val_acc improved from 0.68278 to 0.68828, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 932s - loss: 0.9723 - acc: 0.7419 - val_loss: 1.4448 - val_acc: 0.6883\n",
      "Epoch 29/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9677 - acc: 0.7432Epoch 00028: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 0.9678 - acc: 0.7431 - val_loss: 1.4538 - val_acc: 0.6845\n",
      "Epoch 30/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9642 - acc: 0.7437Epoch 00029: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.9641 - acc: 0.7437 - val_loss: 1.4566 - val_acc: 0.6847\n",
      "Epoch 31/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9594 - acc: 0.7451Epoch 00030: val_acc did not improve\n",
      "267475/267475 [==============================] - 935s - loss: 0.9596 - acc: 0.7451 - val_loss: 1.4388 - val_acc: 0.6878\n",
      "Epoch 32/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9149 - acc: 0.7508Epoch 00031: val_acc improved from 0.68828 to 0.69887, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 935s - loss: 0.9150 - acc: 0.7508 - val_loss: 1.3659 - val_acc: 0.6989\n",
      "Epoch 33/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8773 - acc: 0.7573Epoch 00032: val_acc improved from 0.69887 to 0.70548, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 936s - loss: 0.8774 - acc: 0.7572 - val_loss: 1.3376 - val_acc: 0.7055\n",
      "Epoch 34/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8523 - acc: 0.7629Epoch 00033: val_acc improved from 0.70548 to 0.70826, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 936s - loss: 0.8524 - acc: 0.7629 - val_loss: 1.3270 - val_acc: 0.7083\n",
      "Epoch 35/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8347 - acc: 0.7674Epoch 00034: val_acc improved from 0.70826 to 0.70985, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 935s - loss: 0.8346 - acc: 0.7675 - val_loss: 1.3139 - val_acc: 0.7098\n",
      "Epoch 36/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8175 - acc: 0.7722Epoch 00035: val_acc improved from 0.70985 to 0.71415, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 934s - loss: 0.8175 - acc: 0.7722 - val_loss: 1.3061 - val_acc: 0.7142\n",
      "Epoch 37/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7999 - acc: 0.7763Epoch 00036: val_acc improved from 0.71415 to 0.71879, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 925s - loss: 0.8000 - acc: 0.7763 - val_loss: 1.2962 - val_acc: 0.7188\n",
      "Epoch 38/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7951 - acc: 0.7772Epoch 00037: val_acc improved from 0.71879 to 0.72232, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 926s - loss: 0.7952 - acc: 0.7772 - val_loss: 1.2898 - val_acc: 0.7223\n",
      "Epoch 39/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7762 - acc: 0.7813Epoch 00038: val_acc improved from 0.72232 to 0.72384, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 926s - loss: 0.7763 - acc: 0.7813 - val_loss: 1.2718 - val_acc: 0.7238\n",
      "Epoch 40/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7632 - acc: 0.7853Epoch 00039: val_acc improved from 0.72384 to 0.72639, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 925s - loss: 0.7632 - acc: 0.7853 - val_loss: 1.2683 - val_acc: 0.7264\n",
      "Epoch 41/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7992 - acc: 0.7761Epoch 00040: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 0.7992 - acc: 0.7761 - val_loss: 1.3878 - val_acc: 0.6972\n",
      "Epoch 42/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8333 - acc: 0.7673Epoch 00041: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.8334 - acc: 0.7672 - val_loss: 1.3323 - val_acc: 0.7124\n",
      "Epoch 43/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8037 - acc: 0.7745Epoch 00042: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 0.8037 - acc: 0.7745 - val_loss: 1.3285 - val_acc: 0.7135\n",
      "Epoch 44/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7890 - acc: 0.7782Epoch 00043: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.7890 - acc: 0.7783 - val_loss: 1.3143 - val_acc: 0.7181\n",
      "Epoch 45/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7757 - acc: 0.7812Epoch 00044: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.7757 - acc: 0.7812 - val_loss: 1.3082 - val_acc: 0.7162\n",
      "Epoch 46/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7582 - acc: 0.7847Epoch 00045: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.7584 - acc: 0.7847 - val_loss: 1.3029 - val_acc: 0.7203\n",
      "Epoch 47/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7452 - acc: 0.7884Epoch 00046: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.7453 - acc: 0.7884 - val_loss: 1.2928 - val_acc: 0.7225\n",
      "Epoch 48/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7319 - acc: 0.7915Epoch 00047: val_acc improved from 0.72639 to 0.72761, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 0.7318 - acc: 0.7916 - val_loss: 1.2883 - val_acc: 0.7276\n",
      "Epoch 49/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7235 - acc: 0.7939Epoch 00048: val_acc did not improve\n",
      "267475/267475 [==============================] - 935s - loss: 0.7236 - acc: 0.7939 - val_loss: 1.2897 - val_acc: 0.7263\n",
      "Epoch 50/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7122 - acc: 0.7966Epoch 00049: val_acc improved from 0.72761 to 0.73192, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 938s - loss: 0.7122 - acc: 0.7965 - val_loss: 1.2774 - val_acc: 0.7319\n",
      "Epoch 51/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7068 - acc: 0.7981Epoch 00050: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.7068 - acc: 0.7981 - val_loss: 1.2819 - val_acc: 0.7284\n",
      "Epoch 52/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7026 - acc: 0.7984Epoch 00051: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.7026 - acc: 0.7984 - val_loss: 1.2833 - val_acc: 0.7316\n",
      "Epoch 53/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7006 - acc: 0.7987Epoch 00052: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.7004 - acc: 0.7987 - val_loss: 1.2827 - val_acc: 0.7317\n",
      "Epoch 54/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7231 - acc: 0.7943Epoch 00053: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 932s - loss: 0.7231 - acc: 0.7943 - val_loss: 1.2876 - val_acc: 0.7306\n",
      "Epoch 55/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7035 - acc: 0.7988Epoch 00054: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.7035 - acc: 0.7988 - val_loss: 1.3180 - val_acc: 0.7212\n",
      "Epoch 56/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6986 - acc: 0.8001Epoch 00055: val_acc did not improve\n",
      "267475/267475 [==============================] - 928s - loss: 0.6984 - acc: 0.8001 - val_loss: 1.2888 - val_acc: 0.7319\n",
      "Epoch 57/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6896 - acc: 0.8022Epoch 00056: val_acc did not improve\n",
      "267475/267475 [==============================] - 928s - loss: 0.6899 - acc: 0.8022 - val_loss: 1.3490 - val_acc: 0.7157\n",
      "Epoch 58/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0023 - acc: 0.7319Epoch 00057: val_acc did not improve\n",
      "267475/267475 [==============================] - 928s - loss: 1.0023 - acc: 0.7319 - val_loss: 1.4886 - val_acc: 0.6855\n",
      "Epoch 59/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8972 - acc: 0.7534Epoch 00058: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.8972 - acc: 0.7535 - val_loss: 1.4318 - val_acc: 0.6955\n",
      "Epoch 60/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8632 - acc: 0.7607Epoch 00059: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.8631 - acc: 0.7606 - val_loss: 1.4033 - val_acc: 0.6997\n",
      "Epoch 61/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8461 - acc: 0.7634Epoch 00060: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.8460 - acc: 0.7634 - val_loss: 1.4024 - val_acc: 0.7034\n",
      "Epoch 62/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8415 - acc: 0.7651Epoch 00061: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.8414 - acc: 0.7651 - val_loss: 1.3709 - val_acc: 0.7054\n",
      "Epoch 63/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8183 - acc: 0.7707Epoch 00062: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.8183 - acc: 0.7707 - val_loss: 1.3840 - val_acc: 0.7072\n",
      "Epoch 64/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8232 - acc: 0.7688Epoch 00063: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.8232 - acc: 0.7688 - val_loss: 1.3587 - val_acc: 0.7096\n",
      "Epoch 65/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8164 - acc: 0.7715Epoch 00064: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.8163 - acc: 0.7715 - val_loss: 1.4133 - val_acc: 0.7009\n",
      "Epoch 66/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8294 - acc: 0.7676Epoch 00065: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.8294 - acc: 0.7676 - val_loss: 1.3493 - val_acc: 0.7153\n",
      "Epoch 67/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7907 - acc: 0.7772Epoch 00066: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.7908 - acc: 0.7772 - val_loss: 1.3386 - val_acc: 0.7171\n",
      "Epoch 68/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7878 - acc: 0.7779Epoch 00067: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.7878 - acc: 0.7778 - val_loss: 1.3463 - val_acc: 0.7172\n",
      "Epoch 69/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7801 - acc: 0.7792Epoch 00068: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.7801 - acc: 0.7793 - val_loss: 1.3388 - val_acc: 0.7198\n",
      "Epoch 70/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7717 - acc: 0.7811Epoch 00069: val_acc did not improve\n",
      "267475/267475 [==============================] - 937s - loss: 0.7717 - acc: 0.7811 - val_loss: 1.3301 - val_acc: 0.7191\n",
      "Epoch 71/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7741 - acc: 0.7813Epoch 00070: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.7742 - acc: 0.7813 - val_loss: 1.3528 - val_acc: 0.7114\n",
      "Epoch 72/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7621 - acc: 0.7842Epoch 00071: val_acc did not improve\n",
      "267475/267475 [==============================] - 927s - loss: 0.7622 - acc: 0.7842 - val_loss: 1.3191 - val_acc: 0.7205\n",
      "Epoch 73/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7407 - acc: 0.7888Epoch 00072: val_acc did not improve\n",
      "267475/267475 [==============================] - 927s - loss: 0.7407 - acc: 0.7888 - val_loss: 1.3232 - val_acc: 0.7228\n",
      "Epoch 74/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7252 - acc: 0.7933Epoch 00073: val_acc did not improve\n",
      "267475/267475 [==============================] - 927s - loss: 0.7251 - acc: 0.7933 - val_loss: 1.3179 - val_acc: 0.7275\n",
      "Epoch 75/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7289 - acc: 0.7923Epoch 00074: val_acc did not improve\n",
      "267475/267475 [==============================] - 928s - loss: 0.7289 - acc: 0.7923 - val_loss: 1.3073 - val_acc: 0.7293\n",
      "Epoch 76/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7146 - acc: 0.7958Epoch 00075: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.7146 - acc: 0.7958 - val_loss: 1.3172 - val_acc: 0.7269\n",
      "Epoch 77/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7003 - acc: 0.7992Epoch 00076: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.7005 - acc: 0.7992 - val_loss: 1.3161 - val_acc: 0.7276\n",
      "Epoch 78/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6949 - acc: 0.8002Epoch 00077: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.6948 - acc: 0.8003 - val_loss: 1.3168 - val_acc: 0.7285\n",
      "Epoch 79/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6949 - acc: 0.8006Epoch 00078: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.6949 - acc: 0.8006 - val_loss: 1.3155 - val_acc: 0.7305\n",
      "Epoch 80/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6773 - acc: 0.8051Epoch 00079: val_acc improved from 0.73192 to 0.73240, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 934s - loss: 0.6775 - acc: 0.8051 - val_loss: 1.3006 - val_acc: 0.7324\n",
      "Epoch 81/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6613 - acc: 0.8099Epoch 00080: val_acc improved from 0.73240 to 0.73395, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 932s - loss: 0.6614 - acc: 0.8099 - val_loss: 1.3063 - val_acc: 0.7340\n",
      "Epoch 82/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6479 - acc: 0.8131Epoch 00081: val_acc improved from 0.73395 to 0.73566, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 930s - loss: 0.6480 - acc: 0.8130 - val_loss: 1.3059 - val_acc: 0.7357\n",
      "Epoch 83/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6415 - acc: 0.8150Epoch 00082: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.6415 - acc: 0.8150 - val_loss: 1.3136 - val_acc: 0.7328\n",
      "Epoch 84/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6384 - acc: 0.8160Epoch 00083: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.6384 - acc: 0.8160 - val_loss: 1.3187 - val_acc: 0.7328\n",
      "Epoch 85/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6286 - acc: 0.8181Epoch 00084: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 936s - loss: 0.6287 - acc: 0.8181 - val_loss: 1.3327 - val_acc: 0.7353\n",
      "Epoch 86/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6210 - acc: 0.8205Epoch 00085: val_acc improved from 0.73566 to 0.74008, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 934s - loss: 0.6209 - acc: 0.8205 - val_loss: 1.3181 - val_acc: 0.7401\n",
      "Epoch 87/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.8247Epoch 00086: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 0.6032 - acc: 0.8247 - val_loss: 1.3172 - val_acc: 0.7386\n",
      "Epoch 88/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5956 - acc: 0.8274Epoch 00087: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 0.5957 - acc: 0.8274 - val_loss: 1.3355 - val_acc: 0.7392\n",
      "Epoch 89/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5967 - acc: 0.8275Epoch 00088: val_acc did not improve\n",
      "267475/267475 [==============================] - 928s - loss: 0.5968 - acc: 0.8275 - val_loss: 1.3491 - val_acc: 0.7356\n",
      "Epoch 90/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5792 - acc: 0.8316Epoch 00089: val_acc did not improve\n",
      "267475/267475 [==============================] - 928s - loss: 0.5792 - acc: 0.8316 - val_loss: 1.3306 - val_acc: 0.7391\n",
      "Epoch 91/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5621 - acc: 0.8366Epoch 00090: val_acc improved from 0.74008 to 0.74759, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 929s - loss: 0.5622 - acc: 0.8366 - val_loss: 1.3231 - val_acc: 0.7476\n",
      "Epoch 92/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5673 - acc: 0.8345Epoch 00091: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.5673 - acc: 0.8345 - val_loss: 1.3280 - val_acc: 0.7453\n",
      "Epoch 93/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5508 - acc: 0.8399Epoch 00092: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 0.5507 - acc: 0.8400 - val_loss: 1.3304 - val_acc: 0.7459\n",
      "Epoch 94/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5429 - acc: 0.8419Epoch 00093: val_acc did not improve\n",
      "267475/267475 [==============================] - 928s - loss: 0.5429 - acc: 0.8419 - val_loss: 1.3641 - val_acc: 0.7401\n",
      "Epoch 95/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5371 - acc: 0.8430Epoch 00094: val_acc did not improve\n",
      "267475/267475 [==============================] - 926s - loss: 0.5371 - acc: 0.8429 - val_loss: 1.3503 - val_acc: 0.7469\n",
      "Epoch 96/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5315 - acc: 0.8455Epoch 00095: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.5316 - acc: 0.8455 - val_loss: 1.3605 - val_acc: 0.7446\n",
      "Epoch 97/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5641 - acc: 0.8351Epoch 00096: val_acc did not improve\n",
      "267475/267475 [==============================] - 937s - loss: 0.5641 - acc: 0.8351 - val_loss: 1.3552 - val_acc: 0.7400\n",
      "Epoch 98/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5279 - acc: 0.8458Epoch 00097: val_acc improved from 0.74759 to 0.74762, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 936s - loss: 0.5279 - acc: 0.8458 - val_loss: 1.3371 - val_acc: 0.7476\n",
      "Epoch 99/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5165 - acc: 0.8492Epoch 00098: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.5165 - acc: 0.8492 - val_loss: 1.3757 - val_acc: 0.7418\n",
      "Epoch 100/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5239 - acc: 0.8467Epoch 00099: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.5240 - acc: 0.8467 - val_loss: 1.3689 - val_acc: 0.7467\n",
      "Epoch 101/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4991 - acc: 0.8544Epoch 00100: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.4991 - acc: 0.8544 - val_loss: 1.3663 - val_acc: 0.7464\n",
      "Epoch 102/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4968 - acc: 0.8549Epoch 00101: val_acc did not improve\n",
      "267475/267475 [==============================] - 927s - loss: 0.4969 - acc: 0.8548 - val_loss: 1.3715 - val_acc: 0.7469\n",
      "Epoch 103/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5092 - acc: 0.8507Epoch 00102: val_acc did not improve\n",
      "267475/267475 [==============================] - 925s - loss: 0.5092 - acc: 0.8507 - val_loss: 1.3722 - val_acc: 0.7465\n",
      "Epoch 104/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5142 - acc: 0.8490Epoch 00103: val_acc improved from 0.74762 to 0.74792, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 0.5142 - acc: 0.8490 - val_loss: 1.3692 - val_acc: 0.7479\n",
      "Epoch 105/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4740 - acc: 0.8609Epoch 00104: val_acc did not improve\n",
      "267475/267475 [==============================] - 938s - loss: 0.4741 - acc: 0.8609 - val_loss: 1.3885 - val_acc: 0.7471\n",
      "Epoch 106/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4915 - acc: 0.8560Epoch 00105: val_acc improved from 0.74792 to 0.75142, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 938s - loss: 0.4915 - acc: 0.8560 - val_loss: 1.3764 - val_acc: 0.7514\n",
      "Epoch 107/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5217 - acc: 0.8466Epoch 00106: val_acc did not improve\n",
      "267475/267475 [==============================] - 938s - loss: 0.5217 - acc: 0.8467 - val_loss: 1.3747 - val_acc: 0.7472\n",
      "Epoch 108/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5054 - acc: 0.8510Epoch 00107: val_acc did not improve\n",
      "267475/267475 [==============================] - 937s - loss: 0.5053 - acc: 0.8510 - val_loss: 1.3946 - val_acc: 0.7460\n",
      "Epoch 109/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5113 - acc: 0.8499Epoch 00108: val_acc improved from 0.75142 to 0.75142, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 935s - loss: 0.5113 - acc: 0.8499 - val_loss: 1.3659 - val_acc: 0.7514\n",
      "Epoch 110/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4884 - acc: 0.8570Epoch 00109: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.4885 - acc: 0.8569 - val_loss: 1.4607 - val_acc: 0.7285\n",
      "Epoch 111/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5706 - acc: 0.8327Epoch 00110: val_acc did not improve\n",
      "267475/267475 [==============================] - 927s - loss: 0.5706 - acc: 0.8328 - val_loss: 1.3961 - val_acc: 0.7418\n",
      "Epoch 112/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.8556Epoch 00111: val_acc improved from 0.75142 to 0.75265, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 933s - loss: 0.4916 - acc: 0.8556 - val_loss: 1.3697 - val_acc: 0.7526\n",
      "Epoch 113/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8655Epoch 00112: val_acc improved from 0.75265 to 0.75357, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 0.4591 - acc: 0.8655 - val_loss: 1.3842 - val_acc: 0.7536\n",
      "Epoch 114/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4753 - acc: 0.8594Epoch 00113: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.4754 - acc: 0.8593 - val_loss: 1.4039 - val_acc: 0.7469\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4727 - acc: 0.8598Epoch 00114: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.4727 - acc: 0.8598 - val_loss: 1.4028 - val_acc: 0.7507\n",
      "Epoch 116/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.8683Epoch 00115: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.4488 - acc: 0.8682 - val_loss: 1.4362 - val_acc: 0.7450\n",
      "Epoch 117/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4558 - acc: 0.8657Epoch 00116: val_acc improved from 0.75357 to 0.75435, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 935s - loss: 0.4558 - acc: 0.8657 - val_loss: 1.4116 - val_acc: 0.7544\n",
      "Epoch 118/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4561 - acc: 0.8653Epoch 00117: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.4562 - acc: 0.8653 - val_loss: 1.4199 - val_acc: 0.7512\n",
      "Epoch 119/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4422 - acc: 0.8693Epoch 00118: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.4422 - acc: 0.8693 - val_loss: 1.4070 - val_acc: 0.7511\n",
      "Epoch 120/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8638Epoch 00119: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 0.4616 - acc: 0.8637 - val_loss: 1.4293 - val_acc: 0.7477\n",
      "Epoch 121/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8642Epoch 00120: val_acc did not improve\n",
      "267475/267475 [==============================] - 928s - loss: 0.4590 - acc: 0.8642 - val_loss: 1.4134 - val_acc: 0.7526\n",
      "Epoch 122/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4397 - acc: 0.8698Epoch 00121: val_acc improved from 0.75435 to 0.75624, saving model to models/embeddings32-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 932s - loss: 0.4398 - acc: 0.8698 - val_loss: 1.4356 - val_acc: 0.7562\n",
      "Epoch 123/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.8653Epoch 00122: val_acc did not improve\n",
      "267475/267475 [==============================] - 938s - loss: 0.4562 - acc: 0.8653 - val_loss: 1.4326 - val_acc: 0.7509\n",
      "Epoch 124/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5604 - acc: 0.8363Epoch 00123: val_acc did not improve\n",
      "267475/267475 [==============================] - 937s - loss: 0.5605 - acc: 0.8363 - val_loss: 1.4432 - val_acc: 0.7416\n",
      "Epoch 125/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6558 - acc: 0.8237Epoch 00124: val_acc did not improve\n",
      "267475/267475 [==============================] - 935s - loss: 0.6562 - acc: 0.8236 - val_loss: 1.8749 - val_acc: 0.6476\n",
      "Epoch 126/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1082 - acc: 0.7175Epoch 00125: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 1.1081 - acc: 0.7175 - val_loss: 1.6081 - val_acc: 0.6831\n",
      "Epoch 127/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9568 - acc: 0.7448Epoch 00126: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.9566 - acc: 0.7448 - val_loss: 1.5662 - val_acc: 0.6853\n",
      "Epoch 128/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8967 - acc: 0.7559Epoch 00127: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.8967 - acc: 0.7559 - val_loss: 1.5090 - val_acc: 0.6975\n",
      "Epoch 129/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8611 - acc: 0.7631Epoch 00128: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.8609 - acc: 0.7631 - val_loss: 1.4796 - val_acc: 0.7013\n",
      "Epoch 130/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8386 - acc: 0.7671Epoch 00129: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.8385 - acc: 0.7671 - val_loss: 1.4680 - val_acc: 0.7052\n",
      "Epoch 131/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8163 - acc: 0.7713Epoch 00130: val_acc did not improve\n",
      "267475/267475 [==============================] - 935s - loss: 0.8164 - acc: 0.7713 - val_loss: 1.4499 - val_acc: 0.7055\n",
      "Epoch 132/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7987 - acc: 0.7758Epoch 00131: val_acc did not improve\n",
      "267475/267475 [==============================] - 938s - loss: 0.7987 - acc: 0.7758 - val_loss: 1.4416 - val_acc: 0.7085\n",
      "Epoch 133/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7803 - acc: 0.7796Epoch 00132: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.7801 - acc: 0.7796 - val_loss: 1.4307 - val_acc: 0.7099\n",
      "Epoch 134/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7677 - acc: 0.7825Epoch 00133: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.7677 - acc: 0.7825 - val_loss: 1.4080 - val_acc: 0.7128\n",
      "Epoch 135/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7501 - acc: 0.7860Epoch 00134: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.7501 - acc: 0.7860 - val_loss: 1.4164 - val_acc: 0.7140\n",
      "Epoch 136/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7803 - acc: 0.7796Epoch 00135: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.7803 - acc: 0.7796 - val_loss: 1.4681 - val_acc: 0.6994\n",
      "Epoch 137/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7946 - acc: 0.7758Epoch 00136: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.7946 - acc: 0.7758 - val_loss: 1.4115 - val_acc: 0.7163\n",
      "Epoch 138/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7499 - acc: 0.7865Epoch 00137: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.7500 - acc: 0.7865 - val_loss: 1.4019 - val_acc: 0.7162\n",
      "Epoch 139/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7345 - acc: 0.7901Epoch 00138: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.7345 - acc: 0.7901 - val_loss: 1.3766 - val_acc: 0.7194\n",
      "Epoch 140/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7144 - acc: 0.7955Epoch 00139: val_acc did not improve\n",
      "267475/267475 [==============================] - 938s - loss: 0.7145 - acc: 0.7955 - val_loss: 1.3725 - val_acc: 0.7230\n",
      "Epoch 141/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6986 - acc: 0.7987Epoch 00140: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.6985 - acc: 0.7987 - val_loss: 1.3705 - val_acc: 0.7252\n",
      "Epoch 142/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6902 - acc: 0.8007Epoch 00141: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.6902 - acc: 0.8007 - val_loss: 1.3655 - val_acc: 0.7261\n",
      "Epoch 143/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7178 - acc: 0.7937Epoch 00142: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 0.7179 - acc: 0.7937 - val_loss: 1.3860 - val_acc: 0.7191\n",
      "Epoch 144/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7655 - acc: 0.7829Epoch 00143: val_acc did not improve\n",
      "267475/267475 [==============================] - 928s - loss: 0.7656 - acc: 0.7828 - val_loss: 1.4148 - val_acc: 0.7150\n",
      "Epoch 145/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7336 - acc: 0.7907Epoch 00144: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.7336 - acc: 0.7906 - val_loss: 1.3863 - val_acc: 0.7208\n",
      "Epoch 146/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7034 - acc: 0.7981Epoch 00145: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 936s - loss: 0.7034 - acc: 0.7981 - val_loss: 1.3882 - val_acc: 0.7207\n",
      "Epoch 147/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6813 - acc: 0.8034Epoch 00146: val_acc did not improve\n",
      "267475/267475 [==============================] - 937s - loss: 0.6813 - acc: 0.8034 - val_loss: 1.3698 - val_acc: 0.7263\n",
      "Epoch 148/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6656 - acc: 0.8077Epoch 00147: val_acc did not improve\n",
      "267475/267475 [==============================] - 937s - loss: 0.6657 - acc: 0.8077 - val_loss: 1.3714 - val_acc: 0.7271\n",
      "Epoch 149/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6740 - acc: 0.8046Epoch 00148: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.6740 - acc: 0.8047 - val_loss: 1.3788 - val_acc: 0.7250\n",
      "Epoch 150/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6601 - acc: 0.8087Epoch 00149: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.6601 - acc: 0.8087 - val_loss: 1.3692 - val_acc: 0.7300\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 256\n",
    "epochs = 150\n",
    "\n",
    "history = model.fit([X_melody_train, X_chords_train], Y_chord_train, epochs=epochs, validation_data=([X_melody_valid, X_chords_valid], Y_chord_valid), batch_size=batch_size, callbacks=[bp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd591269860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFkCAYAAADWs8tQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5247ee0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize model learning\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Training history of root model\", fontsize=16)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load best performance model\n",
    "best_model = load_model(\"models/embeddings32-Mel2-Cho2-FC2_150ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33435, 135, 14)\n",
      "(33435, 7, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody_test.shape)\n",
    "print(X_chords_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord prediction: 0.7273\n",
      "Kappa score of combined chord prediction: 0.7205\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of labels\n",
    "\n",
    "# Predict chords from each test sample melody\n",
    "Y_chord_pred = model.predict([X_melody_test, X_chords_test])\n",
    "\n",
    "# Compute accuracy and kappa score \n",
    "print(\"Categorical accuracy of combined chord prediction: {0:.4f}\".format(harmoutil.compute_accuracy_score(Y_chord_test, Y_chord_pred)))\n",
    "print(\"Kappa score of combined chord prediction: {0:.4f}\".format(harmoutil.compute_kappa_score(Y_chord_test, Y_chord_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord pitch prediction: 0.9044\n",
      "TP: 111345 TN: 251536 FP: 19231 FN: 19108\n",
      "Kappa score of combined chord pitch prediction: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of pitches\n",
    "\n",
    "def label_to_pitch_tensors(predictions):\n",
    "    predicted_chords = [int_to_chord[np.argmax(ch)] for ch in predictions]\n",
    "    pitch_chords = [harmoutil.chord_to_notes(label) for label in predicted_chords]\n",
    "    \n",
    "    Y_pitches = np.zeros((predictions.shape[0], 12), dtype='float32')\n",
    "    for i, chord_pitches in enumerate(pitch_chords):\n",
    "        for j, pitch_presence in enumerate(chord_pitches):\n",
    "            Y_pitches[i, j] = pitch_presence\n",
    "\n",
    "    return Y_pitches\n",
    "\n",
    "Y_pitch_pred = label_to_pitch_tensors(Y_chord_pred)\n",
    "Y_pitch_test = label_to_pitch_tensors(Y_chord_test)\n",
    "\n",
    "print(\"Categorical accuracy of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_accuracy_score(Y_pitch_test, Y_pitch_pred)))\n",
    "print(\"Kappa score of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_kappa_score(Y_pitch_test, Y_pitch_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
