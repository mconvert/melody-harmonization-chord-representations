{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, GRU, concatenate\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# Custom library for the project\n",
    "import sys\n",
    "sys.path.insert(0, '../../src')\n",
    "import harmoutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'harmoutil' from '../../src/harmoutil.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Remove when done with kernel\n",
    "import importlib\n",
    "importlib.reload(harmoutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = harmoutil.load_pickled_data(\"../../data/refined_data.pkl\") # lists of (chord label, melody seqs) by sections\n",
    "augmented_data = harmoutil.transpose_and_augment_data(raw_data)\n",
    "data = [harmoutil.to_sevenths(section) for section in augmented_data]\n",
    "data = [harmoutil.melody_to_octave_range(section) for section in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chords: 334344 | Sample chord: E6\n",
      "Number of melody notes in the data: 2209944 | Sample melody note: 4\n",
      "Unique notes: [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Unique notes: ['A', 'A+', 'A+7', 'A+j7', 'A-', 'A-6', 'A-7', 'A-j7', 'A6', 'A7', 'Ab', 'Ab+', 'Ab+7', 'Ab+j7', 'Ab-', 'Ab-6', 'Ab-7', 'Ab-j7', 'Ab6', 'Ab7', 'Abj7', 'Abm7b5', 'Abo', 'Abo7', 'Absus', 'Absus7', 'Aj7', 'Am7b5', 'Ao', 'Ao7', 'Asus', 'Asus7', 'B', 'B+', 'B+7', 'B+j7', 'B-', 'B-6', 'B-7', 'B-j7', 'B6', 'B7', 'Bb', 'Bb+', 'Bb+7', 'Bb+j7', 'Bb-', 'Bb-6', 'Bb-7', 'Bb-j7', 'Bb6', 'Bb7', 'Bbj7', 'Bbm7b5', 'Bbo', 'Bbo7', 'Bbsus', 'Bbsus7', 'Bj7', 'Bm7b5', 'Bo', 'Bo7', 'Bsus', 'Bsus7', 'C', 'C+', 'C+7', 'C+j7', 'C-', 'C-6', 'C-7', 'C-j7', 'C6', 'C7', 'Cj7', 'Cm7b5', 'Co', 'Co7', 'Csus', 'Csus7', 'D', 'D+', 'D+7', 'D+j7', 'D-', 'D-6', 'D-7', 'D-j7', 'D6', 'D7', 'Db', 'Db+', 'Db+7', 'Db+j7', 'Db-', 'Db-6', 'Db-7', 'Db-j7', 'Db6', 'Db7', 'Dbj7', 'Dbm7b5', 'Dbo', 'Dbo7', 'Dbsus', 'Dbsus7', 'Dj7', 'Dm7b5', 'Do', 'Do7', 'Dsus', 'Dsus7', 'E', 'E+', 'E+7', 'E+j7', 'E-', 'E-6', 'E-7', 'E-j7', 'E6', 'E7', 'Eb', 'Eb+', 'Eb+7', 'Eb+j7', 'Eb-', 'Eb-6', 'Eb-7', 'Eb-j7', 'Eb6', 'Eb7', 'Ebj7', 'Ebm7b5', 'Ebo', 'Ebo7', 'Ebsus', 'Ebsus7', 'Ej7', 'Em7b5', 'Eo', 'Eo7', 'Esus', 'Esus7', 'F', 'F+', 'F+7', 'F+j7', 'F-', 'F-6', 'F-7', 'F-j7', 'F6', 'F7', 'Fj7', 'Fm7b5', 'Fo', 'Fo7', 'Fsus', 'Fsus7', 'G', 'G+', 'G+7', 'G+j7', 'G-', 'G-6', 'G-7', 'G-j7', 'G6', 'G7', 'Gb', 'Gb+', 'Gb+7', 'Gb+j7', 'Gb-', 'Gb-6', 'Gb-7', 'Gb-j7', 'Gb6', 'Gb7', 'Gbj7', 'Gbm7b5', 'Gbo', 'Gbo7', 'Gbsus', 'Gbsus7', 'Gj7', 'Gm7b5', 'Go', 'Go7', 'Gsus', 'Gsus7', 'NC']\n"
     ]
    }
   ],
   "source": [
    "# Isolate relevant data\n",
    "def get_notes_by_chord(beats):\n",
    "    return [note for beat in beats for note in beat]\n",
    "\n",
    "def get_chords_by_section(section):\n",
    "    return [chord_info[0] for chord_info in section]\n",
    "\n",
    "# def check_if_augmented_major(section):\n",
    "#     section_chords = get_chords_by_section(section)\n",
    "#     for ch in section_chords:\n",
    "#         if \"+j7\" in ch:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "# data = [section for section in data if not check_if_augmented_major(section)]\n",
    "# print(\"---Remove sections with augmented major chord---\")\n",
    "# print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections_bf_augmaj7 = [get_chords_by_section(section) for section in data]\n",
    "chords = [chord_info[0] for section in data for chord_info in section]\n",
    "unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords_bf_augmaj7 = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "notes = [note for chord_notes in notes_by_chords_bf_augmaj7 for note in chord_notes]\n",
    "unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "# print(sum([len(section) for section in chords_by_sections]))\n",
    "# print(\"Number of sections: {} | Sample section chords: {}\".format(len(chords_by_sections), chords_by_sections[0]))\n",
    "print(\"Number of chords: {} | Sample chord: {}\".format(len(chords), chords[0]))\n",
    "# print(\"Number of melodies {} | Sample melody: {}\".format(len(notes_by_chords), notes_by_chords[0]))\n",
    "print(\"Number of melody notes in the data: {} | Sample melody note: {}\".format(len(notes), notes[0]))\n",
    "print(\"Unique notes: {}\".format(unique_notes))\n",
    "print(\"Unique notes: {}\".format(unique_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melody note to integer mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, '<pad>': 13, -1: 12}\n",
      "\n",
      "Integer to melody note mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: -1, 13: '<pad>'}\n",
      "\n",
      "Chord label to integer mapping:\n",
      " {'Bo7': 61, 'F7': 153, 'Db-6': 95, 'F-7': 150, 'C+7': 66, 'E+': 113, 'Gb-6': 175, 'Absus7': 25, 'Eo': 140, 'G+7': 162, 'Bbo': 54, 'Ebo7': 135, 'Dbsus7': 105, 'Eb': 122, 'C+j7': 67, 'Bb6': 50, 'Abo': 22, 'Aj7': 26, 'Do': 108, 'Dm7b5': 107, 'Esus': 142, 'D6': 88, 'Fm7b5': 155, 'Em7b5': 139, 'Cj7': 74, 'Eb+j7': 125, 'B-': 36, 'Bbsus7': 57, 'C': 64, 'D+': 81, 'C+': 65, 'Bsus7': 63, 'Db-': 94, 'Asus7': 31, 'Bb7': 51, 'Dbsus': 104, 'Csus': 78, 'Bbj7': 52, 'Gb-j7': 177, 'B-6': 37, 'Bsus': 62, 'Co': 76, 'E': 112, 'Eb6': 130, 'E-7': 118, 'C-j7': 71, 'Db': 90, 'Gb+': 171, 'D': 80, 'A-j7': 7, 'Gm7b5': 187, 'E+7': 114, 'Bb+j7': 45, '<bos>': 193, 'A7': 9, 'Ebsus7': 137, 'Ab-j7': 17, 'F6': 152, 'Gbm7b5': 181, 'Gb+7': 172, 'Bbo7': 55, 'Gb': 170, '<eos>': 194, 'A-': 4, 'Gbj7': 180, 'G+': 161, 'Ao7': 29, 'Bb-6': 47, 'Ab6': 18, 'F-j7': 151, 'B6': 40, 'C-6': 69, 'Ab7': 19, 'Db6': 98, 'G7': 169, 'Ab': 10, 'B-j7': 39, 'F-6': 149, 'Eo7': 141, 'Ebsus': 136, 'A6': 8, 'Abj7': 20, 'Gb-': 174, 'Dbo7': 103, 'C-': 68, 'Eb+': 123, 'G-6': 165, 'G-': 164, 'G': 160, 'F+7': 146, 'Db-j7': 97, 'Bj7': 58, 'E-': 116, 'Bb-': 46, 'B+': 33, 'Fj7': 154, 'Db+7': 92, 'Esus7': 143, 'C-7': 70, 'G-j7': 167, 'Bb-7': 48, 'Fsus7': 159, 'B7': 41, 'Gsus7': 191, 'F+j7': 147, 'Db-7': 96, 'Go': 188, 'Cm7b5': 75, 'D-': 84, 'Ab+7': 12, 'Gb7': 179, 'Dbm7b5': 101, 'Co7': 77, 'Gj7': 186, 'Eb-': 126, 'Bb+': 43, 'Bb+7': 44, 'Ab-': 14, 'Absus': 24, 'D-6': 85, 'D+7': 82, 'Ab+j7': 13, 'A': 0, 'Am7b5': 27, 'Db+j7': 93, 'A+': 1, 'Eb7': 131, 'Do7': 109, 'Ao': 28, 'D7': 89, 'B': 32, 'Ab-6': 15, 'Ebo': 134, 'A+j7': 3, 'G-7': 166, 'Gbo7': 183, 'Ab-7': 16, 'Eb-7': 128, 'Gbo': 182, 'Bbsus': 56, 'Fo7': 157, 'Ebm7b5': 133, 'Dbo': 102, 'Bb': 42, 'B+7': 34, 'E+j7': 115, 'Db7': 99, 'A-7': 6, 'Dbj7': 100, 'Fo': 156, 'Csus7': 79, 'Gb+j7': 173, 'B-7': 38, 'Gbsus': 184, 'Ej7': 138, 'Eb-6': 127, 'D+j7': 83, 'G6': 168, 'Eb+7': 124, 'Dsus': 110, 'Ebj7': 132, 'Asus': 30, 'E-j7': 119, 'A-6': 5, 'Bb-j7': 49, 'Bm7b5': 59, 'Gb6': 178, 'Dsus7': 111, 'Dj7': 106, 'NC': 192, 'Gb-7': 176, 'Bo': 60, 'Abm7b5': 21, 'Fsus': 158, 'E7': 121, 'E6': 120, 'B+j7': 35, 'Go7': 189, 'A+7': 2, 'G+j7': 163, 'Eb-j7': 129, 'E-6': 117, 'Gsus': 190, 'F': 144, 'Gbsus7': 185, 'D-j7': 87, 'Ab+': 11, 'F+': 145, 'Db+': 91, 'F-': 148, 'C6': 72, 'C7': 73, 'Abo7': 23, 'Bbm7b5': 53, 'D-7': 86}\n",
      "\n",
      "Integer to chord label mapping:\n",
      " {0: 'A', 1: 'A+', 2: 'A+7', 3: 'A+j7', 4: 'A-', 5: 'A-6', 6: 'A-7', 7: 'A-j7', 8: 'A6', 9: 'A7', 10: 'Ab', 11: 'Ab+', 12: 'Ab+7', 13: 'Ab+j7', 14: 'Ab-', 15: 'Ab-6', 16: 'Ab-7', 17: 'Ab-j7', 18: 'Ab6', 19: 'Ab7', 20: 'Abj7', 21: 'Abm7b5', 22: 'Abo', 23: 'Abo7', 24: 'Absus', 25: 'Absus7', 26: 'Aj7', 27: 'Am7b5', 28: 'Ao', 29: 'Ao7', 30: 'Asus', 31: 'Asus7', 32: 'B', 33: 'B+', 34: 'B+7', 35: 'B+j7', 36: 'B-', 37: 'B-6', 38: 'B-7', 39: 'B-j7', 40: 'B6', 41: 'B7', 42: 'Bb', 43: 'Bb+', 44: 'Bb+7', 45: 'Bb+j7', 46: 'Bb-', 47: 'Bb-6', 48: 'Bb-7', 49: 'Bb-j7', 50: 'Bb6', 51: 'Bb7', 52: 'Bbj7', 53: 'Bbm7b5', 54: 'Bbo', 55: 'Bbo7', 56: 'Bbsus', 57: 'Bbsus7', 58: 'Bj7', 59: 'Bm7b5', 60: 'Bo', 61: 'Bo7', 62: 'Bsus', 63: 'Bsus7', 64: 'C', 65: 'C+', 66: 'C+7', 67: 'C+j7', 68: 'C-', 69: 'C-6', 70: 'C-7', 71: 'C-j7', 72: 'C6', 73: 'C7', 74: 'Cj7', 75: 'Cm7b5', 76: 'Co', 77: 'Co7', 78: 'Csus', 79: 'Csus7', 80: 'D', 81: 'D+', 82: 'D+7', 83: 'D+j7', 84: 'D-', 85: 'D-6', 86: 'D-7', 87: 'D-j7', 88: 'D6', 89: 'D7', 90: 'Db', 91: 'Db+', 92: 'Db+7', 93: 'Db+j7', 94: 'Db-', 95: 'Db-6', 96: 'Db-7', 97: 'Db-j7', 98: 'Db6', 99: 'Db7', 100: 'Dbj7', 101: 'Dbm7b5', 102: 'Dbo', 103: 'Dbo7', 104: 'Dbsus', 105: 'Dbsus7', 106: 'Dj7', 107: 'Dm7b5', 108: 'Do', 109: 'Do7', 110: 'Dsus', 111: 'Dsus7', 112: 'E', 113: 'E+', 114: 'E+7', 115: 'E+j7', 116: 'E-', 117: 'E-6', 118: 'E-7', 119: 'E-j7', 120: 'E6', 121: 'E7', 122: 'Eb', 123: 'Eb+', 124: 'Eb+7', 125: 'Eb+j7', 126: 'Eb-', 127: 'Eb-6', 128: 'Eb-7', 129: 'Eb-j7', 130: 'Eb6', 131: 'Eb7', 132: 'Ebj7', 133: 'Ebm7b5', 134: 'Ebo', 135: 'Ebo7', 136: 'Ebsus', 137: 'Ebsus7', 138: 'Ej7', 139: 'Em7b5', 140: 'Eo', 141: 'Eo7', 142: 'Esus', 143: 'Esus7', 144: 'F', 145: 'F+', 146: 'F+7', 147: 'F+j7', 148: 'F-', 149: 'F-6', 150: 'F-7', 151: 'F-j7', 152: 'F6', 153: 'F7', 154: 'Fj7', 155: 'Fm7b5', 156: 'Fo', 157: 'Fo7', 158: 'Fsus', 159: 'Fsus7', 160: 'G', 161: 'G+', 162: 'G+7', 163: 'G+j7', 164: 'G-', 165: 'G-6', 166: 'G-7', 167: 'G-j7', 168: 'G6', 169: 'G7', 170: 'Gb', 171: 'Gb+', 172: 'Gb+7', 173: 'Gb+j7', 174: 'Gb-', 175: 'Gb-6', 176: 'Gb-7', 177: 'Gb-j7', 178: 'Gb6', 179: 'Gb7', 180: 'Gbj7', 181: 'Gbm7b5', 182: 'Gbo', 183: 'Gbo7', 184: 'Gbsus', 185: 'Gbsus7', 186: 'Gj7', 187: 'Gm7b5', 188: 'Go', 189: 'Go7', 190: 'Gsus', 191: 'Gsus7', 192: 'NC', 193: '<bos>', 194: '<eos>'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create categorical data mappings\n",
    "note_to_int = dict([(c, i) for i, c in enumerate(unique_notes[1:])])\n",
    "note_to_int[-1] = len(note_to_int)\n",
    "note_to_int['<pad>'] = len(note_to_int)\n",
    "\n",
    "int_to_note = dict([(k, v) for v, k in note_to_int.items()])\n",
    "\n",
    "chord_to_int = dict([(c, i) for i, c in enumerate(unique_chords)])\n",
    "chord_to_int['<bos>'] = len(chord_to_int)\n",
    "chord_to_int['<eos>'] = len(chord_to_int)\n",
    "\n",
    "int_to_chord = dict([(k, v) for v, k in chord_to_int.items()])\n",
    "\n",
    "print(\"Melody note to integer mapping:\\n {}\\n\".format(note_to_int))\n",
    "print(\"Integer to melody note mapping:\\n {}\\n\".format(int_to_note))\n",
    "print(\"Chord label to integer mapping:\\n {}\\n\".format(chord_to_int))\n",
    "print(\"Integer to chord label mapping:\\n {}\\n\".format(int_to_chord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 334344\n",
      "Number of distinct melody notes: 14\n",
      "Number of distinct chord labels: 195\n",
      "Maximum length of melody sequences for one chord: 135\n",
      "Number of past chords given as input: 7\n"
     ]
    }
   ],
   "source": [
    "# Define numerical variables\n",
    "\n",
    "n_samples = len(chords)\n",
    "n_chords = len(chord_to_int)\n",
    "n_notes = len(note_to_int)\n",
    "max_mel_len = max([len(mel) for mel in notes_by_chords_bf_augmaj7])\n",
    "chord_context_len = 7\n",
    "\n",
    "# print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Number of distinct melody notes: {}\".format(n_notes))\n",
    "print(\"Number of distinct chord labels: {}\".format(n_chords))\n",
    "print(\"Maximum length of melody sequences for one chord: {}\".format(max_mel_len))\n",
    "print(\"Number of past chords given as input: {}\".format(chord_context_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [4]]\n"
     ]
    }
   ],
   "source": [
    "mel_by_sections = [mel for section in data for ch, mel in section]\n",
    "print(mel_by_sections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Remove sections with augmented major chord---\n",
      "Number of sections: 28836\n",
      "\n",
      "Sample input melody sequence: [8, 3, 6, '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "\n",
      "Sample input chord sequence: ['<bos>', '<bos>', 'E6', 'Db7', 'Gb-7', 'B7', 'E']\n",
      "\n",
      "Sample target chord: Db-7\n",
      "\n",
      "Input melody: 333480, Input chords: 333480, Target chords: 333480\n"
     ]
    }
   ],
   "source": [
    "# Prepare tensor data\n",
    "\n",
    "\n",
    "def check_if_augmented_major(section):\n",
    "    section_chords = get_chords_by_section(section)\n",
    "    for ch in section_chords:\n",
    "        if \"+j7\" in ch:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "data = [section for section in data if not check_if_augmented_major(section)]\n",
    "print(\"---Remove sections with augmented major chord---\")\n",
    "print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections = [get_chords_by_section(section) for section in data]\n",
    "# chords = [chord_info[0] for section in data for chord_info in section]\n",
    "# unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "# notes = [note for chord_notes in notes_by_chords for note in chord_notes]\n",
    "# unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "\n",
    "\n",
    "def pad_melody(melody, max_len):\n",
    "    return melody + (max_len-len(melody))*['<pad>']\n",
    "\n",
    "def build_input_chord_sequences(chord_seq, context_len):\n",
    "    padded_sequence = context_len*['<bos>'] + chord_seq\n",
    "    formatted_sequences = [padded_sequence[i:i+context_len+1] for i in range(len(chord_seq))]\n",
    "    return formatted_sequences\n",
    "\n",
    "# Melody\n",
    "input_melody_data = [pad_melody(melody, max_mel_len) for melody in notes_by_chords]\n",
    "print(\"Sample input melody sequence: {}\\n\".format(input_melody_data[5]))\n",
    "\n",
    "# Chords\n",
    "formatted_chords_data = []\n",
    "for section_chords in chords_by_sections:\n",
    "    formatted_chords_data += build_input_chord_sequences(section_chords, chord_context_len)\n",
    "    \n",
    "input_chords_data = [ch[:-1] for ch in formatted_chords_data]\n",
    "target_chords_data = [ch[-1] for ch in formatted_chords_data]\n",
    "print(\"Sample input chord sequence: {}\\n\".format(input_chords_data[5]))\n",
    "print(\"Sample target chord: {}\\n\".format(target_chords_data[5]))\n",
    "\n",
    "print(\"Input melody: {}, Input chords: {}, Target chords: {}\".format(len(input_melody_data), len(input_chords_data), len(target_chords_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load embedding vectors\n",
    "\n",
    "num_dim = 32\n",
    "num_ch = 192\n",
    "num_notes = 12\n",
    "\n",
    "# Define embedding training model and load weights\n",
    "input_layer = Input(shape=(num_ch,)) \n",
    "embeddings_layer = Dense(num_dim, activation='linear', name=\"embeddings\")(input_layer)\n",
    "root_output_layer = Dense(num_notes, activation='softmax')(embeddings_layer)\n",
    "interval_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "pitch_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "melody_output_layer = Dense(num_notes, activation='relu')(embeddings_layer)\n",
    "embeddings_model = Model(input_layer, [root_output_layer, interval_output_layer, pitch_output_layer, melody_output_layer])\n",
    "\n",
    "embeddings_model.load_weights(\"../Skipgram & WJD/weights/combined_weights_dim32.h5\")\n",
    "\n",
    "X_chords_embeddings = embeddings_model.layers[1].get_weights()[0]\n",
    "print(X_chords_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embedding vector for each chord: 32\n"
     ]
    }
   ],
   "source": [
    "# Build tensors\n",
    "\n",
    "n_dimensions = X_chords_embeddings.shape[1]\n",
    "print(\"Size of embedding vector for each chord: {}\".format(n_dimensions))\n",
    "\n",
    "X_melody = np.zeros((n_samples, max_mel_len, n_notes), dtype='float32')\n",
    "X_chords = np.zeros((n_samples, chord_context_len, n_dimensions), dtype='float32')\n",
    "Y_chord = np.zeros((n_samples, n_chords), dtype='float32')\n",
    "\n",
    "for i, (input_mel, input_ch, target_ch) in enumerate(zip(input_melody_data, input_chords_data, target_chords_data)):\n",
    "    Y_chord[i, chord_to_int[target_ch]] = 1\n",
    "    for j, chord in enumerate(input_ch):\n",
    "#         X_chords[i, j, chord_to_int[chord]] = 1\n",
    "        chord_index = chord_to_int[chord]\n",
    "        if (chord_index < num_ch):\n",
    "            X_chords[i, j, :] = X_chords_embeddings[chord_index, :]\n",
    "    \n",
    "    for j, note in enumerate(input_mel):\n",
    "        X_melody[i, j, note_to_int[note]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334344, 135, 14)\n",
      "(334344, 7, 32)\n",
      "(334344, 195)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody.shape)\n",
    "print(X_chords.shape)\n",
    "print(Y_chord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset into 80%-10%-10% train-valid-test sets\n",
    "seed = 0\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "\n",
    "for train_index, aux_index in sss.split(X_chords, Y_chord):\n",
    "    X_melody_train, X_melody_aux = X_melody[train_index], X_melody[aux_index]\n",
    "    X_chords_train, X_chords_aux = X_chords[train_index], X_chords[aux_index]\n",
    "    Y_chord_train, Y_chord_aux = Y_chord[train_index], Y_chord[aux_index]\n",
    "    \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)\n",
    "\n",
    "for valid_index, test_index in sss.split(X_chords_aux, Y_chord_aux):\n",
    "    X_melody_valid, X_melody_test = X_melody[valid_index], X_melody[test_index]\n",
    "    X_chords_valid, X_chords_test = X_chords[valid_index], X_chords[test_index]\n",
    "    Y_chord_valid, Y_chord_test = Y_chord[valid_index], Y_chord[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 135, 14)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 7, 32)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_1 (GRU)                      (None, 135, 128)      54912       input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      (None, 7, 128)        61824       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_2 (GRU)                      (None, 135, 128)      98688       gru_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_5 (GRU)                      (None, 7, 128)        98688       gru_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_3 (GRU)                      (None, 128)           98688       gru_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_6 (GRU)                      (None, 128)           98688       gru_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 256)           0           gru_3[0][0]                      \n",
      "                                                                   gru_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 128)           32896       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 128)           16512       dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 195)           25155       dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 586,051\n",
      "Trainable params: 586,051\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define neual net architecture\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "melody_input = Input(shape=(max_mel_len, n_notes))\n",
    "melody_gru1 = GRU(latent_dim, return_sequences=True)(melody_input)\n",
    "melody_gru2 = GRU(latent_dim, return_sequences=True)(melody_gru1)\n",
    "melody_gru3 = GRU(latent_dim)(melody_gru2)\n",
    "\n",
    "chords_input = Input(shape=(chord_context_len, n_dimensions))\n",
    "chords_gru1 = GRU(latent_dim, return_sequences=True)(chords_input)\n",
    "chords_gru2 = GRU(latent_dim, return_sequences=True)(chords_gru1)\n",
    "chords_gru3 = GRU(latent_dim)(chords_gru2)\n",
    "\n",
    "concat = concatenate([melody_gru3, chords_gru3])\n",
    "\n",
    "chord_dense1 = Dense(latent_dim, activation='relu')(concat)\n",
    "chord_dense2 = Dense(latent_dim, activation='relu')(chord_dense1)\n",
    "chord_dense3 = Dense(n_chords, activation='softmax')(chord_dense2)\n",
    "\n",
    "model = Model([melody_input, chords_input], chord_dense3)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Introduce Best-Performance callbacks\n",
    "# es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "filepath = \"models/embeddings32-Mel3-Cho3-FC3_150ep.h5\"\n",
    "bp = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267475 samples, validate on 33434 samples\n",
      "Epoch 1/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.8630 - acc: 0.3458Epoch 00000: val_acc improved from -inf to 0.42899, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 496s - loss: 2.8625 - acc: 0.3459 - val_loss: 2.4460 - val_acc: 0.4290\n",
      "Epoch 2/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.1789 - acc: 0.4787Epoch 00001: val_acc improved from 0.42899 to 0.49967, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 497s - loss: 2.1788 - acc: 0.4787 - val_loss: 2.1536 - val_acc: 0.4997\n",
      "Epoch 3/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.8971 - acc: 0.5432Epoch 00002: val_acc improved from 0.49967 to 0.54295, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 495s - loss: 1.8970 - acc: 0.5432 - val_loss: 1.9742 - val_acc: 0.5430\n",
      "Epoch 4/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.6946 - acc: 0.5905Epoch 00003: val_acc improved from 0.54295 to 0.57504, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 488s - loss: 1.6943 - acc: 0.5906 - val_loss: 1.8421 - val_acc: 0.5750\n",
      "Epoch 5/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.5453 - acc: 0.6237Epoch 00004: val_acc improved from 0.57504 to 0.59042, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 490s - loss: 1.5453 - acc: 0.6237 - val_loss: 1.7791 - val_acc: 0.5904\n",
      "Epoch 6/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.4291 - acc: 0.6494Epoch 00005: val_acc improved from 0.59042 to 0.60941, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 490s - loss: 1.4291 - acc: 0.6494 - val_loss: 1.6928 - val_acc: 0.6094\n",
      "Epoch 7/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.3423 - acc: 0.6681Epoch 00006: val_acc improved from 0.60941 to 0.61692, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 490s - loss: 1.3426 - acc: 0.6680 - val_loss: 1.6499 - val_acc: 0.6169\n",
      "Epoch 8/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2766 - acc: 0.6821Epoch 00007: val_acc improved from 0.61692 to 0.63199, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 489s - loss: 1.2766 - acc: 0.6821 - val_loss: 1.6071 - val_acc: 0.6320\n",
      "Epoch 9/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2228 - acc: 0.6924Epoch 00008: val_acc improved from 0.63199 to 0.63800, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 489s - loss: 1.2229 - acc: 0.6924 - val_loss: 1.5875 - val_acc: 0.6380\n",
      "Epoch 10/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1799 - acc: 0.7019Epoch 00009: val_acc improved from 0.63800 to 0.64790, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 489s - loss: 1.1798 - acc: 0.7019 - val_loss: 1.5444 - val_acc: 0.6479\n",
      "Epoch 11/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1464 - acc: 0.7087Epoch 00010: val_acc improved from 0.64790 to 0.65242, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 489s - loss: 1.1462 - acc: 0.7087 - val_loss: 1.5281 - val_acc: 0.6524\n",
      "Epoch 12/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1171 - acc: 0.7145Epoch 00011: val_acc improved from 0.65242 to 0.66268, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 487s - loss: 1.1173 - acc: 0.7144 - val_loss: 1.5111 - val_acc: 0.6627\n",
      "Epoch 13/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0958 - acc: 0.7181Epoch 00012: val_acc did not improve\n",
      "267475/267475 [==============================] - 485s - loss: 1.0957 - acc: 0.7181 - val_loss: 1.5077 - val_acc: 0.6607\n",
      "Epoch 14/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0753 - acc: 0.7222Epoch 00013: val_acc improved from 0.66268 to 0.66483, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 486s - loss: 1.0754 - acc: 0.7222 - val_loss: 1.4880 - val_acc: 0.6648\n",
      "Epoch 15/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0573 - acc: 0.7254Epoch 00014: val_acc improved from 0.66483 to 0.67285, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 487s - loss: 1.0573 - acc: 0.7254 - val_loss: 1.4780 - val_acc: 0.6728\n",
      "Epoch 16/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0450 - acc: 0.7271Epoch 00015: val_acc did not improve\n",
      "267475/267475 [==============================] - 486s - loss: 1.0451 - acc: 0.7270 - val_loss: 1.4727 - val_acc: 0.6712\n",
      "Epoch 17/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0323 - acc: 0.7301Epoch 00016: val_acc did not improve\n",
      "267475/267475 [==============================] - 487s - loss: 1.0324 - acc: 0.7300 - val_loss: 1.4619 - val_acc: 0.6725\n",
      "Epoch 18/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0222 - acc: 0.7325Epoch 00017: val_acc improved from 0.67285 to 0.67294, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 487s - loss: 1.0222 - acc: 0.7324 - val_loss: 1.4603 - val_acc: 0.6729\n",
      "Epoch 19/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0132 - acc: 0.7332Epoch 00018: val_acc improved from 0.67294 to 0.67638, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 486s - loss: 1.0133 - acc: 0.7332 - val_loss: 1.4630 - val_acc: 0.6764\n",
      "Epoch 20/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0033 - acc: 0.7358Epoch 00019: val_acc did not improve\n",
      "267475/267475 [==============================] - 487s - loss: 1.0033 - acc: 0.7358 - val_loss: 1.4611 - val_acc: 0.6749\n",
      "Epoch 21/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9971 - acc: 0.7367Epoch 00020: val_acc improved from 0.67638 to 0.68104, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 487s - loss: 0.9970 - acc: 0.7367 - val_loss: 1.4537 - val_acc: 0.6810\n",
      "Epoch 22/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9916 - acc: 0.7378Epoch 00021: val_acc improved from 0.68104 to 0.68604, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 487s - loss: 0.9915 - acc: 0.7378 - val_loss: 1.4431 - val_acc: 0.6860\n",
      "Epoch 23/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9841 - acc: 0.7385Epoch 00022: val_acc did not improve\n",
      "267475/267475 [==============================] - 488s - loss: 0.9841 - acc: 0.7385 - val_loss: 1.4421 - val_acc: 0.6836\n",
      "Epoch 24/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9800 - acc: 0.7392Epoch 00023: val_acc did not improve\n",
      "267475/267475 [==============================] - 488s - loss: 0.9800 - acc: 0.7392 - val_loss: 1.4407 - val_acc: 0.6834\n",
      "Epoch 25/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9717 - acc: 0.7408Epoch 00024: val_acc did not improve\n",
      "267475/267475 [==============================] - 489s - loss: 0.9717 - acc: 0.7407 - val_loss: 1.4371 - val_acc: 0.6834\n",
      "Epoch 26/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9712 - acc: 0.7413Epoch 00025: val_acc did not improve\n",
      "267475/267475 [==============================] - 489s - loss: 0.9711 - acc: 0.7413 - val_loss: 1.4567 - val_acc: 0.6817\n",
      "Epoch 27/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9681 - acc: 0.7411Epoch 00026: val_acc improved from 0.68604 to 0.68819, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 478s - loss: 0.9681 - acc: 0.7411 - val_loss: 1.4428 - val_acc: 0.6882\n",
      "Epoch 28/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9635 - acc: 0.7420Epoch 00027: val_acc did not improve\n",
      "267475/267475 [==============================] - 478s - loss: 0.9634 - acc: 0.7421 - val_loss: 1.4526 - val_acc: 0.6820\n",
      "Epoch 29/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9592 - acc: 0.7429Epoch 00028: val_acc improved from 0.68819 to 0.68831, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 479s - loss: 0.9592 - acc: 0.7429 - val_loss: 1.4389 - val_acc: 0.6883\n",
      "Epoch 30/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9583 - acc: 0.7426Epoch 00029: val_acc improved from 0.68831 to 0.68903, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 479s - loss: 0.9584 - acc: 0.7426 - val_loss: 1.4340 - val_acc: 0.6890\n",
      "Epoch 31/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9558 - acc: 0.7434Epoch 00030: val_acc improved from 0.68903 to 0.68978, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 478s - loss: 0.9558 - acc: 0.7434 - val_loss: 1.4289 - val_acc: 0.6898\n",
      "Epoch 32/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9510 - acc: 0.7452Epoch 00031: val_acc did not improve\n",
      "267475/267475 [==============================] - 479s - loss: 0.9511 - acc: 0.7452 - val_loss: 1.4451 - val_acc: 0.6885\n",
      "Epoch 33/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9507 - acc: 0.7444Epoch 00032: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.9508 - acc: 0.7444 - val_loss: 1.4491 - val_acc: 0.6857\n",
      "Epoch 34/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9470 - acc: 0.7454Epoch 00033: val_acc did not improve\n",
      "267475/267475 [==============================] - 479s - loss: 0.9470 - acc: 0.7454 - val_loss: 1.4507 - val_acc: 0.6891\n",
      "Epoch 35/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9452 - acc: 0.7457Epoch 00034: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.9452 - acc: 0.7457 - val_loss: 1.4372 - val_acc: 0.6883\n",
      "Epoch 36/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9494 - acc: 0.7446Epoch 00035: val_acc improved from 0.68978 to 0.69064, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 480s - loss: 0.9495 - acc: 0.7446 - val_loss: 1.4342 - val_acc: 0.6906\n",
      "Epoch 37/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9429 - acc: 0.7454Epoch 00036: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.9428 - acc: 0.7454 - val_loss: 1.4432 - val_acc: 0.6879\n",
      "Epoch 38/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9287 - acc: 0.7483Epoch 00037: val_acc improved from 0.69064 to 0.69367, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 480s - loss: 0.9286 - acc: 0.7483 - val_loss: 1.4074 - val_acc: 0.6937\n",
      "Epoch 39/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9040 - acc: 0.7510Epoch 00038: val_acc improved from 0.69367 to 0.69585, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 481s - loss: 0.9039 - acc: 0.7510 - val_loss: 1.3880 - val_acc: 0.6958\n",
      "Epoch 40/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8820 - acc: 0.7541Epoch 00039: val_acc improved from 0.69585 to 0.69779, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 481s - loss: 0.8821 - acc: 0.7541 - val_loss: 1.3771 - val_acc: 0.6978\n",
      "Epoch 41/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8664 - acc: 0.7574Epoch 00040: val_acc improved from 0.69779 to 0.69902, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 481s - loss: 0.8665 - acc: 0.7574 - val_loss: 1.3724 - val_acc: 0.6990\n",
      "Epoch 42/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8542 - acc: 0.7603Epoch 00041: val_acc improved from 0.69902 to 0.70458, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 477s - loss: 0.8544 - acc: 0.7603 - val_loss: 1.3610 - val_acc: 0.7046\n",
      "Epoch 43/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8346 - acc: 0.7659Epoch 00042: val_acc improved from 0.70458 to 0.70512, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 477s - loss: 0.8347 - acc: 0.7659 - val_loss: 1.3486 - val_acc: 0.7051\n",
      "Epoch 44/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8236 - acc: 0.7679Epoch 00043: val_acc improved from 0.70512 to 0.70665, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 478s - loss: 0.8235 - acc: 0.7679 - val_loss: 1.3545 - val_acc: 0.7066\n",
      "Epoch 45/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8102 - acc: 0.7711Epoch 00044: val_acc improved from 0.70665 to 0.70886, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 478s - loss: 0.8101 - acc: 0.7711 - val_loss: 1.3435 - val_acc: 0.7089\n",
      "Epoch 46/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7946 - acc: 0.7760Epoch 00045: val_acc improved from 0.70886 to 0.71003, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 479s - loss: 0.7946 - acc: 0.7760 - val_loss: 1.3486 - val_acc: 0.7100\n",
      "Epoch 47/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7873 - acc: 0.7774Epoch 00046: val_acc did not improve\n",
      "267475/267475 [==============================] - 479s - loss: 0.7873 - acc: 0.7773 - val_loss: 1.3628 - val_acc: 0.7073\n",
      "Epoch 48/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7876 - acc: 0.7773Epoch 00047: val_acc did not improve\n",
      "267475/267475 [==============================] - 479s - loss: 0.7876 - acc: 0.7773 - val_loss: 1.3441 - val_acc: 0.7081\n",
      "Epoch 49/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7773 - acc: 0.7800Epoch 00048: val_acc improved from 0.71003 to 0.71382, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 479s - loss: 0.7774 - acc: 0.7800 - val_loss: 1.3466 - val_acc: 0.7138\n",
      "Epoch 50/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7726 - acc: 0.7806Epoch 00049: val_acc improved from 0.71382 to 0.71750, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 479s - loss: 0.7729 - acc: 0.7805 - val_loss: 1.3320 - val_acc: 0.7175\n",
      "Epoch 51/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7670 - acc: 0.7824Epoch 00050: val_acc did not improve\n",
      "267475/267475 [==============================] - 479s - loss: 0.7671 - acc: 0.7824 - val_loss: 1.4331 - val_acc: 0.6948\n",
      "Epoch 52/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7981 - acc: 0.7742Epoch 00051: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.7981 - acc: 0.7742 - val_loss: 1.3416 - val_acc: 0.7148\n",
      "Epoch 53/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7571 - acc: 0.7847Epoch 00052: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.7573 - acc: 0.7847 - val_loss: 1.3681 - val_acc: 0.7124\n",
      "Epoch 54/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9339 - acc: 0.7457Epoch 00053: val_acc did not improve\n",
      "267475/267475 [==============================] - 481s - loss: 0.9339 - acc: 0.7457 - val_loss: 1.4744 - val_acc: 0.6860\n",
      "Epoch 55/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9315 - acc: 0.7463Epoch 00054: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.9314 - acc: 0.7464 - val_loss: 1.4396 - val_acc: 0.6942\n",
      "Epoch 56/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9114 - acc: 0.7501Epoch 00055: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.9115 - acc: 0.7501 - val_loss: 1.4381 - val_acc: 0.6918\n",
      "Epoch 57/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9026 - acc: 0.7529Epoch 00056: val_acc did not improve\n",
      "267475/267475 [==============================] - 478s - loss: 0.9024 - acc: 0.7530 - val_loss: 1.4271 - val_acc: 0.6979\n",
      "Epoch 58/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8915 - acc: 0.7545Epoch 00057: val_acc did not improve\n",
      "267475/267475 [==============================] - 479s - loss: 0.8917 - acc: 0.7544 - val_loss: 1.4173 - val_acc: 0.6970\n",
      "Epoch 59/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8784 - acc: 0.7566Epoch 00058: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.8783 - acc: 0.7566 - val_loss: 1.4152 - val_acc: 0.6974\n",
      "Epoch 60/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8657 - acc: 0.7607Epoch 00059: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.8657 - acc: 0.7607 - val_loss: 1.4253 - val_acc: 0.6969\n",
      "Epoch 61/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8497 - acc: 0.7642Epoch 00060: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.8496 - acc: 0.7642 - val_loss: 1.3837 - val_acc: 0.7058\n",
      "Epoch 62/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8372 - acc: 0.7667Epoch 00061: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.8372 - acc: 0.7667 - val_loss: 1.3793 - val_acc: 0.7030\n",
      "Epoch 63/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8249 - acc: 0.7689Epoch 00062: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.8249 - acc: 0.7689 - val_loss: 1.3755 - val_acc: 0.7094\n",
      "Epoch 64/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8121 - acc: 0.7720Epoch 00063: val_acc did not improve\n",
      "267475/267475 [==============================] - 481s - loss: 0.8121 - acc: 0.7720 - val_loss: 1.3565 - val_acc: 0.7117\n",
      "Epoch 65/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8113 - acc: 0.7723Epoch 00064: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.8112 - acc: 0.7723 - val_loss: 1.3984 - val_acc: 0.7043\n",
      "Epoch 66/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8120 - acc: 0.7727Epoch 00065: val_acc did not improve\n",
      "267475/267475 [==============================] - 481s - loss: 0.8120 - acc: 0.7727 - val_loss: 1.3478 - val_acc: 0.7127\n",
      "Epoch 67/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7973 - acc: 0.7757Epoch 00066: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.7973 - acc: 0.7757 - val_loss: 1.3795 - val_acc: 0.7061\n",
      "Epoch 68/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7909 - acc: 0.7775Epoch 00067: val_acc did not improve\n",
      "267475/267475 [==============================] - 481s - loss: 0.7910 - acc: 0.7775 - val_loss: 1.3591 - val_acc: 0.7155\n",
      "Epoch 69/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7733 - acc: 0.7808Epoch 00068: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.7732 - acc: 0.7808 - val_loss: 1.3322 - val_acc: 0.7160\n",
      "Epoch 70/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7736 - acc: 0.7809Epoch 00069: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.7737 - acc: 0.7809 - val_loss: 1.3676 - val_acc: 0.7134\n",
      "Epoch 71/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7679 - acc: 0.7831Epoch 00070: val_acc improved from 0.71750 to 0.71849, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 480s - loss: 0.7678 - acc: 0.7831 - val_loss: 1.3350 - val_acc: 0.7185\n",
      "Epoch 72/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7422 - acc: 0.7886Epoch 00071: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.7422 - acc: 0.7886 - val_loss: 1.3503 - val_acc: 0.7173\n",
      "Epoch 73/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9259 - acc: 0.7457Epoch 00072: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.9259 - acc: 0.7457 - val_loss: 1.4697 - val_acc: 0.6888\n",
      "Epoch 74/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8776 - acc: 0.7566Epoch 00073: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.8776 - acc: 0.7566 - val_loss: 1.4016 - val_acc: 0.7051\n",
      "Epoch 75/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8453 - acc: 0.7643Epoch 00074: val_acc did not improve\n",
      "267475/267475 [==============================] - 480s - loss: 0.8453 - acc: 0.7643 - val_loss: 1.4107 - val_acc: 0.7040\n",
      "Epoch 76/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8280 - acc: 0.7679Epoch 00075: val_acc did not improve\n",
      "267475/267475 [==============================] - 481s - loss: 0.8281 - acc: 0.7679 - val_loss: 1.3778 - val_acc: 0.7072\n",
      "Epoch 77/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8122 - acc: 0.7714Epoch 00076: val_acc did not improve\n",
      "267475/267475 [==============================] - 481s - loss: 0.8121 - acc: 0.7714 - val_loss: 1.3777 - val_acc: 0.7106\n",
      "Epoch 78/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9154 - acc: 0.7489Epoch 00077: val_acc did not improve\n",
      "267475/267475 [==============================] - 481s - loss: 0.9154 - acc: 0.7489 - val_loss: 1.4494 - val_acc: 0.6917\n",
      "Epoch 79/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8861 - acc: 0.7550Epoch 00078: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.8862 - acc: 0.7550 - val_loss: 1.4373 - val_acc: 0.6969\n",
      "Epoch 80/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8930 - acc: 0.7544Epoch 00079: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.8929 - acc: 0.7544 - val_loss: 1.4567 - val_acc: 0.6941\n",
      "Epoch 81/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8791 - acc: 0.7576Epoch 00080: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.8793 - acc: 0.7575 - val_loss: 1.4378 - val_acc: 0.6980\n",
      "Epoch 82/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8580 - acc: 0.7617Epoch 00081: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.8581 - acc: 0.7617 - val_loss: 1.4168 - val_acc: 0.7011\n",
      "Epoch 83/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8381 - acc: 0.7665Epoch 00082: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.8381 - acc: 0.7665 - val_loss: 1.3952 - val_acc: 0.7037\n",
      "Epoch 84/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8187 - acc: 0.7705Epoch 00083: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.8188 - acc: 0.7704 - val_loss: 1.3743 - val_acc: 0.7122\n",
      "Epoch 85/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8481 - acc: 0.7633Epoch 00084: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.8481 - acc: 0.7633 - val_loss: 1.3890 - val_acc: 0.7073\n",
      "Epoch 86/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8154 - acc: 0.7714Epoch 00085: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 481s - loss: 0.8154 - acc: 0.7713 - val_loss: 1.3897 - val_acc: 0.7092\n",
      "Epoch 87/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8631 - acc: 0.7596Epoch 00086: val_acc did not improve\n",
      "267475/267475 [==============================] - 481s - loss: 0.8630 - acc: 0.7596 - val_loss: 1.4159 - val_acc: 0.7025\n",
      "Epoch 88/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8321 - acc: 0.7675Epoch 00087: val_acc did not improve\n",
      "267475/267475 [==============================] - 481s - loss: 0.8321 - acc: 0.7675 - val_loss: 1.3859 - val_acc: 0.7069\n",
      "Epoch 89/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8152 - acc: 0.7707Epoch 00088: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.8150 - acc: 0.7708 - val_loss: 1.3817 - val_acc: 0.7098\n",
      "Epoch 90/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7994 - acc: 0.7751Epoch 00089: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.7994 - acc: 0.7751 - val_loss: 1.3769 - val_acc: 0.7133\n",
      "Epoch 91/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7897 - acc: 0.7766Epoch 00090: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.7897 - acc: 0.7766 - val_loss: 1.3769 - val_acc: 0.7120\n",
      "Epoch 92/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7833 - acc: 0.7780Epoch 00091: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.7833 - acc: 0.7780 - val_loss: 1.3762 - val_acc: 0.7109\n",
      "Epoch 93/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7670 - acc: 0.7816Epoch 00092: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.7670 - acc: 0.7816 - val_loss: 1.3607 - val_acc: 0.7149\n",
      "Epoch 94/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7851 - acc: 0.7777Epoch 00093: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.7851 - acc: 0.7777 - val_loss: 1.3944 - val_acc: 0.7057\n",
      "Epoch 95/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7717 - acc: 0.7811Epoch 00094: val_acc improved from 0.71849 to 0.71924, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 483s - loss: 0.7717 - acc: 0.7811 - val_loss: 1.3510 - val_acc: 0.7192\n",
      "Epoch 96/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7518 - acc: 0.7850Epoch 00095: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.7518 - acc: 0.7850 - val_loss: 1.3433 - val_acc: 0.7177\n",
      "Epoch 97/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7607 - acc: 0.7832Epoch 00096: val_acc did not improve\n",
      "267475/267475 [==============================] - 484s - loss: 0.7606 - acc: 0.7832 - val_loss: 1.3486 - val_acc: 0.7189\n",
      "Epoch 98/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7347 - acc: 0.7896Epoch 00097: val_acc improved from 0.71924 to 0.71939, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 484s - loss: 0.7347 - acc: 0.7896 - val_loss: 1.3449 - val_acc: 0.7194\n",
      "Epoch 99/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7357 - acc: 0.7887Epoch 00098: val_acc improved from 0.71939 to 0.72070, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 483s - loss: 0.7358 - acc: 0.7887 - val_loss: 1.3515 - val_acc: 0.7207\n",
      "Epoch 100/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7227 - acc: 0.7928Epoch 00099: val_acc improved from 0.72070 to 0.72420, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 483s - loss: 0.7229 - acc: 0.7928 - val_loss: 1.3293 - val_acc: 0.7242\n",
      "Epoch 101/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7178 - acc: 0.7940Epoch 00100: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.7178 - acc: 0.7940 - val_loss: 1.3351 - val_acc: 0.7237\n",
      "Epoch 102/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7176 - acc: 0.7952Epoch 00101: val_acc improved from 0.72420 to 0.72462, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 482s - loss: 0.7175 - acc: 0.7952 - val_loss: 1.3357 - val_acc: 0.7246\n",
      "Epoch 103/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7045 - acc: 0.7973Epoch 00102: val_acc did not improve\n",
      "267475/267475 [==============================] - 481s - loss: 0.7045 - acc: 0.7973 - val_loss: 1.3512 - val_acc: 0.7211\n",
      "Epoch 104/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7107 - acc: 0.7953Epoch 00103: val_acc improved from 0.72462 to 0.72495, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 481s - loss: 0.7108 - acc: 0.7953 - val_loss: 1.3465 - val_acc: 0.7250\n",
      "Epoch 105/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.7997Epoch 00104: val_acc improved from 0.72495 to 0.72956, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 482s - loss: 0.6941 - acc: 0.7997 - val_loss: 1.3258 - val_acc: 0.7296\n",
      "Epoch 106/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6896 - acc: 0.8017Epoch 00105: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.6897 - acc: 0.8017 - val_loss: 1.3614 - val_acc: 0.7221\n",
      "Epoch 107/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6757 - acc: 0.8041Epoch 00106: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.6757 - acc: 0.8042 - val_loss: 1.3419 - val_acc: 0.7278\n",
      "Epoch 108/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7694 - acc: 0.7809Epoch 00107: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.7694 - acc: 0.7809 - val_loss: 1.3792 - val_acc: 0.7163\n",
      "Epoch 109/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7483 - acc: 0.7861Epoch 00108: val_acc did not improve\n",
      "267475/267475 [==============================] - 484s - loss: 0.7483 - acc: 0.7861 - val_loss: 1.3480 - val_acc: 0.7195\n",
      "Epoch 110/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7394 - acc: 0.7883Epoch 00109: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.7394 - acc: 0.7883 - val_loss: 1.3450 - val_acc: 0.7224\n",
      "Epoch 111/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7143 - acc: 0.7949Epoch 00110: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.7144 - acc: 0.7948 - val_loss: 1.3543 - val_acc: 0.7225\n",
      "Epoch 112/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7029 - acc: 0.7971Epoch 00111: val_acc did not improve\n",
      "267475/267475 [==============================] - 484s - loss: 0.7029 - acc: 0.7971 - val_loss: 1.3428 - val_acc: 0.7263\n",
      "Epoch 113/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6886 - acc: 0.8017Epoch 00112: val_acc did not improve\n",
      "267475/267475 [==============================] - 485s - loss: 0.6886 - acc: 0.8017 - val_loss: 1.3588 - val_acc: 0.7229\n",
      "Epoch 114/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6858 - acc: 0.8022Epoch 00113: val_acc did not improve\n",
      "267475/267475 [==============================] - 484s - loss: 0.6857 - acc: 0.8022 - val_loss: 1.3420 - val_acc: 0.7274\n",
      "Epoch 115/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6769 - acc: 0.8039Epoch 00114: val_acc improved from 0.72956 to 0.73117, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 484s - loss: 0.6769 - acc: 0.8039 - val_loss: 1.3253 - val_acc: 0.7312\n",
      "Epoch 116/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6695 - acc: 0.8058Epoch 00115: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.6695 - acc: 0.8058 - val_loss: 1.3442 - val_acc: 0.7282\n",
      "Epoch 117/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6628 - acc: 0.8082Epoch 00116: val_acc improved from 0.73117 to 0.73306, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 483s - loss: 0.6628 - acc: 0.8082 - val_loss: 1.3471 - val_acc: 0.7331\n",
      "Epoch 118/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6653 - acc: 0.8069Epoch 00117: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.6653 - acc: 0.8069 - val_loss: 1.3680 - val_acc: 0.7247\n",
      "Epoch 119/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.8121Epoch 00118: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.6461 - acc: 0.8121 - val_loss: 1.3448 - val_acc: 0.7310\n",
      "Epoch 120/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6604 - acc: 0.8090Epoch 00119: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.6606 - acc: 0.8090 - val_loss: 1.3793 - val_acc: 0.7244\n",
      "Epoch 121/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6677 - acc: 0.8065Epoch 00120: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.6677 - acc: 0.8065 - val_loss: 1.3533 - val_acc: 0.7305\n",
      "Epoch 122/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6490 - acc: 0.8121Epoch 00121: val_acc did not improve\n",
      "267475/267475 [==============================] - 484s - loss: 0.6490 - acc: 0.8121 - val_loss: 1.3604 - val_acc: 0.7303\n",
      "Epoch 123/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6275 - acc: 0.8174Epoch 00122: val_acc improved from 0.73306 to 0.73542, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 484s - loss: 0.6274 - acc: 0.8174 - val_loss: 1.3600 - val_acc: 0.7354\n",
      "Epoch 124/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6244 - acc: 0.8181Epoch 00123: val_acc did not improve\n",
      "267475/267475 [==============================] - 484s - loss: 0.6244 - acc: 0.8181 - val_loss: 1.3746 - val_acc: 0.7273\n",
      "Epoch 125/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6431 - acc: 0.8127Epoch 00124: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.6431 - acc: 0.8127 - val_loss: 1.3707 - val_acc: 0.7325\n",
      "Epoch 126/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6068 - acc: 0.8236Epoch 00125: val_acc improved from 0.73542 to 0.73578, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 483s - loss: 0.6068 - acc: 0.8237 - val_loss: 1.3618 - val_acc: 0.7358\n",
      "Epoch 127/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6047 - acc: 0.8237Epoch 00126: val_acc improved from 0.73578 to 0.73671, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 483s - loss: 0.6047 - acc: 0.8237 - val_loss: 1.3451 - val_acc: 0.7367\n",
      "Epoch 128/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6110 - acc: 0.8225Epoch 00127: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.6112 - acc: 0.8225 - val_loss: 1.3607 - val_acc: 0.7357\n",
      "Epoch 129/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6039 - acc: 0.8242Epoch 00128: val_acc improved from 0.73671 to 0.73823, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 485s - loss: 0.6040 - acc: 0.8242 - val_loss: 1.3641 - val_acc: 0.7382\n",
      "Epoch 130/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5775 - acc: 0.8310Epoch 00129: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.5775 - acc: 0.8310 - val_loss: 1.3634 - val_acc: 0.7358\n",
      "Epoch 131/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5835 - acc: 0.8298Epoch 00130: val_acc did not improve\n",
      "267475/267475 [==============================] - 482s - loss: 0.5837 - acc: 0.8297 - val_loss: 1.3850 - val_acc: 0.7349\n",
      "Epoch 132/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5922 - acc: 0.8274Epoch 00131: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.5924 - acc: 0.8273 - val_loss: 1.4026 - val_acc: 0.7311\n",
      "Epoch 133/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5697 - acc: 0.8327Epoch 00132: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.5697 - acc: 0.8326 - val_loss: 1.3655 - val_acc: 0.7372\n",
      "Epoch 134/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5700 - acc: 0.8333Epoch 00133: val_acc improved from 0.73823 to 0.74257, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 483s - loss: 0.5700 - acc: 0.8333 - val_loss: 1.3682 - val_acc: 0.7426\n",
      "Epoch 135/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5495 - acc: 0.8391Epoch 00134: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.5495 - acc: 0.8391 - val_loss: 1.3787 - val_acc: 0.7382\n",
      "Epoch 136/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5409 - acc: 0.8411Epoch 00135: val_acc did not improve\n",
      "267475/267475 [==============================] - 483s - loss: 0.5411 - acc: 0.8411 - val_loss: 1.3526 - val_acc: 0.7423\n",
      "Epoch 137/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5373 - acc: 0.8427Epoch 00136: val_acc improved from 0.74257 to 0.74340, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 483s - loss: 0.5373 - acc: 0.8427 - val_loss: 1.3841 - val_acc: 0.7434\n",
      "Epoch 138/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5325 - acc: 0.8435Epoch 00137: val_acc did not improve\n",
      "267475/267475 [==============================] - 484s - loss: 0.5326 - acc: 0.8434 - val_loss: 1.3950 - val_acc: 0.7426\n",
      "Epoch 139/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5188 - acc: 0.8476Epoch 00138: val_acc improved from 0.74340 to 0.74484, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 485s - loss: 0.5188 - acc: 0.8476 - val_loss: 1.3993 - val_acc: 0.7448\n",
      "Epoch 140/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.8470Epoch 00139: val_acc did not improve\n",
      "267475/267475 [==============================] - 485s - loss: 0.5203 - acc: 0.8471 - val_loss: 1.4018 - val_acc: 0.7416\n",
      "Epoch 141/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5131 - acc: 0.8495Epoch 00140: val_acc did not improve\n",
      "267475/267475 [==============================] - 486s - loss: 0.5130 - acc: 0.8495 - val_loss: 1.4033 - val_acc: 0.7432\n",
      "Epoch 142/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6173 - acc: 0.8222Epoch 00141: val_acc did not improve\n",
      "267475/267475 [==============================] - 485s - loss: 0.6174 - acc: 0.8222 - val_loss: 1.4043 - val_acc: 0.7304\n",
      "Epoch 143/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5672 - acc: 0.8336Epoch 00142: val_acc did not improve\n",
      "267475/267475 [==============================] - 486s - loss: 0.5672 - acc: 0.8336 - val_loss: 1.3780 - val_acc: 0.7407\n",
      "Epoch 144/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5291 - acc: 0.8453Epoch 00143: val_acc did not improve\n",
      "267475/267475 [==============================] - 485s - loss: 0.5291 - acc: 0.8452 - val_loss: 1.3950 - val_acc: 0.7425\n",
      "Epoch 145/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5214 - acc: 0.8469Epoch 00144: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 484s - loss: 0.5214 - acc: 0.8469 - val_loss: 1.4060 - val_acc: 0.7416\n",
      "Epoch 146/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5047 - acc: 0.8520Epoch 00145: val_acc improved from 0.74484 to 0.74490, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 483s - loss: 0.5047 - acc: 0.8520 - val_loss: 1.3869 - val_acc: 0.7449\n",
      "Epoch 147/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4943 - acc: 0.8543Epoch 00146: val_acc improved from 0.74490 to 0.74975, saving model to models/embeddings32-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 484s - loss: 0.4944 - acc: 0.8543 - val_loss: 1.4027 - val_acc: 0.7497\n",
      "Epoch 148/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5088 - acc: 0.8501Epoch 00147: val_acc did not improve\n",
      "267475/267475 [==============================] - 484s - loss: 0.5088 - acc: 0.8501 - val_loss: 1.4253 - val_acc: 0.7422\n",
      "Epoch 149/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4912 - acc: 0.8551Epoch 00148: val_acc did not improve\n",
      "267475/267475 [==============================] - 484s - loss: 0.4913 - acc: 0.8550 - val_loss: 1.3986 - val_acc: 0.7482\n",
      "Epoch 150/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4906 - acc: 0.8556Epoch 00149: val_acc did not improve\n",
      "267475/267475 [==============================] - 484s - loss: 0.4906 - acc: 0.8556 - val_loss: 1.4256 - val_acc: 0.7432\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 256\n",
    "epochs = 150\n",
    "\n",
    "history = model.fit([X_melody_train, X_chords_train], Y_chord_train, epochs=epochs, validation_data=([X_melody_valid, X_chords_valid], Y_chord_valid), batch_size=batch_size, callbacks=[bp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd88d227438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFkCAYAAADWs8tQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIitd7/Bxbb6Eu1SniYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd88d227c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize model learning\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Training history of root model\", fontsize=16)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load best performance model\n",
    "best_model = load_model(\"models/embeddings32-Mel3-Cho3-FC3_150ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33435, 135, 14)\n",
      "(33435, 7, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody_test.shape)\n",
    "print(X_chords_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord prediction: 0.7384\n",
      "Kappa score of combined chord prediction: 0.7319\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of labels\n",
    "\n",
    "# Predict chords from each test sample melody\n",
    "Y_chord_pred = model.predict([X_melody_test, X_chords_test])\n",
    "\n",
    "# Compute accuracy and kappa score \n",
    "print(\"Categorical accuracy of combined chord prediction: {0:.4f}\".format(harmoutil.compute_accuracy_score(Y_chord_test, Y_chord_pred)))\n",
    "print(\"Kappa score of combined chord prediction: {0:.4f}\".format(harmoutil.compute_kappa_score(Y_chord_test, Y_chord_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord pitch prediction: 0.9093\n",
      "TP: 112218 TN: 252598 FP: 18169 FN: 18235\n",
      "Kappa score of combined chord pitch prediction: 0.7932\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of pitches\n",
    "\n",
    "def label_to_pitch_tensors(predictions):\n",
    "    predicted_chords = [int_to_chord[np.argmax(ch)] for ch in predictions]\n",
    "    pitch_chords = [harmoutil.chord_to_notes(label) for label in predicted_chords]\n",
    "    \n",
    "    Y_pitches = np.zeros((predictions.shape[0], 12), dtype='float32')\n",
    "    for i, chord_pitches in enumerate(pitch_chords):\n",
    "        for j, pitch_presence in enumerate(chord_pitches):\n",
    "            Y_pitches[i, j] = pitch_presence\n",
    "\n",
    "    return Y_pitches\n",
    "\n",
    "Y_pitch_pred = label_to_pitch_tensors(Y_chord_pred)\n",
    "Y_pitch_test = label_to_pitch_tensors(Y_chord_test)\n",
    "\n",
    "print(\"Categorical accuracy of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_accuracy_score(Y_pitch_test, Y_pitch_pred)))\n",
    "print(\"Kappa score of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_kappa_score(Y_pitch_test, Y_pitch_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
