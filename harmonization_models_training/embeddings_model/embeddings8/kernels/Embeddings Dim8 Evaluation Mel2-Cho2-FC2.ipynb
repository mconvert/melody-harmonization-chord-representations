{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/.local/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, GRU, concatenate\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# Custom library for the project\n",
    "import sys\n",
    "sys.path.insert(0, '../../src')\n",
    "import harmoutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'harmoutil' from '../../src/harmoutil.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Remove when done with kernel\n",
    "import importlib\n",
    "importlib.reload(harmoutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = harmoutil.load_pickled_data(\"../../data/refined_data.pkl\") # lists of (chord label, melody seqs) by sections\n",
    "augmented_data = harmoutil.transpose_and_augment_data(raw_data)\n",
    "data = [harmoutil.to_sevenths(section) for section in augmented_data]\n",
    "data = [harmoutil.melody_to_octave_range(section) for section in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chords: 334344 | Sample chord: E6\n",
      "Number of melody notes in the data: 2209944 | Sample melody note: 4\n",
      "Unique notes: [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Unique notes: ['A', 'A+', 'A+7', 'A+j7', 'A-', 'A-6', 'A-7', 'A-j7', 'A6', 'A7', 'Ab', 'Ab+', 'Ab+7', 'Ab+j7', 'Ab-', 'Ab-6', 'Ab-7', 'Ab-j7', 'Ab6', 'Ab7', 'Abj7', 'Abm7b5', 'Abo', 'Abo7', 'Absus', 'Absus7', 'Aj7', 'Am7b5', 'Ao', 'Ao7', 'Asus', 'Asus7', 'B', 'B+', 'B+7', 'B+j7', 'B-', 'B-6', 'B-7', 'B-j7', 'B6', 'B7', 'Bb', 'Bb+', 'Bb+7', 'Bb+j7', 'Bb-', 'Bb-6', 'Bb-7', 'Bb-j7', 'Bb6', 'Bb7', 'Bbj7', 'Bbm7b5', 'Bbo', 'Bbo7', 'Bbsus', 'Bbsus7', 'Bj7', 'Bm7b5', 'Bo', 'Bo7', 'Bsus', 'Bsus7', 'C', 'C+', 'C+7', 'C+j7', 'C-', 'C-6', 'C-7', 'C-j7', 'C6', 'C7', 'Cj7', 'Cm7b5', 'Co', 'Co7', 'Csus', 'Csus7', 'D', 'D+', 'D+7', 'D+j7', 'D-', 'D-6', 'D-7', 'D-j7', 'D6', 'D7', 'Db', 'Db+', 'Db+7', 'Db+j7', 'Db-', 'Db-6', 'Db-7', 'Db-j7', 'Db6', 'Db7', 'Dbj7', 'Dbm7b5', 'Dbo', 'Dbo7', 'Dbsus', 'Dbsus7', 'Dj7', 'Dm7b5', 'Do', 'Do7', 'Dsus', 'Dsus7', 'E', 'E+', 'E+7', 'E+j7', 'E-', 'E-6', 'E-7', 'E-j7', 'E6', 'E7', 'Eb', 'Eb+', 'Eb+7', 'Eb+j7', 'Eb-', 'Eb-6', 'Eb-7', 'Eb-j7', 'Eb6', 'Eb7', 'Ebj7', 'Ebm7b5', 'Ebo', 'Ebo7', 'Ebsus', 'Ebsus7', 'Ej7', 'Em7b5', 'Eo', 'Eo7', 'Esus', 'Esus7', 'F', 'F+', 'F+7', 'F+j7', 'F-', 'F-6', 'F-7', 'F-j7', 'F6', 'F7', 'Fj7', 'Fm7b5', 'Fo', 'Fo7', 'Fsus', 'Fsus7', 'G', 'G+', 'G+7', 'G+j7', 'G-', 'G-6', 'G-7', 'G-j7', 'G6', 'G7', 'Gb', 'Gb+', 'Gb+7', 'Gb+j7', 'Gb-', 'Gb-6', 'Gb-7', 'Gb-j7', 'Gb6', 'Gb7', 'Gbj7', 'Gbm7b5', 'Gbo', 'Gbo7', 'Gbsus', 'Gbsus7', 'Gj7', 'Gm7b5', 'Go', 'Go7', 'Gsus', 'Gsus7', 'NC']\n"
     ]
    }
   ],
   "source": [
    "# Isolate relevant data\n",
    "def get_notes_by_chord(beats):\n",
    "    return [note for beat in beats for note in beat]\n",
    "\n",
    "def get_chords_by_section(section):\n",
    "    return [chord_info[0] for chord_info in section]\n",
    "\n",
    "# def check_if_augmented_major(section):\n",
    "#     section_chords = get_chords_by_section(section)\n",
    "#     for ch in section_chords:\n",
    "#         if \"+j7\" in ch:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "# data = [section for section in data if not check_if_augmented_major(section)]\n",
    "# print(\"---Remove sections with augmented major chord---\")\n",
    "# print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections_bf_augmaj7 = [get_chords_by_section(section) for section in data]\n",
    "chords = [chord_info[0] for section in data for chord_info in section]\n",
    "unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords_bf_augmaj7 = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "notes = [note for chord_notes in notes_by_chords_bf_augmaj7 for note in chord_notes]\n",
    "unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "# print(sum([len(section) for section in chords_by_sections]))\n",
    "# print(\"Number of sections: {} | Sample section chords: {}\".format(len(chords_by_sections), chords_by_sections[0]))\n",
    "print(\"Number of chords: {} | Sample chord: {}\".format(len(chords), chords[0]))\n",
    "# print(\"Number of melodies {} | Sample melody: {}\".format(len(notes_by_chords), notes_by_chords[0]))\n",
    "print(\"Number of melody notes in the data: {} | Sample melody note: {}\".format(len(notes), notes[0]))\n",
    "print(\"Unique notes: {}\".format(unique_notes))\n",
    "print(\"Unique notes: {}\".format(unique_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melody note to integer mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, -1: 12, '<pad>': 13}\n",
      "\n",
      "Integer to melody note mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: -1, 13: '<pad>'}\n",
      "\n",
      "Chord label to integer mapping:\n",
      " {'E-6': 117, 'Ab-6': 15, 'A-': 4, 'Absus7': 25, 'Fo7': 157, 'G+': 161, 'Db-': 94, 'Bb-j7': 49, 'Dbsus7': 105, 'F7': 153, 'Bm7b5': 59, 'Gbm7b5': 181, '<eos>': 194, 'Bb-6': 47, 'Bsus7': 63, 'C6': 72, 'Bbm7b5': 53, 'G6': 168, 'Bb': 42, 'Fsus7': 159, 'E7': 121, 'Bsus': 62, 'Gbo': 182, 'A+j7': 3, 'Ebj7': 132, 'Ao': 28, 'C+7': 66, 'Gbsus7': 185, 'E+': 113, 'F-6': 149, 'Ebm7b5': 133, 'C-j7': 71, 'Ab6': 18, 'Eb-j7': 129, 'Bb6': 50, 'Fm7b5': 155, 'Ebsus7': 137, 'Eb+': 123, 'Gsus': 190, 'Eb6': 130, 'D': 80, 'Ab': 10, 'C-': 68, 'A+7': 2, 'Ab-j7': 17, 'Db-7': 96, 'B+': 33, 'Gbj7': 180, 'Em7b5': 139, 'G+7': 162, 'Abj7': 20, 'Bbo7': 55, 'Go': 188, 'Gj7': 186, 'G7': 169, 'Bbj7': 52, 'Fo': 156, 'F-7': 150, 'C7': 73, 'E': 112, 'Abo': 22, 'NC': 192, 'Eb+j7': 125, 'Gbo7': 183, 'A-6': 5, 'D6': 88, 'G-6': 165, 'Dbsus': 104, 'Bb-': 46, 'Do': 108, 'A+': 1, 'Bo7': 61, 'Ab+7': 12, 'Gb7': 179, 'Ab+j7': 13, 'Dm7b5': 107, 'Bb-7': 48, 'Ab-': 14, 'B-7': 38, 'B+7': 34, 'Ebo': 134, 'D-': 84, 'A6': 8, 'B6': 40, 'F+7': 146, 'Esus7': 143, 'B7': 41, 'D7': 89, 'D-7': 86, 'Dsus7': 111, 'Gb+': 171, 'Eb-6': 127, 'Co': 76, 'E+j7': 115, 'Db-6': 95, 'A-j7': 7, 'Esus': 142, 'Gb-6': 175, 'Am7b5': 27, 'C-6': 69, 'A7': 9, 'E-7': 118, 'Do7': 109, 'Gb-j7': 177, 'Eb-7': 128, 'E+7': 114, 'Asus7': 31, 'C+j7': 67, 'D+': 81, 'Bbo': 54, 'Csus': 78, '<bos>': 193, 'Ebo7': 135, 'Eb7': 131, 'B': 32, 'Db+': 91, 'Gbsus': 184, 'Ab7': 19, 'Eo7': 141, 'Db6': 98, 'E-j7': 119, 'Db+7': 92, 'Eo': 140, 'Aj7': 26, 'C+': 65, 'Csus7': 79, 'G-7': 166, 'F+j7': 147, 'Bj7': 58, 'G-': 164, 'B-j7': 39, 'Gb-': 174, 'Db+j7': 93, 'A-7': 6, 'Co7': 77, 'Ej7': 138, 'G': 160, 'Cj7': 74, 'C': 64, 'Gb+7': 172, 'D-j7': 87, 'Bo': 60, 'F+': 145, 'Db-j7': 97, 'Gb': 170, 'Dbo': 102, 'Ebsus': 136, 'Abm7b5': 21, 'D+j7': 83, 'A': 0, 'Dbm7b5': 101, 'Ab+': 11, 'Asus': 30, 'B-': 36, 'B+j7': 35, 'Abo7': 23, 'Bbsus7': 57, 'C-7': 70, 'Gm7b5': 187, 'E-': 116, 'Ab-7': 16, 'Eb': 122, 'D-6': 85, 'F-j7': 151, 'Absus': 24, 'Bb+j7': 45, 'Bbsus': 56, 'G+j7': 163, 'Ao7': 29, 'B-6': 37, 'Bb7': 51, 'Bb+7': 44, 'Gsus7': 191, 'Dj7': 106, 'F': 144, 'Gb6': 178, 'Gb+j7': 173, 'Bb+': 43, 'Cm7b5': 75, 'F-': 148, 'Eb+7': 124, 'Dbj7': 100, 'Eb-': 126, 'F6': 152, 'Go7': 189, 'Db': 90, 'Gb-7': 176, 'G-j7': 167, 'Fsus': 158, 'Fj7': 154, 'Dsus': 110, 'D+7': 82, 'E6': 120, 'Db7': 99, 'Dbo7': 103}\n",
      "\n",
      "Integer to chord label mapping:\n",
      " {0: 'A', 1: 'A+', 2: 'A+7', 3: 'A+j7', 4: 'A-', 5: 'A-6', 6: 'A-7', 7: 'A-j7', 8: 'A6', 9: 'A7', 10: 'Ab', 11: 'Ab+', 12: 'Ab+7', 13: 'Ab+j7', 14: 'Ab-', 15: 'Ab-6', 16: 'Ab-7', 17: 'Ab-j7', 18: 'Ab6', 19: 'Ab7', 20: 'Abj7', 21: 'Abm7b5', 22: 'Abo', 23: 'Abo7', 24: 'Absus', 25: 'Absus7', 26: 'Aj7', 27: 'Am7b5', 28: 'Ao', 29: 'Ao7', 30: 'Asus', 31: 'Asus7', 32: 'B', 33: 'B+', 34: 'B+7', 35: 'B+j7', 36: 'B-', 37: 'B-6', 38: 'B-7', 39: 'B-j7', 40: 'B6', 41: 'B7', 42: 'Bb', 43: 'Bb+', 44: 'Bb+7', 45: 'Bb+j7', 46: 'Bb-', 47: 'Bb-6', 48: 'Bb-7', 49: 'Bb-j7', 50: 'Bb6', 51: 'Bb7', 52: 'Bbj7', 53: 'Bbm7b5', 54: 'Bbo', 55: 'Bbo7', 56: 'Bbsus', 57: 'Bbsus7', 58: 'Bj7', 59: 'Bm7b5', 60: 'Bo', 61: 'Bo7', 62: 'Bsus', 63: 'Bsus7', 64: 'C', 65: 'C+', 66: 'C+7', 67: 'C+j7', 68: 'C-', 69: 'C-6', 70: 'C-7', 71: 'C-j7', 72: 'C6', 73: 'C7', 74: 'Cj7', 75: 'Cm7b5', 76: 'Co', 77: 'Co7', 78: 'Csus', 79: 'Csus7', 80: 'D', 81: 'D+', 82: 'D+7', 83: 'D+j7', 84: 'D-', 85: 'D-6', 86: 'D-7', 87: 'D-j7', 88: 'D6', 89: 'D7', 90: 'Db', 91: 'Db+', 92: 'Db+7', 93: 'Db+j7', 94: 'Db-', 95: 'Db-6', 96: 'Db-7', 97: 'Db-j7', 98: 'Db6', 99: 'Db7', 100: 'Dbj7', 101: 'Dbm7b5', 102: 'Dbo', 103: 'Dbo7', 104: 'Dbsus', 105: 'Dbsus7', 106: 'Dj7', 107: 'Dm7b5', 108: 'Do', 109: 'Do7', 110: 'Dsus', 111: 'Dsus7', 112: 'E', 113: 'E+', 114: 'E+7', 115: 'E+j7', 116: 'E-', 117: 'E-6', 118: 'E-7', 119: 'E-j7', 120: 'E6', 121: 'E7', 122: 'Eb', 123: 'Eb+', 124: 'Eb+7', 125: 'Eb+j7', 126: 'Eb-', 127: 'Eb-6', 128: 'Eb-7', 129: 'Eb-j7', 130: 'Eb6', 131: 'Eb7', 132: 'Ebj7', 133: 'Ebm7b5', 134: 'Ebo', 135: 'Ebo7', 136: 'Ebsus', 137: 'Ebsus7', 138: 'Ej7', 139: 'Em7b5', 140: 'Eo', 141: 'Eo7', 142: 'Esus', 143: 'Esus7', 144: 'F', 145: 'F+', 146: 'F+7', 147: 'F+j7', 148: 'F-', 149: 'F-6', 150: 'F-7', 151: 'F-j7', 152: 'F6', 153: 'F7', 154: 'Fj7', 155: 'Fm7b5', 156: 'Fo', 157: 'Fo7', 158: 'Fsus', 159: 'Fsus7', 160: 'G', 161: 'G+', 162: 'G+7', 163: 'G+j7', 164: 'G-', 165: 'G-6', 166: 'G-7', 167: 'G-j7', 168: 'G6', 169: 'G7', 170: 'Gb', 171: 'Gb+', 172: 'Gb+7', 173: 'Gb+j7', 174: 'Gb-', 175: 'Gb-6', 176: 'Gb-7', 177: 'Gb-j7', 178: 'Gb6', 179: 'Gb7', 180: 'Gbj7', 181: 'Gbm7b5', 182: 'Gbo', 183: 'Gbo7', 184: 'Gbsus', 185: 'Gbsus7', 186: 'Gj7', 187: 'Gm7b5', 188: 'Go', 189: 'Go7', 190: 'Gsus', 191: 'Gsus7', 192: 'NC', 193: '<bos>', 194: '<eos>'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create categorical data mappings\n",
    "note_to_int = dict([(c, i) for i, c in enumerate(unique_notes[1:])])\n",
    "note_to_int[-1] = len(note_to_int)\n",
    "note_to_int['<pad>'] = len(note_to_int)\n",
    "\n",
    "int_to_note = dict([(k, v) for v, k in note_to_int.items()])\n",
    "\n",
    "chord_to_int = dict([(c, i) for i, c in enumerate(unique_chords)])\n",
    "chord_to_int['<bos>'] = len(chord_to_int)\n",
    "chord_to_int['<eos>'] = len(chord_to_int)\n",
    "\n",
    "int_to_chord = dict([(k, v) for v, k in chord_to_int.items()])\n",
    "\n",
    "print(\"Melody note to integer mapping:\\n {}\\n\".format(note_to_int))\n",
    "print(\"Integer to melody note mapping:\\n {}\\n\".format(int_to_note))\n",
    "print(\"Chord label to integer mapping:\\n {}\\n\".format(chord_to_int))\n",
    "print(\"Integer to chord label mapping:\\n {}\\n\".format(int_to_chord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 334344\n",
      "Number of distinct melody notes: 14\n",
      "Number of distinct chord labels: 195\n",
      "Maximum length of melody sequences for one chord: 135\n",
      "Number of past chords given as input: 7\n"
     ]
    }
   ],
   "source": [
    "# Define numerical variables\n",
    "\n",
    "n_samples = len(chords)\n",
    "n_chords = len(chord_to_int)\n",
    "n_notes = len(note_to_int)\n",
    "max_mel_len = max([len(mel) for mel in notes_by_chords_bf_augmaj7])\n",
    "chord_context_len = 7\n",
    "\n",
    "# print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Number of distinct melody notes: {}\".format(n_notes))\n",
    "print(\"Number of distinct chord labels: {}\".format(n_chords))\n",
    "print(\"Maximum length of melody sequences for one chord: {}\".format(max_mel_len))\n",
    "print(\"Number of past chords given as input: {}\".format(chord_context_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [4]]\n"
     ]
    }
   ],
   "source": [
    "mel_by_sections = [mel for section in data for ch, mel in section]\n",
    "print(mel_by_sections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Remove sections with augmented major chord---\n",
      "Number of sections: 28836\n",
      "\n",
      "Sample input melody sequence: [8, 3, 6, '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "\n",
      "Sample input chord sequence: ['<bos>', '<bos>', 'E6', 'Db7', 'Gb-7', 'B7', 'E']\n",
      "\n",
      "Sample target chord: Db-7\n",
      "\n",
      "Input melody: 333480, Input chords: 333480, Target chords: 333480\n"
     ]
    }
   ],
   "source": [
    "# Prepare tensor data\n",
    "\n",
    "\n",
    "def check_if_augmented_major(section):\n",
    "    section_chords = get_chords_by_section(section)\n",
    "    for ch in section_chords:\n",
    "        if \"+j7\" in ch:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "data = [section for section in data if not check_if_augmented_major(section)]\n",
    "print(\"---Remove sections with augmented major chord---\")\n",
    "print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections = [get_chords_by_section(section) for section in data]\n",
    "# chords = [chord_info[0] for section in data for chord_info in section]\n",
    "# unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "# notes = [note for chord_notes in notes_by_chords for note in chord_notes]\n",
    "# unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "\n",
    "\n",
    "def pad_melody(melody, max_len):\n",
    "    return melody + (max_len-len(melody))*['<pad>']\n",
    "\n",
    "def build_input_chord_sequences(chord_seq, context_len):\n",
    "    padded_sequence = context_len*['<bos>'] + chord_seq\n",
    "    formatted_sequences = [padded_sequence[i:i+context_len+1] for i in range(len(chord_seq))]\n",
    "    return formatted_sequences\n",
    "\n",
    "# Melody\n",
    "input_melody_data = [pad_melody(melody, max_mel_len) for melody in notes_by_chords]\n",
    "print(\"Sample input melody sequence: {}\\n\".format(input_melody_data[5]))\n",
    "\n",
    "# Chords\n",
    "formatted_chords_data = []\n",
    "for section_chords in chords_by_sections:\n",
    "    formatted_chords_data += build_input_chord_sequences(section_chords, chord_context_len)\n",
    "    \n",
    "input_chords_data = [ch[:-1] for ch in formatted_chords_data]\n",
    "target_chords_data = [ch[-1] for ch in formatted_chords_data]\n",
    "print(\"Sample input chord sequence: {}\\n\".format(input_chords_data[5]))\n",
    "print(\"Sample target chord: {}\\n\".format(target_chords_data[5]))\n",
    "\n",
    "print(\"Input melody: {}, Input chords: {}, Target chords: {}\".format(len(input_melody_data), len(input_chords_data), len(target_chords_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load embedding vectors\n",
    "\n",
    "num_dim = 8\n",
    "num_ch = 192\n",
    "num_notes = 12\n",
    "\n",
    "# Define embedding training model and load weights\n",
    "input_layer = Input(shape=(num_ch,)) \n",
    "embeddings_layer = Dense(num_dim, activation='linear', name=\"embeddings\")(input_layer)\n",
    "root_output_layer = Dense(num_notes, activation='softmax')(embeddings_layer)\n",
    "interval_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "pitch_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "melody_output_layer = Dense(num_notes, activation='relu')(embeddings_layer)\n",
    "embeddings_model = Model(input_layer, [root_output_layer, interval_output_layer, pitch_output_layer, melody_output_layer])\n",
    "\n",
    "embeddings_model.load_weights(\"../Skipgram & WJD/weights/combined_weights_dim8.h5\")\n",
    "\n",
    "X_chords_embeddings = embeddings_model.layers[1].get_weights()[0]\n",
    "print(X_chords_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embedding vector for each chord: 8\n"
     ]
    }
   ],
   "source": [
    "# Build tensors\n",
    "\n",
    "n_dimensions = X_chords_embeddings.shape[1]\n",
    "print(\"Size of embedding vector for each chord: {}\".format(n_dimensions))\n",
    "\n",
    "X_melody = np.zeros((n_samples, max_mel_len, n_notes), dtype='float32')\n",
    "X_chords = np.zeros((n_samples, chord_context_len, n_dimensions), dtype='float32')\n",
    "Y_chord = np.zeros((n_samples, n_chords), dtype='float32')\n",
    "\n",
    "for i, (input_mel, input_ch, target_ch) in enumerate(zip(input_melody_data, input_chords_data, target_chords_data)):\n",
    "    Y_chord[i, chord_to_int[target_ch]] = 1\n",
    "    for j, chord in enumerate(input_ch):\n",
    "#         X_chords[i, j, chord_to_int[chord]] = 1\n",
    "        chord_index = chord_to_int[chord]\n",
    "        if (chord_index < num_ch):\n",
    "            X_chords[i, j, :] = X_chords_embeddings[chord_index, :]\n",
    "    \n",
    "    for j, note in enumerate(input_mel):\n",
    "        X_melody[i, j, note_to_int[note]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334344, 135, 14)\n",
      "(334344, 7, 8)\n",
      "(334344, 195)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody.shape)\n",
    "print(X_chords.shape)\n",
    "print(Y_chord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset into 80%-10%-10% train-valid-test sets\n",
    "seed = 0\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "\n",
    "for train_index, aux_index in sss.split(X_chords, Y_chord):\n",
    "    X_melody_train, X_melody_aux = X_melody[train_index], X_melody[aux_index]\n",
    "    X_chords_train, X_chords_aux = X_chords[train_index], X_chords[aux_index]\n",
    "    Y_chord_train, Y_chord_aux = Y_chord[train_index], Y_chord[aux_index]\n",
    "    \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)\n",
    "\n",
    "for valid_index, test_index in sss.split(X_chords_aux, Y_chord_aux):\n",
    "    X_melody_valid, X_melody_test = X_melody[valid_index], X_melody[test_index]\n",
    "    X_chords_valid, X_chords_test = X_chords[valid_index], X_chords[test_index]\n",
    "    Y_chord_valid, Y_chord_test = Y_chord[valid_index], Y_chord[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maxime/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1192: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/maxime/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 135, 14)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 7, 8)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_1 (GRU)                      (None, 135, 128)      54912       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_3 (GRU)                      (None, 7, 128)        52608       input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_2 (GRU)                      (None, 128)           98688       gru_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      (None, 128)           98688       gru_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 256)           0           gru_2[0][0]                      \n",
      "                                                                   gru_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 128)           32896       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 195)           25155       dense_9[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 362,947\n",
      "Trainable params: 362,947\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define neual net architecture\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "melody_input = Input(shape=(max_mel_len, n_notes))\n",
    "melody_gru1 = GRU(latent_dim, return_sequences=True)(melody_input)\n",
    "melody_gru2 = GRU(latent_dim)(melody_gru1)\n",
    "\n",
    "chords_input = Input(shape=(chord_context_len, n_dimensions))\n",
    "chords_gru1 = GRU(latent_dim, return_sequences=True)(chords_input)\n",
    "chords_gru2 = GRU(latent_dim)(chords_gru1)\n",
    "\n",
    "concat = concatenate([melody_gru2, chords_gru2])\n",
    "\n",
    "chord_dense1 = Dense(latent_dim, activation='relu')(concat)\n",
    "chord_dense2 = Dense(n_chords, activation='softmax')(chord_dense1)\n",
    "\n",
    "model = Model([melody_input, chords_input], chord_dense2)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Introduce Best-Performance callbacks\n",
    "# es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "filepath = \"models/embeddings8-Mel2-Cho2-FC2_150ep.h5\"\n",
    "bp = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267475 samples, validate on 33434 samples\n",
      "Epoch 1/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.8241 - acc: 0.3585Epoch 00000: val_acc improved from -inf to 0.43234, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 2.8239 - acc: 0.3585 - val_loss: 2.4328 - val_acc: 0.4323\n",
      "Epoch 2/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.1908 - acc: 0.4799Epoch 00001: val_acc improved from 0.43234 to 0.49877, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 2.1908 - acc: 0.4799 - val_loss: 2.1596 - val_acc: 0.4988\n",
      "Epoch 3/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.9307 - acc: 0.5376Epoch 00002: val_acc improved from 0.49877 to 0.53458, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 1.9308 - acc: 0.5376 - val_loss: 2.0067 - val_acc: 0.5346\n",
      "Epoch 4/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.7470 - acc: 0.5798Epoch 00003: val_acc improved from 0.53458 to 0.56688, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 937s - loss: 1.7469 - acc: 0.5798 - val_loss: 1.8938 - val_acc: 0.5669\n",
      "Epoch 5/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.6086 - acc: 0.6123Epoch 00004: val_acc improved from 0.56688 to 0.58408, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 941s - loss: 1.6086 - acc: 0.6123 - val_loss: 1.8107 - val_acc: 0.5841\n",
      "Epoch 6/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.5003 - acc: 0.6368Epoch 00005: val_acc improved from 0.58408 to 0.59535, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 940s - loss: 1.5003 - acc: 0.6368 - val_loss: 1.7615 - val_acc: 0.5954\n",
      "Epoch 7/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.4154 - acc: 0.6556Epoch 00006: val_acc improved from 0.59535 to 0.61399, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 940s - loss: 1.4154 - acc: 0.6556 - val_loss: 1.7024 - val_acc: 0.6140\n",
      "Epoch 8/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.3472 - acc: 0.6703Epoch 00007: val_acc improved from 0.61399 to 0.61997, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 1.3471 - acc: 0.6703 - val_loss: 1.6697 - val_acc: 0.6200\n",
      "Epoch 9/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2921 - acc: 0.6823Epoch 00008: val_acc improved from 0.61997 to 0.63271, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 929s - loss: 1.2921 - acc: 0.6823 - val_loss: 1.6313 - val_acc: 0.6327\n",
      "Epoch 10/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2468 - acc: 0.6916Epoch 00009: val_acc improved from 0.63271 to 0.63800, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 930s - loss: 1.2469 - acc: 0.6916 - val_loss: 1.6203 - val_acc: 0.6380\n",
      "Epoch 11/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2090 - acc: 0.6988Epoch 00010: val_acc improved from 0.63800 to 0.63893, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 933s - loss: 1.2090 - acc: 0.6988 - val_loss: 1.5956 - val_acc: 0.6389\n",
      "Epoch 12/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1772 - acc: 0.7054Epoch 00011: val_acc improved from 0.63893 to 0.64922, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 940s - loss: 1.1774 - acc: 0.7054 - val_loss: 1.5660 - val_acc: 0.6492\n",
      "Epoch 13/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1497 - acc: 0.7104Epoch 00012: val_acc improved from 0.64922 to 0.65356, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 940s - loss: 1.1498 - acc: 0.7104 - val_loss: 1.5582 - val_acc: 0.6536\n",
      "Epoch 14/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1274 - acc: 0.7151Epoch 00013: val_acc improved from 0.65356 to 0.65679, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 939s - loss: 1.1274 - acc: 0.7151 - val_loss: 1.5505 - val_acc: 0.6568\n",
      "Epoch 15/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1065 - acc: 0.7188Epoch 00014: val_acc improved from 0.65679 to 0.66429, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 937s - loss: 1.1065 - acc: 0.7188 - val_loss: 1.5254 - val_acc: 0.6643\n",
      "Epoch 16/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0880 - acc: 0.7226Epoch 00015: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 1.0881 - acc: 0.7226 - val_loss: 1.5365 - val_acc: 0.6581\n",
      "Epoch 17/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0740 - acc: 0.7242Epoch 00016: val_acc improved from 0.66429 to 0.66441, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 932s - loss: 1.0738 - acc: 0.7242 - val_loss: 1.5155 - val_acc: 0.6644\n",
      "Epoch 18/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0599 - acc: 0.7269Epoch 00017: val_acc improved from 0.66441 to 0.66869, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 1.0598 - acc: 0.7270 - val_loss: 1.5075 - val_acc: 0.6687\n",
      "Epoch 19/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0481 - acc: 0.7293Epoch 00018: val_acc improved from 0.66869 to 0.66917, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 1.0481 - acc: 0.7292 - val_loss: 1.5015 - val_acc: 0.6692\n",
      "Epoch 20/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0372 - acc: 0.7307Epoch 00019: val_acc improved from 0.66917 to 0.66932, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 940s - loss: 1.0372 - acc: 0.7307 - val_loss: 1.5025 - val_acc: 0.6693\n",
      "Epoch 21/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0319 - acc: 0.7319Epoch 00020: val_acc improved from 0.66932 to 0.67416, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 938s - loss: 1.0318 - acc: 0.7320 - val_loss: 1.4722 - val_acc: 0.6742\n",
      "Epoch 22/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9716 - acc: 0.7418Epoch 00021: val_acc improved from 0.67416 to 0.68813, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 940s - loss: 0.9716 - acc: 0.7418 - val_loss: 1.3994 - val_acc: 0.6881\n",
      "Epoch 23/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9288 - acc: 0.7490Epoch 00022: val_acc improved from 0.68813 to 0.69495, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 935s - loss: 0.9288 - acc: 0.7491 - val_loss: 1.3813 - val_acc: 0.6950\n",
      "Epoch 24/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9034 - acc: 0.7550Epoch 00023: val_acc improved from 0.69495 to 0.69716, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 929s - loss: 0.9033 - acc: 0.7550 - val_loss: 1.3649 - val_acc: 0.6972\n",
      "Epoch 25/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8829 - acc: 0.7587Epoch 00024: val_acc improved from 0.69716 to 0.70084, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 928s - loss: 0.8829 - acc: 0.7587 - val_loss: 1.3520 - val_acc: 0.7008\n",
      "Epoch 26/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8645 - acc: 0.7638Epoch 00025: val_acc improved from 0.70084 to 0.70503, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 928s - loss: 0.8644 - acc: 0.7638 - val_loss: 1.3390 - val_acc: 0.7050\n",
      "Epoch 27/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8463 - acc: 0.7676Epoch 00026: val_acc improved from 0.70503 to 0.70787, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 933s - loss: 0.8464 - acc: 0.7676 - val_loss: 1.3358 - val_acc: 0.7079\n",
      "Epoch 28/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8292 - acc: 0.7718Epoch 00027: val_acc improved from 0.70787 to 0.71224, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 937s - loss: 0.8292 - acc: 0.7719 - val_loss: 1.3308 - val_acc: 0.7122\n",
      "Epoch 29/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8133 - acc: 0.7752Epoch 00028: val_acc improved from 0.71224 to 0.71810, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 937s - loss: 0.8133 - acc: 0.7752 - val_loss: 1.3159 - val_acc: 0.7181\n",
      "Epoch 30/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8021 - acc: 0.7780Epoch 00029: val_acc improved from 0.71810 to 0.71831, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 936s - loss: 0.8021 - acc: 0.7780 - val_loss: 1.3151 - val_acc: 0.7183\n",
      "Epoch 31/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7807 - acc: 0.7836Epoch 00030: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.7806 - acc: 0.7836 - val_loss: 1.3271 - val_acc: 0.7128\n",
      "Epoch 32/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7694 - acc: 0.7855Epoch 00031: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.7697 - acc: 0.7854 - val_loss: 1.3362 - val_acc: 0.7167\n",
      "Epoch 33/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7650 - acc: 0.7867Epoch 00032: val_acc did not improve\n",
      "267475/267475 [==============================] - 935s - loss: 0.7650 - acc: 0.7867 - val_loss: 1.3210 - val_acc: 0.7171\n",
      "Epoch 34/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7611 - acc: 0.7877Epoch 00033: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.7612 - acc: 0.7877 - val_loss: 1.3510 - val_acc: 0.7128\n",
      "Epoch 35/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7475 - acc: 0.7902Epoch 00034: val_acc improved from 0.71831 to 0.72064, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 934s - loss: 0.7476 - acc: 0.7902 - val_loss: 1.3132 - val_acc: 0.7206\n",
      "Epoch 36/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7370 - acc: 0.7934Epoch 00035: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.7370 - acc: 0.7934 - val_loss: 1.3522 - val_acc: 0.7114\n",
      "Epoch 37/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8100 - acc: 0.7746Epoch 00036: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.8100 - acc: 0.7745 - val_loss: 1.3448 - val_acc: 0.7114\n",
      "Epoch 38/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7501 - acc: 0.7892Epoch 00037: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.7500 - acc: 0.7892 - val_loss: 1.3304 - val_acc: 0.7206\n",
      "Epoch 39/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7253 - acc: 0.7951Epoch 00038: val_acc improved from 0.72064 to 0.72546, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 0.7251 - acc: 0.7952 - val_loss: 1.3161 - val_acc: 0.7255\n",
      "Epoch 40/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7058 - acc: 0.8002Epoch 00039: val_acc improved from 0.72546 to 0.72782, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 930s - loss: 0.7059 - acc: 0.8002 - val_loss: 1.3127 - val_acc: 0.7278\n",
      "Epoch 41/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7246 - acc: 0.7955Epoch 00040: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.7247 - acc: 0.7955 - val_loss: 1.3235 - val_acc: 0.7250\n",
      "Epoch 42/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6939 - acc: 0.8033Epoch 00041: val_acc improved from 0.72782 to 0.72803, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 935s - loss: 0.6941 - acc: 0.8033 - val_loss: 1.3106 - val_acc: 0.7280\n",
      "Epoch 43/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6903 - acc: 0.8041Epoch 00042: val_acc did not improve\n",
      "267475/267475 [==============================] - 937s - loss: 0.6903 - acc: 0.8041 - val_loss: 1.3327 - val_acc: 0.7258\n",
      "Epoch 44/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7023 - acc: 0.8005Epoch 00043: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.7023 - acc: 0.8005 - val_loss: 1.3429 - val_acc: 0.7233\n",
      "Epoch 45/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7477 - acc: 0.7890Epoch 00044: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.7478 - acc: 0.7889 - val_loss: 1.3416 - val_acc: 0.7197\n",
      "Epoch 46/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7310 - acc: 0.7928Epoch 00045: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.7312 - acc: 0.7928 - val_loss: 1.3470 - val_acc: 0.7195\n",
      "Epoch 47/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7196 - acc: 0.7965Epoch 00046: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.7195 - acc: 0.7965 - val_loss: 1.3395 - val_acc: 0.7252\n",
      "Epoch 48/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7207 - acc: 0.7952Epoch 00047: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.7206 - acc: 0.7952 - val_loss: 1.3508 - val_acc: 0.7223\n",
      "Epoch 49/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7219 - acc: 0.7954Epoch 00048: val_acc improved from 0.72803 to 0.72887, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 931s - loss: 0.7220 - acc: 0.7953 - val_loss: 1.3324 - val_acc: 0.7289\n",
      "Epoch 50/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7028 - acc: 0.8001Epoch 00049: val_acc did not improve\n",
      "267475/267475 [==============================] - 935s - loss: 0.7028 - acc: 0.8002 - val_loss: 1.3322 - val_acc: 0.7247\n",
      "Epoch 51/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6992 - acc: 0.8014Epoch 00050: val_acc did not improve\n",
      "267475/267475 [==============================] - 951s - loss: 0.6992 - acc: 0.8014 - val_loss: 1.3719 - val_acc: 0.7187\n",
      "Epoch 52/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6925 - acc: 0.8028Epoch 00051: val_acc improved from 0.72887 to 0.72941, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 948s - loss: 0.6925 - acc: 0.8028 - val_loss: 1.3358 - val_acc: 0.7294\n",
      "Epoch 53/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6806 - acc: 0.8056Epoch 00052: val_acc did not improve\n",
      "267475/267475 [==============================] - 949s - loss: 0.6807 - acc: 0.8056 - val_loss: 1.3352 - val_acc: 0.7286\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6816 - acc: 0.8056Epoch 00053: val_acc did not improve\n",
      "267475/267475 [==============================] - 944s - loss: 0.6815 - acc: 0.8056 - val_loss: 1.3915 - val_acc: 0.7138\n",
      "Epoch 55/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6849 - acc: 0.8050Epoch 00054: val_acc improved from 0.72941 to 0.72992, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 941s - loss: 0.6848 - acc: 0.8050 - val_loss: 1.3350 - val_acc: 0.7299\n",
      "Epoch 56/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6631 - acc: 0.8102Epoch 00055: val_acc improved from 0.72992 to 0.73007, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 942s - loss: 0.6631 - acc: 0.8102 - val_loss: 1.3382 - val_acc: 0.7301\n",
      "Epoch 57/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6736 - acc: 0.8075Epoch 00056: val_acc did not improve\n",
      "267475/267475 [==============================] - 942s - loss: 0.6736 - acc: 0.8075 - val_loss: 1.3504 - val_acc: 0.7252\n",
      "Epoch 58/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6686 - acc: 0.8086Epoch 00057: val_acc did not improve\n",
      "267475/267475 [==============================] - 951s - loss: 0.6687 - acc: 0.8086 - val_loss: 1.3476 - val_acc: 0.7271\n",
      "Epoch 59/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6616 - acc: 0.8100Epoch 00058: val_acc improved from 0.73007 to 0.73237, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 953s - loss: 0.6617 - acc: 0.8100 - val_loss: 1.3384 - val_acc: 0.7324\n",
      "Epoch 60/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6534 - acc: 0.8119Epoch 00059: val_acc improved from 0.73237 to 0.73270, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 951s - loss: 0.6533 - acc: 0.8120 - val_loss: 1.3403 - val_acc: 0.7327\n",
      "Epoch 61/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6463 - acc: 0.8150Epoch 00060: val_acc did not improve\n",
      "267475/267475 [==============================] - 952s - loss: 0.6463 - acc: 0.8150 - val_loss: 1.3519 - val_acc: 0.7292\n",
      "Epoch 62/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6326 - acc: 0.8175Epoch 00061: val_acc did not improve\n",
      "267475/267475 [==============================] - 939s - loss: 0.6326 - acc: 0.8175 - val_loss: 1.3489 - val_acc: 0.7317\n",
      "Epoch 63/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6298 - acc: 0.8181Epoch 00062: val_acc improved from 0.73270 to 0.73342, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 939s - loss: 0.6298 - acc: 0.8181 - val_loss: 1.3500 - val_acc: 0.7334\n",
      "Epoch 64/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6215 - acc: 0.8213Epoch 00063: val_acc did not improve\n",
      "267475/267475 [==============================] - 940s - loss: 0.6215 - acc: 0.8213 - val_loss: 1.3464 - val_acc: 0.7333\n",
      "Epoch 65/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6724 - acc: 0.8065Epoch 00064: val_acc improved from 0.73342 to 0.73410, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 944s - loss: 0.6725 - acc: 0.8065 - val_loss: 1.3419 - val_acc: 0.7341\n",
      "Epoch 66/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6402 - acc: 0.8157Epoch 00065: val_acc did not improve\n",
      "267475/267475 [==============================] - 954s - loss: 0.6403 - acc: 0.8156 - val_loss: 1.3634 - val_acc: 0.7264\n",
      "Epoch 67/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6741 - acc: 0.8059Epoch 00066: val_acc did not improve\n",
      "267475/267475 [==============================] - 953s - loss: 0.6742 - acc: 0.8059 - val_loss: 1.3664 - val_acc: 0.7282\n",
      "Epoch 68/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6353 - acc: 0.8179Epoch 00067: val_acc did not improve\n",
      "267475/267475 [==============================] - 951s - loss: 0.6353 - acc: 0.8179 - val_loss: 1.3532 - val_acc: 0.7322\n",
      "Epoch 69/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6165 - acc: 0.8223Epoch 00068: val_acc did not improve\n",
      "267475/267475 [==============================] - 950s - loss: 0.6166 - acc: 0.8223 - val_loss: 1.3710 - val_acc: 0.7299\n",
      "Epoch 70/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6119 - acc: 0.8229Epoch 00069: val_acc improved from 0.73410 to 0.73524, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 947s - loss: 0.6119 - acc: 0.8229 - val_loss: 1.3524 - val_acc: 0.7352\n",
      "Epoch 71/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6204 - acc: 0.8212Epoch 00070: val_acc did not improve\n",
      "267475/267475 [==============================] - 946s - loss: 0.6205 - acc: 0.8212 - val_loss: 1.3645 - val_acc: 0.7322\n",
      "Epoch 72/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5993 - acc: 0.8265Epoch 00071: val_acc improved from 0.73524 to 0.74062, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 946s - loss: 0.5994 - acc: 0.8265 - val_loss: 1.3594 - val_acc: 0.7406\n",
      "Epoch 73/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5866 - acc: 0.8297Epoch 00072: val_acc improved from 0.74062 to 0.74224, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 948s - loss: 0.5865 - acc: 0.8297 - val_loss: 1.3518 - val_acc: 0.7422\n",
      "Epoch 74/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6767 - acc: 0.8058Epoch 00073: val_acc did not improve\n",
      "267475/267475 [==============================] - 944s - loss: 0.6767 - acc: 0.8058 - val_loss: 1.3760 - val_acc: 0.7332\n",
      "Epoch 75/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6027 - acc: 0.8255Epoch 00074: val_acc did not improve\n",
      "267475/267475 [==============================] - 939s - loss: 0.6027 - acc: 0.8255 - val_loss: 1.3614 - val_acc: 0.7385\n",
      "Epoch 76/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5816 - acc: 0.8315Epoch 00075: val_acc improved from 0.74224 to 0.74281, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 939s - loss: 0.5815 - acc: 0.8315 - val_loss: 1.3585 - val_acc: 0.7428\n",
      "Epoch 77/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5655 - acc: 0.8362Epoch 00076: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 0.5655 - acc: 0.8362 - val_loss: 1.3643 - val_acc: 0.7394\n",
      "Epoch 78/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5580 - acc: 0.8381Epoch 00077: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.5581 - acc: 0.8381 - val_loss: 1.3828 - val_acc: 0.7311\n",
      "Epoch 79/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5624 - acc: 0.8360Epoch 00078: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.5624 - acc: 0.8360 - val_loss: 1.3747 - val_acc: 0.7386\n",
      "Epoch 80/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5556 - acc: 0.8389Epoch 00079: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.5554 - acc: 0.8390 - val_loss: 1.3679 - val_acc: 0.7397\n",
      "Epoch 81/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5556 - acc: 0.8381Epoch 00080: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.5557 - acc: 0.8381 - val_loss: 1.4082 - val_acc: 0.7274\n",
      "Epoch 82/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6369 - acc: 0.8157Epoch 00081: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.6369 - acc: 0.8158 - val_loss: 1.3964 - val_acc: 0.7303\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5697 - acc: 0.8341Epoch 00082: val_acc improved from 0.74281 to 0.74487, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 930s - loss: 0.5696 - acc: 0.8342 - val_loss: 1.3617 - val_acc: 0.7449\n",
      "Epoch 84/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5313 - acc: 0.8462Epoch 00083: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.5313 - acc: 0.8462 - val_loss: 1.3863 - val_acc: 0.7405\n",
      "Epoch 85/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5418 - acc: 0.8415Epoch 00084: val_acc did not improve\n",
      "267475/267475 [==============================] - 926s - loss: 0.5418 - acc: 0.8415 - val_loss: 1.3737 - val_acc: 0.7442\n",
      "Epoch 86/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5272 - acc: 0.8462Epoch 00085: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 0.5272 - acc: 0.8462 - val_loss: 1.3779 - val_acc: 0.7428\n",
      "Epoch 87/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5394 - acc: 0.8432Epoch 00086: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.5394 - acc: 0.8432 - val_loss: 1.4049 - val_acc: 0.7354\n",
      "Epoch 88/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5245 - acc: 0.8470Epoch 00087: val_acc improved from 0.74487 to 0.74502, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 930s - loss: 0.5245 - acc: 0.8470 - val_loss: 1.3875 - val_acc: 0.7450\n",
      "Epoch 89/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5130 - acc: 0.8502Epoch 00088: val_acc improved from 0.74502 to 0.74631, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 934s - loss: 0.5132 - acc: 0.8502 - val_loss: 1.3823 - val_acc: 0.7463\n",
      "Epoch 90/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5280 - acc: 0.8454Epoch 00089: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.5280 - acc: 0.8454 - val_loss: 1.4035 - val_acc: 0.7431\n",
      "Epoch 91/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5272 - acc: 0.8461Epoch 00090: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.5272 - acc: 0.8462 - val_loss: 1.4001 - val_acc: 0.7427\n",
      "Epoch 92/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5340 - acc: 0.8442Epoch 00091: val_acc did not improve\n",
      "267475/267475 [==============================] - 935s - loss: 0.5339 - acc: 0.8442 - val_loss: 1.3878 - val_acc: 0.7458\n",
      "Epoch 93/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4943 - acc: 0.8555Epoch 00092: val_acc improved from 0.74631 to 0.75019, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 936s - loss: 0.4944 - acc: 0.8555 - val_loss: 1.3827 - val_acc: 0.7502\n",
      "Epoch 94/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5007 - acc: 0.8532Epoch 00093: val_acc did not improve\n",
      "267475/267475 [==============================] - 942s - loss: 0.5006 - acc: 0.8532 - val_loss: 1.3951 - val_acc: 0.7496\n",
      "Epoch 95/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4967 - acc: 0.8545Epoch 00094: val_acc did not improve\n",
      "267475/267475 [==============================] - 941s - loss: 0.4967 - acc: 0.8545 - val_loss: 1.3947 - val_acc: 0.7458\n",
      "Epoch 96/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4964 - acc: 0.8544Epoch 00095: val_acc did not improve\n",
      "267475/267475 [==============================] - 941s - loss: 0.4964 - acc: 0.8544 - val_loss: 1.4276 - val_acc: 0.7365\n",
      "Epoch 97/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5002 - acc: 0.8524Epoch 00096: val_acc did not improve\n",
      "267475/267475 [==============================] - 941s - loss: 0.5004 - acc: 0.8523 - val_loss: 1.4067 - val_acc: 0.7462\n",
      "Epoch 98/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4824 - acc: 0.8584Epoch 00097: val_acc did not improve\n",
      "267475/267475 [==============================] - 940s - loss: 0.4823 - acc: 0.8584 - val_loss: 1.4171 - val_acc: 0.7456\n",
      "Epoch 99/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4762 - acc: 0.8600Epoch 00098: val_acc improved from 0.75019 to 0.75169, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 941s - loss: 0.4761 - acc: 0.8600 - val_loss: 1.3993 - val_acc: 0.7517\n",
      "Epoch 100/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5049 - acc: 0.8514Epoch 00099: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.5049 - acc: 0.8514 - val_loss: 1.4175 - val_acc: 0.7461\n",
      "Epoch 101/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4765 - acc: 0.8602Epoch 00100: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.4765 - acc: 0.8602 - val_loss: 1.4475 - val_acc: 0.7384\n",
      "Epoch 102/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4887 - acc: 0.8560Epoch 00101: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.4887 - acc: 0.8560 - val_loss: 1.4155 - val_acc: 0.7452\n",
      "Epoch 103/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8640Epoch 00102: val_acc improved from 0.75169 to 0.75199, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 934s - loss: 0.4611 - acc: 0.8640 - val_loss: 1.4012 - val_acc: 0.7520\n",
      "Epoch 104/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4700 - acc: 0.8615Epoch 00103: val_acc did not improve\n",
      "267475/267475 [==============================] - 940s - loss: 0.4699 - acc: 0.8615 - val_loss: 1.4540 - val_acc: 0.7407\n",
      "Epoch 105/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4626 - acc: 0.8635Epoch 00104: val_acc did not improve\n",
      "267475/267475 [==============================] - 941s - loss: 0.4626 - acc: 0.8635 - val_loss: 1.4253 - val_acc: 0.7500\n",
      "Epoch 106/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.8453Epoch 00105: val_acc did not improve\n",
      "267475/267475 [==============================] - 940s - loss: 0.5259 - acc: 0.8453 - val_loss: 1.4123 - val_acc: 0.7502\n",
      "Epoch 107/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4452 - acc: 0.8697Epoch 00106: val_acc did not improve\n",
      "267475/267475 [==============================] - 937s - loss: 0.4452 - acc: 0.8697 - val_loss: 1.4164 - val_acc: 0.7506\n",
      "Epoch 108/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4459 - acc: 0.8685Epoch 00107: val_acc improved from 0.75199 to 0.75474, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 926s - loss: 0.4459 - acc: 0.8685 - val_loss: 1.4121 - val_acc: 0.7547\n",
      "Epoch 109/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4323 - acc: 0.8725Epoch 00108: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.4324 - acc: 0.8725 - val_loss: 1.4306 - val_acc: 0.7503\n",
      "Epoch 110/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4401 - acc: 0.8697Epoch 00109: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.4402 - acc: 0.8697 - val_loss: 1.4748 - val_acc: 0.7426\n",
      "Epoch 111/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8638Epoch 00110: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.4587 - acc: 0.8639 - val_loss: 1.4716 - val_acc: 0.7462\n",
      "Epoch 112/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4435 - acc: 0.8686Epoch 00111: val_acc did not improve\n",
      "267475/267475 [==============================] - 940s - loss: 0.4436 - acc: 0.8686 - val_loss: 1.4578 - val_acc: 0.7500\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4425 - acc: 0.8688Epoch 00112: val_acc did not improve\n",
      "267475/267475 [==============================] - 938s - loss: 0.4425 - acc: 0.8687 - val_loss: 1.4493 - val_acc: 0.7518\n",
      "Epoch 114/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4300 - acc: 0.8725Epoch 00113: val_acc did not improve\n",
      "267475/267475 [==============================] - 937s - loss: 0.4301 - acc: 0.8725 - val_loss: 1.4625 - val_acc: 0.7523\n",
      "Epoch 115/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4384 - acc: 0.8700Epoch 00114: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.4384 - acc: 0.8700 - val_loss: 1.4692 - val_acc: 0.7513\n",
      "Epoch 116/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4477 - acc: 0.8671Epoch 00115: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.4478 - acc: 0.8671 - val_loss: 1.4928 - val_acc: 0.7389\n",
      "Epoch 117/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4462 - acc: 0.8668Epoch 00116: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.4463 - acc: 0.8668 - val_loss: 1.4609 - val_acc: 0.7516\n",
      "Epoch 118/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4097 - acc: 0.8786Epoch 00117: val_acc improved from 0.75474 to 0.75701, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 934s - loss: 0.4097 - acc: 0.8786 - val_loss: 1.4582 - val_acc: 0.7570\n",
      "Epoch 119/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4429 - acc: 0.8687Epoch 00118: val_acc did not improve\n",
      "267475/267475 [==============================] - 940s - loss: 0.4428 - acc: 0.8687 - val_loss: 1.4507 - val_acc: 0.7544\n",
      "Epoch 120/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4225 - acc: 0.8737Epoch 00119: val_acc did not improve\n",
      "267475/267475 [==============================] - 937s - loss: 0.4226 - acc: 0.8737 - val_loss: 1.4761 - val_acc: 0.7532\n",
      "Epoch 121/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.8622Epoch 00120: val_acc did not improve\n",
      "267475/267475 [==============================] - 935s - loss: 0.4715 - acc: 0.8622 - val_loss: 1.5287 - val_acc: 0.7323\n",
      "Epoch 122/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4639 - acc: 0.8621Epoch 00121: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.4640 - acc: 0.8621 - val_loss: 1.4414 - val_acc: 0.7565\n",
      "Epoch 123/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4197 - acc: 0.8748Epoch 00122: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.4198 - acc: 0.8748 - val_loss: 1.4562 - val_acc: 0.7524\n",
      "Epoch 124/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4090 - acc: 0.8784Epoch 00123: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.4090 - acc: 0.8784 - val_loss: 1.4679 - val_acc: 0.7522\n",
      "Epoch 125/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4123 - acc: 0.8772Epoch 00124: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.4123 - acc: 0.8772 - val_loss: 1.4662 - val_acc: 0.7550\n",
      "Epoch 126/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4128 - acc: 0.8772Epoch 00125: val_acc did not improve\n",
      "267475/267475 [==============================] - 931s - loss: 0.4129 - acc: 0.8772 - val_loss: 1.5775 - val_acc: 0.7273\n",
      "Epoch 127/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4330 - acc: 0.8709Epoch 00126: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.4330 - acc: 0.8709 - val_loss: 1.4775 - val_acc: 0.7547\n",
      "Epoch 128/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4200 - acc: 0.8745Epoch 00127: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.4199 - acc: 0.8745 - val_loss: 1.4689 - val_acc: 0.7540\n",
      "Epoch 129/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4300 - acc: 0.8721Epoch 00128: val_acc did not improve\n",
      "267475/267475 [==============================] - 936s - loss: 0.4299 - acc: 0.8721 - val_loss: 1.4938 - val_acc: 0.7520\n",
      "Epoch 130/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4053 - acc: 0.8786Epoch 00129: val_acc did not improve\n",
      "267475/267475 [==============================] - 935s - loss: 0.4053 - acc: 0.8786 - val_loss: 1.5035 - val_acc: 0.7516\n",
      "Epoch 131/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4073 - acc: 0.8780Epoch 00130: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.4072 - acc: 0.8781 - val_loss: 1.4836 - val_acc: 0.7534\n",
      "Epoch 132/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4059 - acc: 0.8783Epoch 00131: val_acc improved from 0.75701 to 0.75701, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 932s - loss: 0.4059 - acc: 0.8783 - val_loss: 1.4731 - val_acc: 0.7570\n",
      "Epoch 133/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3988 - acc: 0.8807Epoch 00132: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.3988 - acc: 0.8807 - val_loss: 1.4878 - val_acc: 0.7541\n",
      "Epoch 134/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3944 - acc: 0.8821Epoch 00133: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.3945 - acc: 0.8822 - val_loss: 1.4847 - val_acc: 0.7559\n",
      "Epoch 135/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4205 - acc: 0.8746Epoch 00134: val_acc did not improve\n",
      "267475/267475 [==============================] - 935s - loss: 0.4207 - acc: 0.8746 - val_loss: 1.5803 - val_acc: 0.7293\n",
      "Epoch 136/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4497 - acc: 0.8658Epoch 00135: val_acc improved from 0.75701 to 0.76003, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 933s - loss: 0.4497 - acc: 0.8658 - val_loss: 1.4638 - val_acc: 0.7600\n",
      "Epoch 137/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3762 - acc: 0.8872Epoch 00136: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.3763 - acc: 0.8872 - val_loss: 1.4997 - val_acc: 0.7583\n",
      "Epoch 138/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3892 - acc: 0.8830Epoch 00137: val_acc did not improve\n",
      "267475/267475 [==============================] - 929s - loss: 0.3892 - acc: 0.8830 - val_loss: 1.4900 - val_acc: 0.7582\n",
      "Epoch 139/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4063 - acc: 0.8785Epoch 00138: val_acc did not improve\n",
      "267475/267475 [==============================] - 924s - loss: 0.4063 - acc: 0.8785 - val_loss: 1.4989 - val_acc: 0.7517\n",
      "Epoch 140/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4235 - acc: 0.8740Epoch 00139: val_acc did not improve\n",
      "267475/267475 [==============================] - 925s - loss: 0.4235 - acc: 0.8740 - val_loss: 1.5351 - val_acc: 0.7397\n",
      "Epoch 141/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3983 - acc: 0.8809Epoch 00140: val_acc did not improve\n",
      "267475/267475 [==============================] - 932s - loss: 0.3983 - acc: 0.8808 - val_loss: 1.4773 - val_acc: 0.7573\n",
      "Epoch 142/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3720 - acc: 0.8893Epoch 00141: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.3720 - acc: 0.8893 - val_loss: 1.4981 - val_acc: 0.7582\n",
      "Epoch 143/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4414 - acc: 0.8685Epoch 00142: val_acc did not improve\n",
      "267475/267475 [==============================] - 935s - loss: 0.4413 - acc: 0.8685 - val_loss: 1.5029 - val_acc: 0.7512\n",
      "Epoch 144/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3781 - acc: 0.8862Epoch 00143: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.3780 - acc: 0.8862 - val_loss: 1.4853 - val_acc: 0.7590\n",
      "Epoch 145/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3682 - acc: 0.8893Epoch 00144: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.3682 - acc: 0.8893 - val_loss: 1.4932 - val_acc: 0.7592\n",
      "Epoch 146/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3808 - acc: 0.8857Epoch 00145: val_acc did not improve\n",
      "267475/267475 [==============================] - 930s - loss: 0.3808 - acc: 0.8857 - val_loss: 1.4997 - val_acc: 0.7588\n",
      "Epoch 147/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3837 - acc: 0.8846Epoch 00146: val_acc improved from 0.76003 to 0.76276, saving model to models/embeddings8-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 927s - loss: 0.3837 - acc: 0.8846 - val_loss: 1.4874 - val_acc: 0.7628\n",
      "Epoch 148/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3698 - acc: 0.8883Epoch 00147: val_acc did not improve\n",
      "267475/267475 [==============================] - 927s - loss: 0.3697 - acc: 0.8884 - val_loss: 1.5212 - val_acc: 0.7581\n",
      "Epoch 149/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4375 - acc: 0.8705Epoch 00148: val_acc did not improve\n",
      "267475/267475 [==============================] - 934s - loss: 0.4377 - acc: 0.8705 - val_loss: 1.5242 - val_acc: 0.7475\n",
      "Epoch 150/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.3892 - acc: 0.8830Epoch 00149: val_acc did not improve\n",
      "267475/267475 [==============================] - 933s - loss: 0.3892 - acc: 0.8830 - val_loss: 1.4937 - val_acc: 0.7600\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 256\n",
    "epochs = 150\n",
    "\n",
    "history = model.fit([X_melody_train, X_chords_train], Y_chord_train, epochs=epochs, validation_data=([X_melody_valid, X_chords_valid], Y_chord_valid), batch_size=batch_size, callbacks=[bp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96a9ccc6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFkCAYAAADWs8tQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd8leX5x/HPlU0WZBBCwggywwwQGQIqgogi4ta6irO2\nto6ftdXWqrW21WrrqtZdWwfWPVEERQFBluy9RwKBAAkhe9y/P54DhhAgISckwPf9ep0XOc+47+t5\nTjT3c517mHMOEREREREREZHGLKChAxARERERERERORwlMERERERERESk0VMCQ0REREREREQaPSUw\nRERERERERKTRUwJDRERERERERBo9JTBEREREREREpNFTAkNERBqEmbkavNb7qa4wX3l3H8G5I33n\nDvBHLLWot4uv3qtqcOxWM3uuFmV3MLMHzKxN3aJsGGbWysw+M7Ndvnt0cwPHE++7nz0bMo6aMLOH\nzazoCM7b+/t4eX3EJSIiUhNBDR2AiIicsAZWef8BsAB4oNK2Yj/VVeyrb+MRnDvDd+5iP8VSH84B\ndtXi+A7A/cAkjuyeNLQHgQHAT4FtwNqGDYd4vPu5GljYwLGIiIgct5TAEBGRBuGc+77yezMrBrKr\nbj8YMwt1ztUoweGcc0CNyq3m3NwjPfdocc790NAxmFmIc67kKFWXCsx1zn1c2xNr83sjIiIijYuG\nkIiISKNnZm+Z2WozO9XMvjezQrxv4TGza8zsWzPbbmZ5ZjbXzK6ocv4BQ0h8XenLzKyjmU0ws3wz\nW2dm95iZVTrugCEkvhgmmdnZZjbfzArMbJGZjaom9mvMbKWZFZnZAt8535vZFzW8/GAz+6tvmMgu\nM/vQzFpWqWO/ISRmlmxmb5jZFjMrNrNMM/vYzGLMbCTwue/QqZWG6wzwnRvquzcbzKzEd08eMLOg\nSuXvHU5wg5k9bmZbgCIzG+TbftZBPsO1le9tNccEmNlvzGyVr+4MM3vSzCIq14vX++LMSrEnHqS8\nvZ/daDN71cx2ABsq7R9tZrPMrNB3b98zs/a1jQlY5jv8tUoxHXSoRaXf54FmNtNX/zIzG2Ge35rZ\nRjPL9cUUV+X8Zmb2L9/nXmJmy83sl9XU08/Mpvt+9zbZQYZQmVmwmf3B93tabGabzewRMws52DWI\niIg0BPXAEBGRY0U88BrwCLAUyPdtbwe8hdd9H2Ao3oNkiHPu1cOUacD7wMvAo8CFwF+A9cC4w5yb\nCvwN+Cve8I3fAu+bWSfn3AYAMzsX+A/wLnA70AL4FxAGzD/cBfvcD3wLjAWSgceAV4EDkgSVvAXE\nAf8HZACJwJm+emcAdwCPAz/jxyEPe4fIjANGA3/C63lyKvAHoA1wXZV6/ghMB24AQoBZvvJ+BkzY\ne5CZNQcuAO739YY5mMd8sT2Bl2Tp6Yuju5kNx/tcBgL/BnJ8xwLsOESZAM8BnwA/8d0DzGwM3rCl\nL4BLgabAQ8A0M+vlnNtWi5gux7vnD1S67lWHiSkO7/fuESDLd+4HwIt49/pmvM/7CbzP6hpf3EG+\nOroC9wLLgTHA02YW65zbm9hLxBsitAG4GijH+x1NqiaWt/F+P/6C9xl2x0sQtgKuPMx1iIiIHD3O\nOb300ksvvfRq8Bfeg+DrB9n3FuCAsw5TRgBecv41YGal7WG+8++utO1h37afVNpmwErg40rbRvqO\nG1Bp2/d482q0rbStle+4/6u07Qe8oQ6VYzzFd9wXh7mWLr7jJlTZfq9ve2ylbVuB5ypdQwlw0yHK\n3ntNg6tsT696n3zbH/Jt71wltunVlH0zUAq0rLTtN76YEg4RU6LvvOeqbL/BV9eIStvmHO7+VbnO\ncdXsWwwsAQIqbeuM96D/l9rEVOl+XFXD3/W9v8/9Km3r59u2ELBK258FCiq9v9h33OVVynwdKACa\n+t7/HSgEEisd0xQv8VNUaduZvvIurVLe9b7tqVWu8fKaXKNeeumll1561cdLQ0hERORYUeCcm1B1\no29YwdtmlgmU4T1wXoX3MFoTn+39wTnn8B5qa7I6xxLn62nhO3cz3sNhG19coUAaXu8LKh03HdhS\nw9j2i89nke/famP0XcNc4Hdm9ksz61aLuk71/ft6le2vV9m/14fVlLH3Qfp6AN+QkZuAD9yPvRqq\ncwpe8qlq3W/4/j3tEOcezgeV35hZLNANL7FRsXe7c24FMLtSXfUZ007n3KxK75f7/p3o+wwrb29i\nZvG+96fiJYPeqVLe60ATvEQIeD1Vpjrntu49wHnzuXxe5byReL2ZPjKzoL0v4Evf/iG1vzQREZH6\noQSGiIgcK7ZW3WBmzfC6yXcB7gIGAyfjPWCG1aDMcufc7irbimt47s5qtlU+NxGvN0R1D+1ZNSj/\nYPXsnYDyUDFegDc04vfAYt+cBvvN7XEQsb5/q97rrVX273VAIsY5twevB8yNZhYADAfa4w3jqEnd\n+5XpnCsEcqupuzaqxlltXT5bK+2vz5iqrhpTcpjtez/vWGCbc668ynFVP6OWVP97VnVbAhABFOEl\n//a+9q5OE4eIiEgjoTkwRETkWFHd3AlD8OYJON85N2fvRjMLPmpRHVwWXswJ1exrQe2SGLXi+9b9\nZuBmM+sKXIs3v8FWvPkjDmZvsqQF3twZeyVW2b+vqoOU8yxwC3C2r+6VzrnJhwl7b9mJwJq9G82s\nCRBdTd21UTXOynVVlVhpf33GdKR2As3NLKBy7xEO/Iy24H2OVVXdtgPIA844SH0ZB9kuIiJy1KkH\nhoiIHMvCff+W7t1gZgnAOQ0Tzo+cc0V4E3VeXHm7mQ3C+3b8aMWx1Dl3F96wju6+zXt7cTSpcvi3\nvn+rrqBxZZX9h63Td+zv8SaYfL4Gp03HGwJUte4r8HqyfFOTumsY3068OTAurdwrxcw64s0Dsreu\nmsZ0sPtZH74FQvF62VR2Jd6cF3uHpcwAhlReocXMmuIllSr7AogCQp1zc6p51Wa4k4iISL1SDwwR\nETmWTcUbv/+8mT2I9634fXi9G1o1ZGA+9wGfmNk7wCt435LfjxdfxaFOPFJm1gL4CHgTWIE3KeXF\neA/XE32HLffVf4OZ5eMNU1jmnJtrZh8AfzGzMLyH4SHAPcC/nXMraxHKs8D/8IYmvHq4g51zW83s\naeB2MyvCm4OhJ95qGF/jDRXyp3vx5sb4yMyeB5rhrS6yHXiyljFtBnYDV5rZCrxk0RrnXNXhIP7w\nEd7n8oqZJeF9xufhzftyv2+eC/BW1bkRmOj7b6MMuBuvt8W+4UfOuS/M7H3fffgH3gSp4K3uMwr4\nVeW5XkRERBqSemCIiMgxyzmXCVyE93D+Ht4D6NNUmTizoTjnPsVb/jQNb8LL/wN+iTfPQe7Bz6yT\nPXgTfd6Md0/e89V/mXPuC19cW4DbgP7AFLyJK3v4zv8JPy6x+hneEpwP4U3EWRsf4fWMedfX46Em\nfo33kH2+r+47gZeA86pMbFlnzrmP8HqHJOLdo2eAeXgrs1Set+SwMTnnSvFWJkkEvsK7n4da5rYu\ncZf5yh6H18PlU7x5Rn7lfEuo+o7b6tuehzfB51N4CZs3qpaJt4zsX/E++4/xllW9GW+54sMtUSsi\nInLUmJ/bAyIiInIIZtYOb6nW3znnHm3oeOqLmY3Gexge7Jz7rqHjERERkWOfEhgiIiL1xDfnwF/w\nvpXfibcax2+BGKCrc257A4ZXL8ysA951PgXscM6d0sAhiYiIyHFCc2CIiIjUn1K8uTiewVuOcg/e\nJIz3HI/JC5+H8Ib1zMNbgURERETEL9QDQ0REREREREQaPU3iKSIiIiIiIiKNnhIYIiIiIiIiItLo\nKYEhIiIiIiIiIo2eEhgiIiIiIiIi0ugpgSEiIiIiIiIijZ4SGCIiIiIiIiLS6CmBISIiIiIiIiKN\nnhIYIiIiIiIiItLoKYEhIiIiIiIiIo2eEhgiIiIiIiIi0ugpgSEiIiIiIiIijZ4SGCIiIiIiIiLS\n6CmBISIiIiIiIiKNnhIYIiIiIiIiItLoKYEhIiIiIiIiIo2eEhgicgAze9XMHqrhsevNbHh9xyQi\nIiInJn+1S2pTjog0TkpgiIiIiIiIiEijpwSGiBy3zCyooWMQERERERH/UAJD5Bjl6yJ5l5ktNLN8\nM3vZzFqY2edmlmdmk8wsptLx55nZEjPLMbNvzCy10r7eZvaD77z/AWFV6jrXzOb7zp1uZj1rGOMo\nM5tnZrvNbJOZPVBl/2BfeTm+/WN925uY2d/NbIOZ5ZrZNN+2081sczX3Ybjv5wfM7F0ze93MdgNj\nzayfmc3w1bHFzP5pZiGVzu9mZhPNbKeZZZnZ78ws0cwKzCyu0nF9zGy7mQXX5NpFREROJMdCu6Sa\nmG80s9W+NsDHZpbk225m9riZbfO1YRaZWXffvnPMbKkvtgwz+/UR3TAROSJKYIgc2y4CzgQ6AaOB\nz4HfAc3x/vu+FcDMOgHjgNt9+8YDn5hZiO9h/kPgNSAWeMdXLr5zewOvAD8D4oDngY/NLLQG8eUD\n1wDNgFHAz83sfF+5bX3xPu2LKQ2Y7zvvMaAvcIovpt8AFTW8J2OAd311vgGUA3cA8cBAYBjwC18M\nUcAk4AsgCegAfOWc2wp8A1xaqdyrgbecc6U1jENERORE09jbJfuY2RnAX/H+1rcENgBv+XaPAE71\nXUdT3zE7fPteBn7mnIsCugNf16ZeEakbJTBEjm1PO+eynHMZwFRgpnNunnOuCPgA6O077jLgM+fc\nRN8D+GNAE7wEwQAgGHjCOVfqnHsXmF2pjpuA551zM51z5c65/wDFvvMOyTn3jXNukXOuwjm3EK+x\ncppv9xXAJOfcOF+9O5xz880sALgOuM05l+Grc7pzrriG92SGc+5DX52Fzrm5zrnvnXNlzrn1eA2d\nvTGcC2x1zv3dOVfknMtzzs307fsPcBWAmQUCP8FrTImIiEj1GnW7pIorgVeccz/42hj3AAPNLAUo\nBaKALoA555Y557b4zisFuppZtHNul3Puh1rWKyJ1oASGyLEtq9LPhdW8j/T9nIT3zQIAzrkKYBOQ\n7NuX4Zxzlc7dUOnntsCdvm6aOWaWA7T2nXdIZtbfzCb7hl7kAjfj9YTAV8aaak6Lx+sqWt2+mthU\nJYZOZvapmW31DSv5Sw1iAPgIr4HSDu/bpFzn3KwjjElERORE0KjbJVVUjWEPXi+LZOfc18A/gWeA\nbWb2gplF+w69CDgH2GBm35rZwFrWKyJ1oASGyIkhE+8PPuCN7cT7Y58BbAGSfdv2alPp503An51z\nzSq9wp1z42pQ75vAx0Br51xT4Dlgbz2bgPbVnJMNFB1kXz4QXuk6AvG6nlbmqrz/F7Ac6Oici8br\nylo5hpOqC9z3bdHbeL0wrka9L0RERPylodolh4ohAm9ISgaAc+4p51xfoCveUJK7fNtnO+fGAAl4\nQ13ermW9IlIHSmCInBjeBkaZ2TDfJJR34nW3nA7MAMqAW80s2MwuBPpVOvdF4GZfbwozswjzJueM\nqkG9UcBO51yRmfXDGzay1xvAcDO71MyCzCzOzNJ838K8AvzDzJLMLNDMBvrGtq4Ewnz1BwP3Aocb\n8xoF7Ab2mFkX4OeV9n0KtDSz280s1MyizKx/pf3/BcYC56EEhoiIiL80VLuksnHAtWaW5mtj/AVv\nyMt6MzvZV34w3pcnRUCFb46OK82sqW/oy25qPkeXiPiBEhgiJwDn3Aq8ngRP4/VwGA2Mds6VOOdK\ngAvxHtR34o1Lfb/SuXOAG/G6Uu4CVvuOrYlfAA+aWR5wH5W+pXDObcTrgnmnr975QC/f7l8Di/DG\nvO4EHgECnHO5vjJfwvuGJB/Yb1WSavwaL3GSh9fo+V+lGPLwhoeMBrYCq4ChlfZ/h9cw+cE5V7n7\nqoiIiByhBmyXVI5hEvAH4D28Xh/tgct9u6Px2gy78IaZ7AAe9e27GljvG5Z6M95cGiJylNj+w8tE\nRKQyM/saeNM591JDxyIiIiIiciJTAkNE5CDM7GRgIt4cHnkNHY+IiIiIyIlMQ0hERKphZv8BJgG3\nK3khIiIiItLw1ANDRERERERERBo99cAQERERERERkUZPCQwRERERERERafSCGjqA2oqPj3cpKSkN\nHYaIiMgJa+7cudnOueYNHYe/qG0hIiLSsGratjjmEhgpKSnMmTOnocMQERE5YZnZhoaOwZ/UthAR\nEWlYNW1baAiJiIiIiIiIiDR69ZrAMLORZrbCzFab2d3V7G9rZl+Z2UIz+8bMWtVnPCIiIiIiIiJy\nbKq3BIaZBQLPAGcDXYGfmFnXKoc9BvzXOdcTeBD4a33FIyIiIiIiIiLHrvqcA6MfsNo5txbAzN4C\nxgBLKx3TFfg/38+TgQ+PpKLS0lI2b95MUVFRHcKVvcLCwmjVqhXBwcENHYqIiEiDUNvCv9S2EBER\nf6jPBEYysKnS+81A/yrHLAAuBJ4ELgCizCzOObejNhVt3ryZqKgoUlJSMLO6xHzCc86xY8cONm/e\nTLt27Ro6HBERkQahtoX/qG0hIiL+0tCTeP4aOM3M5gGnARlAedWDzOwmM5tjZnO2b99+QCFFRUXE\nxcWpgeEHZkZcXJy+cRIRkROa2hb+o7aFiIj4S30mMDKA1pXet/Jt28c5l+mcu9A51xv4vW9bTtWC\nnHMvOOfSnXPpzZtXvzSsGhj+o3spIiKiv4f+pHspIiL+UJ8JjNlARzNrZ2YhwOXAx5UPMLN4M9sb\nwz3AK/UYT73Jycnh2WefrfV555xzDjk5B+RrRERE5ASntoWIiMiB6i2B4ZwrA34JTACWAW8755aY\n2YNmdp7vsNOBFWa2EmgB/Lm+4qlPB2tklJWVHfK88ePH06xZs/oKS0REGrnCknLKyisOeUxBSRkV\nFe4oRST+4JyjuOzwn+2hqG0hIiJyoPqcxBPn3HhgfJVt91X6+V3g3fqM4Wi4++67WbNmDWlpaQQH\nBxMWFkZMTAzLly9n5cqVnH/++WzatImioiJuu+02brrpJgBSUlKYM2cOe/bs4eyzz2bw4MFMnz6d\n5ORkPvroI5o0adLAVyYiIodTVFpOcVkFTZvUbnWF7XnFnPfPaQxLTeCh83scsH/Zlt3865s1fLow\nk04torj77C6c1qn5AV3x527YyZszN3HniE4kNdPfjcagwsGKrXm0bBpG86iwIypDbQsREZED1WsC\noyH88ZMlLM3c7dcyuyZFc//obgfd//DDD7N48WLmz5/PN998w6hRo1i8ePG+mbZfeeUVYmNjKSws\n5OSTT+aiiy4iLi5uvzJWrVrFuHHjePHFF7n00kt57733uOqqq/x6HSIi4n8PfLyED+dncPvwTlw/\nuB3BgYfv3FhWXsGvxv3AltwiPlu4hQdGdyPId55zjjvfXsD78zKICAnkJ/3aMHVVNmP/PZtT2sdx\nTo+WpLaMJjYihCcnreTD+ZkAxEeGcM85qfV6rSeqI2lb5BeXERIUcNDfB7UtREREau+4S2A0Bv36\n9dtvmbCnnnqKDz74AIBNmzaxatWqAxoZ7dq1Iy0tDYC+ffuyfv36oxaviIgcmdLyCsYv2kJoUCAP\nf76cj+Zn8shFPejZ6tBd+B/7ciXfr93JqB4t+WzRFmav38XA9t7fhfmbcnh/XgZX9m/DXWd1pll4\nCCVlFbw5cwP/nLyG6WsW7ysnJCiAXw7twILNOXw4P4PfjOxCYIDti+3LJVmM7J64b5scRQbOjyN/\n1LYQERE5DhMYh/o242iJiIjY9/M333zDpEmTmDFjBuHh4Zx++unVLiMWGhq67+fAwEAKCwuPSqwi\nIrK/gpIyZqzZwez1u5i7YSeFpeW8/NOTaRF94FCAOet3sbuojOeu6gPAfR8t4YJnp/OrMzpwy9AO\n1X77PnFpFs99u4Yr+rfh3lGpTFqWxYQlW/clMN7/IYPQoAB+e3YXosO8YSkhQQGMHdSOn56SQkZO\nIcu35LFhZwEjuragdWw4ny3cwi1v/sCMNTsY3DEegHfnbuae9xfx2vX9GNKx+hW8pGaOpG2xNHM3\n0U2CaBUT7pcY1LYQERE5DhMYDSEqKoq8vLxq9+Xm5hITE0N4eDjLly/n+++/P8rRiYg0rNzCUvYU\nl5Fcx/kZMnIKCTBIjA474iUZKyocczfuIjDAiA0PISosiOKyCgpKytm0s4CPF2QyYclWCkrKCQ40\nuiU1Ze32fK7/z2ze/tlAwkP2/7M5aVkWIUEBDOnYnIjQIAa2j+eBj5fwxKRVTF6xnccv7cVJzSP3\nHT93w05ue2sePZKbct+5XQkLDmRIx3gmLs3i/tFdKSmv4OMFmYzolrgveVGZmdEqJvyAh+JhqQlE\nhQXx/g+bGdwxnqLScp76ahV92jRjcIf4I7pXUjcBAd5cGEdKbQsREZEDKYHhB3FxcQwaNIju3bvT\npEkTWrRosW/fyJEjee6550hNTaVz584MGDCgASMVETm6KiocV700k/U78pn0f6dV24vhcLbtLuLv\nX67k7bmbcA6ahQfTuUUUTZsEE2BGaHAA1w5qR1rrQw/bKK9w/Obdhbz3w+aDHhMdFsSYtCTO7ZlE\n37YxhAUHMnn5Nq7/z2xuHTeP569O3zccwznHpGVZDGofR0So9+e0aZNgHr8sjWGpCfz+g8Wc89RU\nfn9OKlcNaMuSzN2MfWU2CVGhvDw2nbDgQABGdEtk0rJtLMnczeZdBeQWlnJhn+Ra3aOw4EBG9WjJ\nxwsyeaikjHGzNrElt4i/X9rriJM9UjcBZnVaPUZtCxERkQOZ8+cAzaMgPT3dzZkzZ79ty5YtIzVV\nE5f5k+6piPjDh/MyuP1/8zGDYV0SePGa9H0P1BUVjgrn9k1eWZ1/f7eORyesoLS8gp8OTKFNXDjL\ntuSxYutuCkrKqXCObXnFlJRV8NJP0zmlvdfbIK+olIlLs+iW1JTOiVGUVzjuesebGPOWoe1JT4ll\nV34JuwtLCQ0OJDwkkJjwEPqfFEtoUOABcbw2Yz1/+GgJ1w5K2TecYFVWHmc+PoU/X9CdK/u3PeCc\nrblF3PXuAqauymZwh3iWZOYSHhLE2zcP3K83yo49xZz850n8cmgHlm3NY/6mHGbcfcYh70t1Zq3b\nyaXPz+Ch87vz+MSVdGkZxRs31M+DrZnNdc6l10vhDaA+2hZrtu3BjP164Jzo1LYQEZGDqWnbQj0w\nREROQNvzivl4QSb928XSPblprc79YeMuZq3byfDUFnRIOPjDWVFpOY9OWEG3pGjGpCXxl/HL+XhB\nJmPSklmSmcstb/xAckwTXr++f7W9BJZt2c0fP1nKqZ2a86cx3WgbF1FNLV4PjStfmsm1/57NM1f0\nITO3kCcnrWJHfgkA3ZK8FTumrsrmzjM78athHWt1vQBXD0xhXXYBr3y3jj5tYhjdK4mJy7IAGNal\nRbXnJDYN47/X9eO17zfwl/HLiA4L5o0b+h8wlCYuMpT0lFg+mJ/Blpwirh2UUuvkBUB62xhaxTTh\nwU+XUlJWwa9HdK51GeI/AQFGeV3GkIiIiMgBlMAQETnOrcrKIyw4kFYxTahw8OasjTz6xXJ2F5UB\ncHJKDNcOasfZ3RMPOdwga3cRD3++nA/mZQDw8OfL6dOmGZed3Joxacn7hkTs9Z/p68nIKeRvF/dk\nwElxjF+0lQc+XkL2nhL+9sVyAgOM9TsKGL9oK6N6tjygvscnriQqLIinL+9N0/AD54PYKyE6jLdu\nGsDVL8/ihv9636L3bxfL08M6sjIrj/fnZTB1VTZ3ndWZW4Z2qPX92+uec7owf9Mu7nl/ET1bNWXS\n0ix6tmpKYtODD4sxM64ZmMKZXVsQFBBA86jQao87q1sif/p0KQAX9W11RPEFBBgX9E7m6a9XMzy1\nBb3bxBxROeIfAQalSmCIiIj4lRIYIiLHsc27CjjriSlUOIgKDaJpeDCbdxVySvs4fjuyC7PX7+Q/\nM9bzizd+4KI+rXj4oh77Vs74enkWL0xZS35xOSVlFWzcWUC5c9wytD2XprdmwpKtvDNnM799bxF/\n+2IFVw1oy8V9WxET4S37+c/JqxnauTmDfJNIPnpxT0Y9NY0/fbqUQR3iePzSNK55ZRYPf7GMYakJ\n+yVAFm3O5culWdwxvNMhkxd7xUWGMu6mATw+cSVDOsZzRpcEzIxTOsQzdlA7dheVVjspZm0EBwbw\n1E96M+qpadz037ms3JbHHcM71ejclk0PPYHpiK4t+NOnS+naMpouidFHHONlJ7dm2ups7j5bvS8a\nWoAZ5cfYMF0REZHGTgkMEZHj2JSV2VQ4+PWITmzdXcSmnYXcdVZnzuuVhJnRq3Uzrh3Ujqe/XsUT\nk1axfU8xT1yWxlNfreLV6etJiQunXXwEoUGBpKfE8LNT29MmzlsB46ZT23PjkJP4fu1OXpq6lie/\nWsWTX63aV3eAwT3n/DjevWOLKP5+aS+25hZx3eB2BAYY947qylUvz+TV6eu5+bT2+479+8QVNAsP\n5rrBKTW+1qZNgnngvOqXu6xr8mKvVjHh/O3invzstbkADE+tfvhIbbWODefm09rTv11sncppFRPO\nB78Y5JeYpG4CAowKJTBERET8SgkMEZFjiHOOp75aDcCFfZJpHeslE9Zn5zNtdTZndEkgqdIcC9+t\nziYxOoxbhnY46PCQwADj9uGdaNk0jN99sJgBf/mKkvIKrh2Uwm9HdjlgaEhlZsbA9nEMbB/H6m17\n+H7tDgpKysgvLqd9QiSdWkTtd/zoXkn7vR/cMZ5hXRL459erubhvK+IjQ5m7YSffrNjO3Wd3IcpP\niQd/OqtbIj8/vT3fr91Basuow59QQ3ef3cVvZUnDC7C6LaMqIiIiB1ICQ0TkGPLct2t5fNJKAB6f\ntJJ+KbHsKihh1bY9AJyflsQTl/cGvGVDv1uTzfDUFjVaSvOyk9vQPCqUp75azW3DOjK0S0KtYuuQ\nEHnIST0P5nejUjnr8Smc9fgUosKCyCksJT4ylGsGHriyR2Px25FKNsihBZrhnLfSToCWshUREfGL\n2k9zLnUWGek18DMzM7n44ourPeb000+n6pJuVT3xxBMUFBTse3/OOeeQk5Pjv0BFpN4Ul5UzZeV2\nHv58OWO6u5x6AAAgAElEQVSe+Y5b3vxhvxULysoruO7V2Vzx4ves2e4lJ75ensXfJizn3J4tmfqb\nodx5ZidyC0uJiwzhvnO7MqpnS75cmkVBiTc559LM3eQUlDLYNwdFTZzRpQUf3jKo1smLumjfPJLH\nL0vjtM7NSWvdjMEd4nnkoh6EhyjHLseugErLBR8NaluIiMiJQK3DBpSUlMS77757xOc/8cQTXHXV\nVYSHe13Ix48f76/QRKQeZe8pZuy/Z7E4YzfBgUanFlF8tnALHRMiud03KeQTk1bx9fJtRIQEcvaT\nU7luUDve+H4DXVtG8+jFvWgSEsivhnXcb0nQ7uua8tnCLUxcmsWYtGSmrt4OsG8SzcZsdK+kA4aX\niBzLAgJ8CYyjPA+G2hYiInI8Uw8MP7j77rt55pln9r1/4IEHeOihhxg2bBh9+vShR48efPTRRwec\nt379erp37w5AYWEhl19+OampqVxwwQUUFhbuO+7nP/856enpdOvWjfvvvx+Ap556iszMTIYOHcrQ\noUMBSElJITs7G4B//OMfdO/ene7du/PEE0/sqy81NZUbb7yRbt26MWLEiP3qEZHambFmB6OfnsZj\nE1awelseADvzS/h25XZe/34D42Zt5O05m/h6eRZFpeWAtyrIJc/NYPW2PTxxWRoL7h/Bp78azIW9\nk3nyq1V8tzqbqau288w3q7k0vRWT7zqd4akJPPftGkKDA3jhmnSahFQ/J0V62xiSmzXZt8zptFXZ\ndEmMOujSnSJSf3z5iyOeB0NtCxERkQMdfz0wPr8bti7yb5mJPeDshw+6+7LLLuP222/nlltuAeDt\nt99mwoQJ3HrrrURHR5Odnc2AAQM477zzDjoO/V//+hfh4eEsW7aMhQsX0qdPn337/vznPxMbG0t5\neTnDhg1j4cKF3HrrrfzjH/9g8uTJxMfv/+3q3Llz+fe//83MmTNxztG/f39OO+00YmJiWLVqFePG\njePFF1/k0ksv5b333uOqq67yw00SObGUllfw+w8XsW13MUsyc/nn5NXER4aQvaek2uObBAdyeufm\nzNuYQ0FJGa9f35/0lB9XnHjogu4szMjltrfmAdCheSQPnNeN8JAgnr2yL9+tzqZFdCjJzQ6+HGdA\ngDEmLYnnp6xl084C5qzf1ajnkRA5ZhxB2yKyooKTSisIDgmE6v72q20hIiJSa8dfAqMB9O7dm23b\ntpGZmcn27duJiYkhMTGRO+64gylTphAQEEBGRgZZWVkkJiZWW8aUKVO49dZbAejZsyc9e/bct+/t\nt9/mhRdeoKysjC1btrB06dL99lc1bdo0LrjgAiIiIgC48MILmTp1Kueddx7t2rUjLS0NgL59+7J+\n/Xo/3QWRY19OQQkTl2YxomsiTcMPvfrFf2dsYO32fF7+aTo9WjXlkwVbWJKRS+fEKHokN+Wk5pE4\nHGXljvU78pmwZCsTlmQRHGD872cDSW0ZvV95XqKiD2P++R0Ox5s3DthvDoiaDgO5oHcyz36zhvs/\nXkJJeQWDOzb+4SMix6N9SQXnqk9gHIbaFiIiIgc6/hIYh/g2oz5dcsklvPvuu2zdupXLLruMN954\ng+3btzN37lyCg4NJSUmhqKio1uWuW7eOxx57jNmzZxMTE8PYsWOPqJy9QkN/7EoeGBiobp4ieHNS\nvDR1Ha/NWE9+STlPNFvFUz9Jo2/b2GqP35lfwpOTVjKkYzxndEnAzLh+cLuDlt86NpwhHZvz4Hnd\nMeOg35Z2ahHF6zf0p8K5A5YframOLaLolhTN18u3ERIYQL921V+DiNTCEbQtSkrKWLttD23jImja\n5MiWA1bbQkREZH+aA8NPLrvsMt566y3effddLrnkEnJzc0lISCA4OJjJkyezYcOGQ55/6qmn8uab\nbwKwePFiFi5cCMDu3buJiIigadOmZGVl8fnnn+87Jyoqiry8vAPKGjJkCB9++CEFBQXk5+fzwQcf\nMGTIED9erUjj9t8Z65m0NGu/bTkFJTw2YQXvzNlESVkFAEWl5Tz11SqGPDKZF6as4YzUFjxzRR8C\nAuDS57/nH1+u4I2ZG3h0wnJ+/8EiPpyXQU5BCf+YuIL8knLuO7drjZYn3SsgwA57fN+2MZycUrek\nw/lpyQD0adtMK3mINJB9q5DUYRJPtS1ERET2p5atn3Tr1o28vDySk5Np2bIlV155JaNHj6ZHjx6k\np6fTpUuXQ57/85//nGuvvZbU1FRSU1Pp27cvAL169aJ379506dKF1q1bM2jQoH3n3HTTTYwcOZKk\npCQmT568b3ufPn0YO3Ys/fr1A+CGG26gd+/e6tIpJ4RZ63Zy30dLALgsvTX3je7Kooxc7vjffLbk\net8wPvblCi7o3YpPFmSSkVPIqB4tuXNEJ05q7i1DOKRTPPe8v4invl4NQGCA0SQ4kDdmbiQwwKhw\njmsGtKXjEfaSqG/npSXx6JcrOOMoLoUqIvvbtwpJHZZRVdtCRERkf+aO8vJedZWenu6qrmG+bNky\nUlNTGyii45PuqRyLnHNc+K/pZOYUckHvVjw/ZQ0JUaFsyysmJS6CJy9PY1dBKS9MWcN3q3fQJTGK\n+0d3Y2D7uGrLWrN9DxGhQSREhWHA/M05fLUsi7Xb8/nrhT1oFh5y9C+yhjJyCkmICiU4UB3txP/M\nbK5zLr2h4/CX+mhblFc4lmTm0rJpGM2jwuoa4nFBbQsRETmYmrYt1ANDRBq9xRm5ZOQU0iY2nNax\n4USGVv+/ri8Wb2XexhweuagHl53chqGdm/O7DxZxeqcE7hvdlQjfead1as72vGJiwoMJOsgDvpnR\nIWH/HhZ92sTQp02Mfy+unhxqtRIRqX91XUZVREREDqQEhog0qPIKx+z1O5m8fBuTV2xjT1EZw1Jb\nMLJ7IgUl5bw4dS2z1u3c75wr+7fhzxf02G9baXkFf5uwgo4JkVzUpxUA/U+K46s7T6+23uZRodVu\nFxHxBzMjwKxOQ0hERERkf0pgiEiDWZ+dz23/m8+CTTkEBxr92sWSEhfBO3M38dr33uR0yc2acO+o\nVE5OiWXzrkLenLWBj+Zncv/oboQE/dh74q3Zm1iXnc9L16QftFeFiMjRFGBG+TE2VFdERKQxO24S\nGM65Wq0GIAd3rM2LIsce5xzv/ZDB/R8tJigwgEcv7snI7olEhXlLDRaWlPPtyu0ADE9N2JeQ6NW6\nGSFBAdz43znMXr+TQR3iAa8XxzNfr6ZfSizDUjVxpYj4R13bFgEBGkKyl9oWIiLiD8dFAiMsLIwd\nO3YQFxenJEYdOefYsWMHYWGacEyOTEWFI7ewlJiI6ie4LK9w/OGjxbw5cyP928Xy+GVpJFWZr6FJ\nSCAjuydWe/6gDnGEBAXw9fJt+xIYM9fuYOvuIu49N1X/DxARv/BH20JDSDxqW4iIiL8cFwmMVq1a\nsXnzZrZv397QoRwXwsLCaNWqVUOHIceYigrH54u38vTXq1i7PZ+v7jyN1rHh+x1TXFbOHf+bz/hF\nW7n5tPbcdVZnAgNq92AQHhLEgJPimLxiG384tysAH87PIDI0iOGpLfx2PSJyYvNH22J7XjEGFG7X\nnDtqW4iIiD8cFwmM4OBg2rVr19BhiJywFm7O4a53FrIiK4/WsU0oKa/gm5XbuXpA233H5BeXcfPr\nc5m6Kpt7R6Vyw5CTjri+Mzo354FPlrJhRz4tosP4fNFWzuqWSFhwoD8uR0TEL22Lv74yi9zCUj66\nJc1PUYmIiJzYNNOdiNRYSVkFu/JL9hvL/N7czVz83Az2FJfx5OVpfPProbSKacLUlft/a/nct2uY\ntjqbRy/uWafkBcDQLt48F18v38Y3K7aRV1zGmLSkOpUpIo2bmbU2s8lmttTMlpjZbdUcc7qZ5ZrZ\nfN/rvoaIda/I0EDyi8saMgQREZHjynHRA0NEDs05x8x1OzmpeQQJUbUbgzx9dTYPf7GcjTsLyCko\nBbyVQU5pH4cZvD1nMwNPiuOZK/sQ65v3YkjH5ny6IJPS8gqCAwNwzvHpwi0Mah/PJemt63w9beMi\nOKl5BF8v30ZESBDxkaGc0j6uzuWKSKNWBtzpnPvBzKKAuWY20Tm3tMpxU51z5zZAfAcIDwmiQAkM\nERERv1ECQ+Q4VlHh+GLJVp7+ejXLtuzmtE7N+c91/Wp0bmFJOY98sZxXp68nJS6cc3u2pHlkGE1C\nAvhhQw5fLs0it7CUawel8LtzUgmutHTpkI7xjJu1kQWbckhPiWXZljzWZedzYx17XlR2RucE/jtj\nAxhc2b+Nlk4VOc4557YAW3w/55nZMiAZqJrAaDQiQgLJLylv6DBERESOG0pgiBxHVmXl8e4Pm1ma\nuZvtecVsyS0it7CUk5pHMKJrC75cmsXqbXl0SIg6ZDm5haVc+Ox3rNmez7WDUvjNWV1oErL//BLl\nFY6cghLiIg+cnO6U9nEEGExZlU16SizjF20hwGBEN/9Nsjm0SwIvTVsHwJi0ZL+VKyKNn5mlAL2B\nmdXsHmhmC4BM4NfOuSUHKeMm4CaANm3a1Euc4aFBFJSoB4aIiIi/KIEhcowrKavgo/kZvDlrI/M2\n5hAUYHRNiqZVTDh92sZwSvs4zu7ektzCUr5d+RUvT1vPXy/sAXi9LH7z3kIu6J3EGV1+TC489+0a\n1mbn8+q1J3N654Rq6w0MsGqTFwDNwkPo2aoZU1dt547hHRm/aAsDTooj/iDHH4mTU2KJDA0iPjKE\nXq2a+q1cEWnczCwSeA+43Tm3u8ruH4C2zrk9ZnYO8CHQsbpynHMvAC8ApKen18tapxEhgZSWO0rK\nKggJUi8xERGRulICQ+QYtbuolLdmbeTlaevI2l1Mx4RI7h2Vyvm9k6tNFMRGhHBhn2Te/2Ezd53V\nmdiIEB76bCmfLMhk6qrtfHnHqSREhbElt5BXpq3j/LTkgyYvauLUjvH8c/JqZq/fxdrsfK4b7N+V\ngkKCAvjzBd2JCQ/BrHZLsYrIscnMgvGSF284596vur9yQsM5N97MnjWzeOdc9tGMc6+IUK+ZVVBS\nRkhQSEOEICIiclxRAkOkkcgtLGX1tj2ktW5GYMCBD+QVFY612flMW7WdScu2MXPdDkrLHae0j+Nv\nF/fi1I7xh32Qv3ZQO8bN2sS4WRvpmBDJGzM3MrpXEhOWbOX3Hyzmhav78vjElTgH/3dmpzpdz5BO\nzXnq69Xc99FiAgxGdk+sU3nV0dARkROHef+DexlY5pz7x0GOSQSynHPOzPrhrba24yiGuZ+IEK+Z\ntae4jGbhSmCIiIjUlRIYIo3A4oxcfvbaXDJyCklu1oQr+rdhcId41mXnsyIrjyWZu5m/cRe7i7yx\n1O2bR3Dd4Hac2yOJHrUYPtGpRRRDOsbz6vT1lJVX0C0pmscu6UmP5Gj+Mn45f/9yJe/O3cx1g9rR\nOja8TteU1roZkaFBLN+ax0A/Dx8RkRPSIOBqYJGZzfdt+x3QBsA59xxwMfBzMysDCoHLXeV1n4+y\n8FBv7qACTeQpIiLiF/WawDCzkcCTQCDwknPu4Sr72wD/AZr5jrnbOTe+PmMSaQiFJeXM2bCTsgqv\nHR0UYMRHhtIiOozJy7fxuw8WERcRwkPnd+fzxVt4dMIKHp2wYt+xHRIiGdUzid5tmnFySizt4iOO\nOJbrB7dj7L9nExYcwJOX9yY0KJDrB5/E54u38s/Jq4kKC+KWoR3qfM3BgQEMbB/HxKVZnNOzZZ3L\nE5ETm3NuGnDIbmbOuX8C/zw6ER3e3h4Y+VpKVURExC/qLYFhZoHAM8CZwGZgtpl9XGW99nuBt51z\n/zKzrsB4IKW+YpITV05BCfM25rBpVwEZuwpJbRnNeb2SCKhmqIY/bd5VwGvfb+CtWZvILSw96HED\nTorlmSv6EBcZylUD2rJ62x5WZeXRPiGSlLgIv07+dlqn5vykX2uGdGxOh4RIwJuQ87FLenHhs9O5\nY3hHYiL809X57O6JTF+dzchu/h8+IiLSaBXugudOJaXLjUB79cAQERHxk/rsgdEPWO2cWwtgZm8B\nY9h/vXYHRPt+boq35JmIX2XtLuL8Z75jS24R4D2sl1c4Xpiylt+PSmVQh3i/1FNYUs7SLbks3JzL\nos25LNicw9rsfALMGNktkUvSW9G0STAApeWO7XnFbMsrIiQogMvSWxMU+GOSokNC5L7kgr+ZGX+9\nsOcB29s3j2T274f7NVlyQe9kRnZPJDxEo9VE5AQS2hTythBZlAm0Vw8MERERP6nPp4pkYFOl95uB\n/lWOeQD40sx+BUQAw+sxHjnOFZWW8/Dny8kpKOH+0d2IiQihsKScG/87h9zCUl4Zm073pKbERYby\n6cJM/vbFCq58aSa3ntGB/xvR+YjrnbVuJw9+uoSlmbvxjRChRXQoPZKbcWGfVpzfO5nkZk38dJX1\ny9/L/JmZkhcicuIJCIDoljQpzAIgv0QJDBEREX9o6CeLnwCvOuf+bmYDgdfMrLtzrqLyQWZ2E3AT\nQJs2bRogTGnsNu0s4OdvzGVxxm6CAowZa3fw+KVpvDFzI4sycnnx6nTO6NJi3/Fj0pI5q1siv35n\nAf/6dg0X9Gl10HklsvcUExESRJOQwP22l1c4np28mscnraRVTDi/HNqBnq2a0aNVU1pEh9Xr9YqI\nSCMX3YqQ/C0A5BdrCImIiIg/1GcCIwNoXel9K9+2yq4HRgI452aYWRgQD2yrfJBz7gXgBYD09PQG\nm01cGqcpK7fzq3HzqHCOF69Jp2XTMG59ax5XvDQTgN+d04XhXVsccF5YcCD3je7K5OXb+Ov4Zbxw\nTfp++3fml/DYlyt4a9ZGzIyOCZH0SG5KWHAgpeUVrMjKY97GHMakJfHQ+d2JCgs+KtcrIiLHgOgk\ngjbPAaBAPTBERET8oj4TGLOBjmbWDi9xcTlwRZVjNgLDgFfNLBUIA7bXY0xyDNlTXMbr328gY1ch\nfzyvW7UTbn44L4Nfv7OADgmRPH91X9rGeb0oPv3VYP72xQrCQwK5cchJB60jISqMXwztwKMTVjBj\nzQ4Gto+jrLyC17/fwD8mriS/pJyrBrSlWZNg5m/OZfKKbZRXOIIDA4gMDeKRi3pwaXprzOp3MlAR\nETnGRCdheZmAUw8MERERP6m3BIZzrszMfglMwFsi9RXn3BIzexCY45z7GLgTeNHM7sCb0HNsQ67X\nLo3DrvwSXv9+Ay9/t46cAm/ljjFpSaSnxO533CvT1vHgp0sZeFIcL1zTd78eEOEhQTxwXrca1Xf9\n4Ha8OXMjD322lLvP7sKfPl3Kyqw9DO4Qz32ju9KpRZT/Lk5ERE4MTVth5SUkhxSoB4aIiIif1Osc\nGM658XhLo1bedl+ln5cCg+ozBjk2FJSUMXfDLv43exNfLsmipLyCYV0SuH5wO659dTafLMjcL4Hx\n2oz1PPjpUkZ2S+SJy9MICw48eOGHERYcyG9Gdua2t+Zz9cuzaB3bhOev7suIri3Us0JERI5MdBIA\nKcE57FEPDBEREb9o6Ek85QTjnGNddj6LMnJZkrmbZVt2s2bbHjJ9S5w2Cw/miv5tuLxfa7okeivs\nDktN4LNFW/jDuV0JCgyguKycJ79azcCT4njmyj4EVjO0pLbO65XEvI05JESHct2gdnVKiIiIiOxN\nYLQJ2qUeGCIiIn6iBIbUu4oKxxdLtjJ5+Tamrspm624vWRESFEDnFlH0PymO9s0j6JwYzZCO8Qck\nD0b3TGL8oq18v3YngzvG8/H8TLL3FPP4Zb38krwAb7nPmg45EREROazoZACSA3YxXz0wRERE/EIJ\nDKlXhSXl3P6/eUxYkkXTJsEM7hDP4I7xpLVuRoeESIIDAw5bxtAuCUSGBvHxggwGdYjj5Wnr6Nwi\nisEd4o/CFYiIiByBiAQICCLJdjJdPTBERET8QgkMqTfbdhdxw3/nsCgjl3tHpXLtoHZH1GMiLDiQ\nEV1b8MXirZzdvSXLt+bxt4t6an4KERFpvAICICqJFqXZ5JeoB4aIiIg/KIEhfldQUsb7P2TwzOTV\n5BaW8uLV6Qzv2qJOZY5OS+L9eRnc9e5C4iNDOC8tyU/RioiI1JPoJJpn7yC/WD0wRERE/EEJDPGb\n7XnFvDh1LW/N2sjuojJ6JDflxWvS6Z7ctM5lD+4QT7PwYLL3FHPH8E6aZFNERBq/6CRismZSUKEE\nhoiIiD8ogSF1llNQwvNT1vLqd+spKa/g7O6JXDsohT5tYvw2zCM4MIDRPZN4Z+4mrhzQxi9lioiI\n1KumyTQr3U6+UwJDRETEH5TAkCPmnOOduZt56NOl5BWXcV6vJG4f3ol28RH1Ut/dZ3fh+sHtiI8M\nrZfyRURE/Co6mWBXQmjproaORERE5LigBIYckYycQu55fxFTVm6nX7tYHhzTjS6J0fVaZ0RoEBGh\n+pUVEZFjRLQ3X1N8xQ5KyioICTr8ylsiIiJycHoalFopLivn5WnreObr1TjgT2O6cWX/tgQcweoi\nIiIix7XoZAASbSf5xWWEBIU0cEAiIiLHNiUwpMa+Xp7FHz9ZyoYdBZzZtQX3nduV1rHhDR2WiIhI\n4+RLYLS0neSXlBEToQSGiIhIXSiBIYdVWl7Bw58v5+Vp6+iQEMlr1/djSMfmDR2WiMiJyTlY8j5M\newLSroT+PwM/TZgsfhaZQIUF0tJ2UFBS3tDRiIiIHPOUwJBD2pZXxC/fmMes9TsZe0oKvzsnVWN4\nRUQ2zoTF70GbAdDuVIiI92/5+dmQsxHKS7xXYCiERkJpIXz1R1g3BcLj4YvfwpqvYMyzEFklsZy3\nFT67E4b/EeI7+Dc+qZmAQEqaJNCyzBtCIiIiInWjBIZUq6y8gnGzN/H4xJUUlpTz5OVpjElLbuiw\nRORYVLgL8nfU/CHauaPfo6C0ELavgMQeEBB4+ONnPA3LPoFZz3vvm7aGoFAv0dBmAJz9CAQGV3/u\nloWw9CPYuRZyNkDXMTDotkr7F8ArZ0NpfvXnhzWFUX+HPmNhzsvw5R/gX6fA2E+heecfj5vyKKz8\nAkb8qUa3QOpHaURLEvN2qgeGiIiIHyiBIQeYtiqbBz5Zwupte+jfLpYHx3Snc2JUQ4clInXlHGxb\nCvGdIfAo/e9/0yx460rI3wbJfaHvWOh6PoQdYtWiV8+F0gI493FISjtwf1kJrJ8CrU72HuYr277C\nu87opEPXsVdFBSx6B756EHZvhtiTYOAt0OVc2DQTVk30khsXvrB/YiPjB+h2AQz8JaydDDvWQFkx\nFO/2kgp7suDif0PVSRvLSuC186EwB5q1gZBImHgfBATDwF94vSbG/QSaxMBFL0JwEwgMgbIiKN7j\n1dFh2I89Pvr/DNoOgv+cC5/cBmPHQ0AA7FoPc/8Dva/2rkkaTEVUEolZc1mtHhgiIiJ1pgSG7OfN\nmRu598NFtIkN5/mr+zKiawtMY6tFGpcj6aGQswnG/9r7Rj6pN5z/HCR0qX3dJQVQsMMb1tCszcF7\nGQAseAs+/pU3keHAB358//Gt3kN1Yg/vAbvj8B/Pyc2ADdPAAuDFM7yH+l4/8Xo2gDf3w+yXYc9W\nGHQ7nPnHH8/dtQGeHQCuwnsfGu093Hc+GzqdBZEtvPvmnNf7YdVEmP8GbF0ILXvBoFu9GD+703uB\nl1ioKIXBt3vxAuzeArszoHV/aJXuvSr7/l/wxd3wzli45NX9kxirvvTu3xVvezFVlMM7P4UJ90BI\nOPzwmtdj5boJ0LJnzT6TxO5w5p/g419619PnavjmEe8envabmpUh9Sc6mST7koXFpQ0diYiIyDFP\nCQwBwDnHM5NX89iXKxnauTnPXtmXJiE16EYtciKrKIfsVRAaBRHND/y2vSbKy7x5DPKz4bynDuxR\nUNXuLfDGJd5D//AH9t9XUuA92BfvgZI9UJIPxXle74BpjwMOBtwCC9+C54fA0N/DKbd639gfzLbl\n3kP36omweY7XM2KvgCCIbQ8dhsOIh/YvZ+YL8PldkDIELv0vhMd6CYdNs2Ddt17SYP1UyPwBblv4\nY0Jm7Tfevz/9BBa+DdOf9l6VtR/mzQexYfr+29dP85IXI/4Mrhx2roPVX8HKz739gSFezwYLhLxM\nb1t8Z7jwJeh+kRd/v5tg4wzv1eYUiG4JT/aC9d/9mMDImOv9m9y3+ns24Ode8uDz33hJhQtf+HHf\ngnEQkeBdA3i9Oi58Cd68xOtBAXDZ6zVPXuyVdqWXvJj4B4hr733GA37h9USRBhXYLJkmVkJx3k6g\ndUOHIyL/z959x1Vd7w8cf304TGU5QHCAC/feq1yZpqY5Km2YZrZv697Wbd9f61a33e1mwzItSzNX\n5cjMHFnugXuLC3ACAjI+vz/eEKAgB+VwQN7Px+M8lHO+482J8Hzf3/fn/VZKlWmawFBYa3n5xy18\nvGQPQ1rX4LXhLfByaKNOpS7o2C6YcS8cWJHzXFAE9HwSWoy4cFIgW1oKfDcWts6RC9747XJnPriA\ni5ykeJg4GOK3QWw0NL8eqjWV107ul4qFpLj8963fR/omVIqEbg/DDw/Dz8/BmXhJPpwrbhvMe0oS\nFwChTaRaIjAcKlSRJMCxHXBoLaz4AGp1gKbXybbJJ+CXF6FeL/l+sqs0jIGIjvIAWeIw+wE4uikn\nObB7kSSDIrpA7W7QYZy819nNLGu2lz4PC56F3/8ryzu8/GTf/cvBN1gu3LPff2vhaLQkTRJjIfm4\n7FOroyReKtfJ+30bA5Fd5JEtOAL2LYNOd8vXB1dL8iY75vx0vEvOt+QNaH+HvD9Jx2D7PHkt9xIe\nL18Y8RVMvwvq9oDG1xZ83IJ4eMCANyUx9eUQ8KoA3R4p+nFUsfOrGgFAcvx+oKV7g1FKKaXKOE1g\nKP776y4+XrKH2zpH8ty1TfHw0CUjqhxKOS1VAcd3y8V+YHj+22VmSo+D7L4FfV+RC+ikOFmeMeMe\nWPUZ9H9dlmrkdmKfVB34V5MeBguekwvra16HqlHw7Sj4pDfc9M35+yafgInXSaLixslyZ3/uEzBq\nluyN/EcAACAASURBVFQdfH+PXJgPek8u4n38wTtA/vQNgoDwnCoH/xC44UupEFj+HlRtAG1GyWtn\njsOvr8LKT6Q/w1XPS6IkqGYB70eGNJD85UXpG+HwhOXvQ+opWdZwoSUmDa+B2Qa2/iDJAGulAqNu\nj5wERFjz/BMFEZ1h2TvSi6J2V3lu/wp5PnfyyBhZYhHWrOA4ChPZTapQspfuHFwtiaPsxElBuj0M\naybKz8qYn2RqSWaaLIk5l08AjPzq4mMEqNZEenIsexu6Pw4Vq1za8VSxcGT9v3P2RIybI1FKKaXK\nPk1glHPfrjzA6/O2cV2r6pq8UGXb/GfkgvKKv8s0CICMNIieIRfVNdrKpIhze0ckHIGvbpDJD9kc\nPtD2NlnyEJQ1fSc9VfojLH8Xju2UJQCD3st5HeCKf0jp/oLn4NOrYdyinAvn9FT46kaI25KzvXFI\nL4pWWRe0Y+fD5BvkDvodC2UpAMgykEnDpfJi5NdSOZBwWHpabP1B4tm3VEZptr7ZuffLGEm+HNsJ\ncx6W9yZuqyQvUk9D2zHQ85+Fjwf1cECvp+GbW+R7b9AP/vifNLgsLGngHyqVEFvnQI8npFIiKQ7q\n9iw8/lpZVRz7f5cERmKsfC+tb3Xu+y+KyC6w/iupkKkSJVUnzYcXvp+Pv1TkzHkYtv0kxwhrfmnJ\nlML0eEIqVJoOcd05VNFk/Y5wnD7g5kCUUkqpsk8TGOXYL1uP8uT3G7kiqiqvDW+pyQt1aayVC7y9\nS+Xi+op/SGn8udJSZLzjobXQ8W6I6nPpIzMPr5fEAsDmWTDkQ0lMzH9aLmqzVQyFvi9Di+tzYp71\nAMRth55PS9WDfyis/FiqKP78WBpB+vhL74fkE9Ls8frPZZLGuXF7eECrm6SC439dYfo4SWJ4+Upi\nIG6L9DuoFCnvUXBk3ikboY3htpnwcW9JqoxdAJ6+kvg4tBZu/FKSFyAJhpWfwo+PykV/42vl3EXh\n8JRJGZ/2kckYIMmDvi/L3XxnNRoI1dvI93h4g7xXPZ50ct8B0rfh5H5ZPgJQz4kERoXKENJIqi5A\nEhmQd+lHccmu8Ni7VP5MPQ012hW8fW6tR8lSlx8ekf/mfV8u/vhy8/Ir+s+Bcq2AcJI8AghN2u7u\nSJRSSqkyTxMY5dTR0yk8NGUdjcMD+PCWtnh7as8LdQn2/Q7TxsgFWrazSdDvlbzbxayGmffKnf6K\nodK4MKKzLDWo1f7846acll4McVuk2WJ274Rz/f6BLHcY9K70bRjfQ56vEgUjp8iSjYOrpYJixt1y\n8Vu/tzQ93DEP+r0qjRezDXpPEjDrp8jEiLOJkuxocYMsbygs4eIfAoM/gMnDZTxn82FS1t/qlpzk\nSUEq14URk+GLQbKkxOElzSqHfSIX+9kcnvL+fnkd+IfBwHcuLhHkFyxLVn5+QS58o64u+nGMgd7P\nSix/fgQtbpQqAGdkJzC2/gi7Fsl/Z2cbT0Z0gk3fyzKWfb+Dpx+E5zN29VJVqiNLcPYtz1k2UlAD\nz3M5POGq56RCxThkOY4qX4whLqAxdU7sJCPT4tCbBUoppdRF0wRGOWSt5anvN5Kansm7I1rj76M/\nBuoSJByRMZBeFeDad6Xx4h//gxX/lSaOUX2kb8SS/8CvL8uF4M3fQZ0rYe1EWPwafN4fxsyFmlkX\nhZmZOSMhs/kGw4Pr5YI7t1MHpbdAhztlkkS9XjJCsnJdaDcmpwdDjTaSgJjQXxIDQ8fDT09If4MO\nd53/fVWKhB6PX/z7EtVHmjeu+ACiv5ckQ9+XnNs3soskUWZkNY0c/EH+Sxbq9YRr35GL9kvpd1C5\nLtzwxcXvD5LYqX2FXOR3L8L7VqUehDSW/4ZHNsrSHWdFdIbVn0PsFqnAqNnu4ibBFMYYGce6b5n0\nE/EOkJ4lzmo0UN6fiiFS4aPKnaTKTWlw8kviTiYQVjnQ3eEopZRSZZbedi+HZq47xM9bYnm0b0Pq\nhvi7OxxVlqSlwPpvIOGofJ2RBlPHSI+GEV/JxWeVelJREdoUvr9bmmJOvQ0WvQhNh8K9v8sIUE9v\nucC/d4Vc3H97KyRmTdBY+LwkL9qNhRFfw01TIeVkzjKR3P78SJpYdsy62PerBNe8Ch3vPL+BpG8Q\n3DxNkiFTbgIsXPeBcxNDLkaf/5MqkIRDUh1ybvLlQlqNhEHvw/DPoPUtBW/XdnTeZSjuYgwM/Rhu\nm5XTu8NZjfpDzJ+Qnuxc/4tsEZ3lz50LpAFrRKeinbcoIrtIhdGW2fJ+exRhzLQxcOsMqaJR5ZIN\nb4mPSefEvvWFb6yUUkqpAumt93ImNiGF52ZF0yYimDFd6xS+gypdMtLg+B5JGJxNlPGO546BBEk0\nHFgBuxfL2EiHt0zMOBMvkzASDkvFQpf7Cz5X9sSFbAlH4ZubIWalNLlslZUA2L9cLlxz90zw8pUL\n7/Hd4f0OYDNkVGfn+89fnlChsvR2+KyvLENpPEimS7S/A/q/kbN9s2Gw4kOplgioJs+lJsKqz2Wf\nSpHOvYeB4XDLd5LA6P4YVKrt3H4Xw7uCnOvIRqnIKKo2LmhI6UqB4QVPb7mQRgOkQsfDM6ffhDOC\nIyCgOqz4nySxshMarlC7m/yZFHtxPSYutc+LKtP8ItvAcji7fw20vsLd4SillFJlliYwLnPJZzPY\ndOgU6w+cZN2Bk6zce5zktAxeG95S1+GWFump8shIkwvegkYzHt8jF92xm3OeMx5yd77Hk1Chqozx\nXP817PoF0lPkgtCvMmScleNXqCyNI/1DYf5TEBB2/tKEtBTp17D0bahaH1qMkJGRM++TJpYD35am\nmesmy3Hb3yFLM84V2ggG/EeWc1z7tvScKEj1VjDwLRlBuncJRPWFfv/Oe9HX8ymZKPLb6zDgDXlu\n7SQZ19nlb86917lje2BN0fa5WJUinU+ulFfhrSGwhiSTfAKc388YqbqIni7/L9Tq4LIQqdpA/h87\nE+98/wulsoRENOa0rYBn7EZ3h6KUUkqVaZrAuMxYa4k+dJpZ6w+xZEc8248mkJFpAagR7EfbyEpc\n37YW9UMv06UjmZmAPb+8O+W0/OlbTGuP05JlQkXD/nKRn5+4bTDnEahQSUZUVm8tDfxyX5SvnSxN\nLbN5B8jF/rlJhd2/wtTRUhUx8C256+xdUUZorvwENnwrPSiSj8tyjDa3SS+I2l3zvyBMT4WJ18GM\neyWhUau9NELctQjmPi6TOxoOkKUP85+SfQJrwu3zILyFfN3jSZka0XRowe9T61suvPwht1Y3yXkP\nrpHqDcc5v56q1JOKhNWfS++H6Bly4Vqrk/Q+UGWXhwfcPLXg5N2FRHSWn4OwFkVLfhSVMbKMZMss\n/XlTRRbo582f1KH6iWh3h6KUUkqVaZrAuEycSDrLN6sO8O2qA+yOS8LTw9CpbhXu7VGPljWDaVEr\niNCAfEZaXg6slRGTG76FTdPkQrzdGKkMyEyH5e/DmomyjKFeb2g2VBIPPheZxElLhq9HysX7Ly9C\njyekAiB3vwVrYfZDsi4/sAbsXChNLb39Zb1/9ja/vy93dtvcJvtvmg7fjYU9i6H3c3DgT5mSseZL\n2W7kV9JwMVudK6DT3VJ+f/YMtBwhPQTOvfg/l6cP3DgJPukFU0bKhdnuXyHllExcuGV6TsVE3HZp\nXthoQN4GhAHV5HzFqfezF369++MyGWTKTfJedrgTuj5UvDEo96jW9OL2y+574YrxqefqME6qlpyd\nkqJULvt8omid/INUw53bn0cppZRSTjHWWnfHUCTt2rWzq1atcncYpUJSajqr9p1gzvpDzFp/iNT0\nTDrUrsx1rWtwTbMwKlV0QTf+0iYxFqbfKckEhzc06CuJga0/5K3CaHGjNG6M/l6qCrwqQrMh0PpW\nqNWx4PXpcdukEWVoYxmzWaV+VvLiV+j7svSZ2DwTwprD9V/kNC9c97VMkLj2XWlsmZEO77SUfhWj\n58g2+1dI34fsbUA+2C56GZa+mRODtz80GQzX/Lv47zDHbZcYPH2hfi+p2mjY/+LuhJeU6BnSw6PV\nTdKUU5VvmZnwy//Jz0NRJoOoS2KMWW2tvWxKUUris8X/3n+Vu+NfgbuXQVgzl55LKaWUKmuc/Wyh\nFRhlTGamZfrag0xasY+NB0+RkWnx83IwvG1NRnWuTcMwF5ZQlza7F8P0cVI1cPVL0PpmmUABcGIv\nrPoMMHLXNKimPH/1i5J0WPeVVDusnSTr2a9+8fw7uPuWS7LCeEDcVun5EBAuY0MHfyDn63wvbJ4F\nsx+Ez/pJw8bgCFjwDNRsLwkSkIqIjnfCgmeloWNYc1g1AXwCpTllNocXXPWcjFzcu1QaB0Z0ds1o\nSICQBvD3bXLestJksOl17o5AlSYeHvL/jFKlXFLl5hCP9BDSBIZSSil1UTSBUYas3Hucf83ezMaD\np2gUFsA93evRsW5l2kZWooL3ZfSfcvs8WfIx+IOCx06u/lyWaFSNglu/P7/8vFJt6POv8/fz8JBE\nRWQX6PcqbJwKi1+DCddIz4eG/cDTD5Li4OfnpD/ELdPkTv/qL2SZSu/nZMRltiaDIKQhfDkEPh8g\nFR1njkkyI/d4zjaj4NdXZZLG1S9KNUibW/NfylK3uzxKgquSI0oppf7iU60+idt88T24Fs/WN7s7\nHKWUUqpMuoyuei9fB46f4dW5W/lhw2HCAn15+8ZWDGpZHY/SNkUkKR5+fl4qFNJTpHKh+2M54wez\npSZCykn50+GVs+wC4PAGaVaZdkaWMQz75PzzHNkIPz4qyx1umHjxvSx8/KVXRosbpT/F0rdh2w85\nr9fqBCO/lskdAN0ekkd+QhrC2PmSxNi5QEZ9hrfMu41fJWh1M6z5AipWhYxUaDvm4mJXSilVplSv\nVJFoW5uWMWv1w5dSSil1kfTf0FIs+WwG7y/awcdL9uBh4KGrorjzyrqls9ri+B6YNAxOH5R+EZ5+\ncGovTBwsUzPajIKkY7DwBamuIFfvlebXy8hMmyFLNvwqSVPLPz6UcZotrs/ZNi0ZvrtDthn68cUn\nL3LzrgBX/gM63ydJmPQUmdIR0qjwZpi5BdWEMXNh/VfQdnT+23S8G1Z+DMvegZodtIxYKaWKwBhT\nC5gIVEP+IRlvrX3nnG0M8A7QHzgDjLbWltDc5IKFB/kRnVmbdnGLpdn0udOylFJKKVWoUnglrAB2\nHE3g3slr2BGbyJDWNXisX0PCg0ppY8XD62HScMg4C6NmQURHeT75JEwbA7P+JlM4dv8KZxOlJ0W1\nZpJ8iN0CS9+S8Z0BYbL04va58vqhNfDDI3K84Ag55vxnpB/Frd9DxSrF+314+UFwrUs7RsUqMpGk\nIFXrQ4N+sH2uVH8opZQqinTg79baNcaYAGC1MWaBtXZzrm2uAaKyHh2BD7P+dKsawX58m1kHR8Zc\niN8BoY3cHZJSSilV5mgCoxSauuoAz8zchL+PJ1+O7cAVUSHuDil/1kovivlPy4SP0XNkKUU2v2C4\naSrMfUKqDupcCde8fv6HtibXwcz74PA6uP5zqN5Knh86Hj7sBl8OlUqFjDTYOgc63y/LR8qqnk/J\nZJGmQ9wdiVJKlSnW2sPA4ay/JxhjtgA1gNwJjMHARCtj1lYYY4KNMeFZ+7pNtSAfNlFHvji4ShMY\nSiml1EXQBEYpkpSazjMzNzF9zUE6163COyNaERro6+6w8nfygFRW7F4kiYkhH0Fg9fO3c3jCgDeg\n6wMQVCv/SRdhzeCOhXA6RppvZqtUG4b8Dxa9BEej5bkmg6H3s674jkpOeAsY/qm7o1BKqTLNGFMb\naA38cc5LNYADub6OyXouTwLDGHMncCdARESEq8L8i4+ng1MV6pBgKxGwezG0vsXl51RKKaUuN5rA\nKCW2HjnNfZPXsDs+iQd7R/FA7ygcpa1JJ0DcNvjjf7B+CmBgwH+g7e15p23kJ7iQD4cOz7zJi2yN\nB8pDKaWUymKM8Qe+Ax6y1p6+mGNYa8cD4wHatWtnC9m8WIRXqsjGxFZ02f2rVDGWlfHVSimlVCnh\n0gSGMaYf0kjLAXxirX31nNffAnpmfVkBCLXWFjA38/L1y9aj3DNpDYF+Xkwe25Eu9au6O6TzHd8j\nS0G2zwWHjzTWvPLR/JMOSimllIsYY7yQ5MVka+30fDY5CORuaFQz6zm3qxHsy9KEZnRJWgSxm88f\nAa6UUkqpC3JZAsMY4wA+APog5ZsrjTGzcjfastY+nGv7vyGloOXKoq2x3P3lGhqGBfDZ6PaEBPi4\nO6S8MtJlGsgvL4GHp/RvaHe7jAFVSimlSlDWhJFPgS3W2jcL2GwWcL8xZgrSvPOUu/tfZAsP8uPH\nrQ15zIE0ttYEhlJKKVUkrqzA6ADstNbuBsj6IDGYvI22chsJPOfCeEqdxdvjuGvSahqE+TNpbEeC\nKni5O6S89i2XqovD66HBNbJcJKiGu6NSSilVfnUFbgU2GmPWZT33TyACwFr7P+BHZITqTmSMaqkZ\n+VQ92I+9aZXJCKmPY9ciGd+tlFJKKae5MoGRXxOtfMeYGWMigTrALwW8XqKNtkrCit3HGDdxFfVD\nSmHy4tguWPgCbJ4JgTVg+ASZmKFrdZVSSrmRtXYpcMF/jLKmj5TKzECNYGnMfTKsK1V2TIX0s+Dp\n7eaolFJKqbKjtDTxHAFMs9Zm5PeiOxptudLWI6cZN3EVEZUrMPmOjgRXKAUfXhJjYeNU2DRdxrt5\nVZDlIp3vB+8K7o5OKaWUKvOqB/sBsD+4A1XSvoCYlVC7q5ujUkoppcoOVyYwitJEawSl9G5JcTt4\nMpnbPvuTCt4Ovri9A5UqloLkRdw2mNAfzsRDWAu46nloORICwtwdmVJKKXXZiKgsNwTWeTajtfGQ\nUeSawFBKKaWc5soExkogyhhTB0lcjABuOncjY0wjoBLwuwtjKRUSUtK47bM/OZOawdR7OlMj606M\nWx3fAxMHg/GAu36D8JbujkgppZS6LAVX8CYkwIfNxwzUaCuNPHs97e6wlFJKqTLDw1UHttamA/cD\n84AtwLfW2mhjzL+MMYNybToCmJK1ZvWy9vyszeyOS+SjW9vSKCzQ3eHAqRiYOAjSU2DUDE1eKKWU\nUi4WFerPjthEqNsDDq6G5JPuDkkppZQqM1yWwACw1v5orW1gra1nrX0p67lnrbWzcm3zvLX2CVfG\nURr8tPEw362J4b6e9elSvxSMILUWpo6WD063TNdRbkoppVQJiAr1Z2dsIrZuD7CZsCvf/uVKKaWU\nyodLExhKHD2dwpPfb6RFzSAe6B3l7nDEnt+keVifF6BGG3dHo5RSSpUL9asFkJiazpGgVuAfJg20\nlVJKKeUUTWC4mLWWf0xdT0paBm/d2AovRyl5y5e9DRVDoeV5bUmUUkop5SJRof4A7IhLhubDYcd8\nSDrm5qiUUkqpsqGUXE1fvn7ceIQlO+L5Z//G1Avxd3c44tA6KVntfC94+bo7GqWUUqrc+CuBEZsI\nLUdAZjpET3dzVEoppVTZoAkMFzqbnsnr87bSsFoAN3eMdHc4OZa9Az6B0O52d0eilFJKlStV/H2o\nXNGbnbEJENYcQpvChm/cHZZSSilVJmgCw4W+/nM/e4+d4YlrGuHwMO4ORxzfDZtnSPLCN8jd0Sil\nlFLlTv1Qf3YcTZQvWt4oPamO7XJvUEoppVQZoAkMF0lISeOdhTvoXLcKPRqGuDsckZYM858BD0/o\ndI+7o1FKKaXKpexRqtZaaH49YLQKQymllHKCJjBc5KPFuzmedJYn+zfCmFJQfRG/Az65CrbOgZ5P\nQUCYuyNSSimlyqWoUH9OJacRl5gKgdWhbndJYFjr7tCUUkqpUs3T3QFcjo4lpvLJ0t1c27I6LWoG\nl9yJE+Ngz2I4cxySj0NqAmSkQXoybPxOGnbePA2i+pRcTEoppZTKI6paAAA7jyYSGuALLUbAjLth\n50KIusrN0SmllFKllyYwXGDyH/tJScvkwd71S+aE1sL6KTD3CUg5mfO8VwVweMsjsjMMek/u9Cil\nlFLKbXJPIulSvyo0HQK/vQZzH4c6y8HTx80RKqWUUqWTUwkMY8x04FPgJ2ttpmtDKttS0zOY+Ps+\nejQMoX5oQPEdOC0Zjm6Gmm3zPp9wBGbeDzsXQK1O0PclCI4Ev2BweBXf+ZVSSilVLEICfAj09WRH\nbII84eUL/d+ASUNh2bvQ/VH3BqiUUkqVUs72wPgvcBOwwxjzqjGmoQtjKtNmrTtEfGIqY7vVKb6D\nZqTBlJvhk17wy0s5a2RP7INPr4Z9y6Dfv2HMT1CzHfiHaPJCKaWUKqWMMURVC8iZRAJQvzc0uQ6W\nvAHH97gvOKWUUqoUcyqBYa392Vp7M9AG2Av8bIxZbowZY4zRK+Us1lo+XbqHhtUC6Fa/anEdFH74\nO+xaKBUWv70G856ScWsT+suSkdFzoNPd4KE9WZVSSqmyICrUn52xiXmf7PeKTAr78VFt6KmUUkrl\nw+krXmNMFWA0cAewFngHSWgscElkZdDvu46x9UgCY7vVKb7JI0vfgjVfwBV/lwqLjnfDig/gv50h\n7QzcNgdqtC38OEoppZQqNeqH+nMs6SzHElNzngysLpPCdi6AHfrxSimllDqXUwkMY8z3wBKgAnCt\ntXaQtfYba+3fAH9XBliWfLp0D1X9vRnUqhgaZZ48AHMegYUvQLPh0PNpqbDo9yp0fwKCI2D0DxDe\n4tLPpZRSSqkSlT2JZMe5VRgdxkkvq0UvaRWGUkopdQ5nKzDetdY2sda+Yq09nPsFa207F8RV5hw+\nlcwv22K5qWMkvl6Oiz9QYhzMfgjebQ1rJkK7sXDdf3OWhxgDPZ+Ev62Cak2KJ3illFJKlajG4ZLA\n2HTwVN4XHF7Q/TE4vA62/eiGyJRSSqnSy9kERhNjTHD2F8aYSsaYe10UU5k0Z/1hrIWhrWtc3AGs\nhU3T4b8dYe0kaDMKHlgLA9/UcWpKKaXUZSY0wJcawX6sPXDy/BdbjIDK9WDRy5Cpw9+UUkqpbM4m\nMMZZa//6F9ZaewIY55qQyqZZ6w/RomYQtatWLPrOqYnw7SiYNkbKRu9eIomL4FrFH6hSSimlSoXW\nEcGs259PAsPhCT2egKObYMuskg9MKaWUKqWcTWA4TK6ulMYYB+DtmpDKnj3xSWw8eIpBLS+y98Uv\n/wdbZkPv52DsAghtXLwBKqWUUqrUaR1RiYMnkzl6OuX8F5sNg6oN4ddXICO95INTSimlSiFnExhz\ngW+MMb2NMb2Br7OeU8Ds9YcwBga2uIgERswq+OMjadp1xSNy10UppZRSl73WEbI6d21+VRgeDuj1\nNMRthTkPakNPpZRSCucTGI8Di4B7sh4LgcdcFVRZYq1l1vpDtK9dmbAg36LtnJEGsx6AgHDo9Yxr\nAlRKKaVUqdS0eiDeDg/WHjiR/wZNBsGVj0lvrJ+fK9nglFJKqVLIqdv91tpM4MOsh8pl65EEdsYm\n8uJ1zYq+8/L3IDYaRnwFvoHFH5xSSimlSi0fTweNqwfm3wcjW89/wpljsOwd8KsM3R4quQCVUkqp\nUsapBIYxJgp4BWgC/FVmYK2t66K4yoxZ6w/h8DD0bx5e+MYZabBuMhyNhuO7Yc8SaHwtNBrg+kCV\nUkopVeq0rhXMNysPkJ6Riacjn8JYY6D/65B8QqowqtSTzw5KKaVUOeTsEpIJSPVFOtATmAhMclVQ\nZYW1ljkbDtGtflUqVyykp2lSPEy8DmY/COu+hqQ4aDYUBrxZMsEqpZRSpYgx5kFjTKARnxpj1hhj\nrnZ3XCWtdUQwyWkZbDuaUPBGHg4Y8j+o3ga+vwfid5RcgEoppVQp4mwCw89auxAw1tp91trngXJf\nNrA7PokDx5O5umm1C294eAOM7wEHV8GQ8fDkAbjrN/kw4h9aIrEqpZRSpczt1trTwNVAJeBW4FX3\nhlTy2kRUAgpo5Jmbpw/c+CV4esM3t8gIdqWUUqqccTaBkWqM8QB2GGPuN8YMAfxdGFeZsGxnPABX\n1A8peKOT++GzfmAzYcxP0PJGKQdVSimlyrfsfwz7A19aa6NzPVdu1KzkR1V/78ITGABBNWH4BIjf\nDtPHyWcMpZRSqhxxNoHxIFABeABoC9wC3OaqoMqKpTviqVXZj4gqFQreaPFrkJkuyYsabUouOKWU\nUqp0W22MmY8kMOYZYwKATDfHVOKMMbSqFcy6giaRnKtud7j6Rdj2I7zdHCYMgA3f6phVpZRS5UKh\nCQxjjAO40VqbaK2NsdaOsdYOs9auKIH4Sq30jEx+33WMbvWrFrzRsV2w7itoNwYqRZZccEoppVTp\nNxZ4AmhvrT0DeAFj3BuSe7SOqMSuuCROnUlzbofO98GD66Hn05B4RKoxZtwLaSmuDVQppZRys0IT\nGNbaDKBbCcRSpmw4eIqE1HS6XWj5yOLXwOEN3R4pucCUUkqpsqEzsM1ae9IYcwvwNHDKzTG5ReuI\nYABW7Tvu/E6VakP3R+G+ldDjSVj/FXw+ABKOuCZIpZRSqhRwdgnJWmPMLGPMrcaYodkPl0ZWyi3b\nEY8x0Llelfw3iNsOG7+F9mMhoJAmn0oppVT58yFwxhjTEvg7sAuZclbutImohK+XB0t2xBd9Zw8P\n6PEE3DARYjfDx72kAlQppZS6DDmbwPAFjgG9gGuzHgNdFVRZsHRnPE2rBxY8PvXXV8DTD7o9XLKB\nKaWUUmVDurXWAoOB9621HwABbo7JLXy9HHSqW4Xftsdd/EGaDIbb50F6Ckzor6NWlVLqYmVmllyT\n5J0L4Wh0yZzrMuFUAiOr78W5j9tdHVxplZSazpr9J+haUP+LZe9C9HTodDdUvECPDKWUUqr8SjDG\nPImMT/0ha9qZl5tjcpsro0KyxrOfufiDhLeA2+aAzZAkRuyW4gtQKaXKizVfwLut4cQ+154nLQW+\nHQVzn3TteS4zTiUwjDETjDGfnftwdXCl1Z97j5OWYc9v4GktLHgWFjwDTYdA98fdE6BSSilVFutW\nZwAAIABJREFU+t0IpAK3W2uPADWB190bkvtc2UB6ai2+lCoMgGpNYPQPMrL9wy4wvgfMfwZ2/Ayp\niZceqFJKXe62z5Upktt+cu15dv8KZxPhwB/ahLkInF1CMgf4IeuxEAgEyu2/gst2xOPt6UH72pXz\nvjDnYVj2DrQbC8M+BU8f9wSolFJKlXJZSYvJQJAxZiCQYq0tlz0wAOqFVKRGsN+lLSPJFtIQ7vhZ\nbqR4VYAVH8LkYfDvSPi0L6yaoGNXlVIqPxlpsHep/H27ixMYW2fLn+kpELPStee6jDi7hOS7XI/J\nwA1AO9eGVnot3RlP+9qV8PVy5Dx5dDOsngAd74EB/wEPR8EHUEoppco5Y8wNwJ/A9cjnij+MMcPd\nG5X7GGO4skEIy3cdIy0j89IPGBwhzT3H/AhP7Idbv4cuf4O0JJjzEMy8H9JTc7Y/fRhSTl/6eZVS\nqiyLWSlVEVUbwt5lrvu9mJkhFR5RfcF4wJ7fin6MjPTij6sMcLYC41xRQGhxBlJWJKams+1owvnV\nF5umyQ/fFY9I2aZSSimlLuQpoL219jZr7SigA/DMhXbIWsIaa4zZVMDrPYwxp4wx67Iez7ogbpfp\n3qAqianprN1/sngP7F0B6vWCq56HO3+DKx+DdZNg4mBY/bn0y3izEbzbCrbMKd5zK6WUO2Rmwvpv\nir50btcvck3X51+QmQa7Fromvv0r4MwxaDUSqreBPYuLtv++3+G1OrB+imviy83aUlW152wPjARj\nzOnsBzAbKJcNHjYfOo210LxGUM6T1sLGaVC3B/iXy7yOUkopVVQe1trYXF8fo/DPJZ8D/QrZZom1\ntlXW41+XEmBJ61K/Kg4Pw+LtsYVvfLE8PKDXUzD8Mzi0FmY/CIlHocc/IagmfHMzzLwPkk+4Lgal\nlHK1dZPg+zvhz4+Ktt+uRVCjHdS/Cvwqu64PxtY54PCR89S5Eg6uhtQE5/Y9sVd+V6eehp9fcE3/\njO3z4bNr4J2W8FI4vN8Oju8p/vNcBGeXkARYawNzPRpYa78rbD9jTD9jzDZjzE5jzBMFbHODMWaz\nMSbaGPNVUb+Bkrbx4CngnARGzCo4uQ+aldvKV6WUUqqo5hpj5hljRhtjRiN9tn680A7W2t+A4yUR\nnDsE+nrRJiKY37bHu/5kzYbBfX/Anb/C/augx+Mw9mfo9gis+wpeqwef9IFfXoKdP0PSMdfHpJRS\nxSHlNCzMyl9vmu78fskn4NAaqNcTHJ4QdTXsmF/8SzWslWq3uj3AJ0ASGJnpUpVRmJTT8PVI2X7g\n25BwCFZ9Wrzx7VsO39wCiUckmdPudqkW+eJa109mcYKnMxsZY4YAv1hrT2V9HQz0sNbOuMA+DuAD\noA8QA6w0xsyy1m7OtU0U8CTQ1Vp7whhT6ssXNh08RbVAH0IDfXM9OU0yaI0Hui8wpZRSqgyx1j5q\njBkGdM16ary19vtiOHRnY8x64BDwD2ttdDEcs8RcGRXCfxZsJz4xlar+Lm4GXqm2PLJ5esNVz0HT\n62DzLClpXvIG2KyeHIE1wcdfGs5lZkDn+6DTPa6NUSmlimrJG5AUBy1HwvqvIXYrhDYqfL89v8nv\nu7o95euG18CGKRDzJ0R2ybuttXB0k/yu3DJb9uv/miQlCnNkI5zaD90fla9rdQSHt/zOjeojy1+W\n/keaMDcaCJUiJYkSsxIWvwpx2+CW7yTRsnkGLPkPtBklyZDUBGnUfHSTbJcUD+3Hyu/r3AMmUk5L\nFV7MStmm2TCo2Q7itsLXI6SP0tj5UCGrbUKLG2TZ4RcDZdJVcETh36eLOJXAAJ7L/aHCWnvSGPMc\nUGACA1nLutNauxvAGDMFGAxszrXNOOADa+2JrOO6sGayeGyIOZm3+iIjXTJ7Da4G36CCd1RKKaVU\nHlnVnIVWdBbBGiDSWptojOmPfE6Jym9DY8ydwJ0AERHu+yB2rl6NQ/nPgu3M3XSEWzpFuieI8Jby\n4BlIOQWH18OhdfKhOyMVPH3hVAzMfULuAnb5m3viVEpd3uJ3wPQ7oWZ7uObfzvUZPL5bJi+1vEn6\n/mz4BjZ9J0vnCrNrEXgHyIU8SO8gDy9ZRpI7gZGaANPvgm0/SL+MyK5w+pBc4LcdDX3+D3wDc7bP\nzISdC+DkfggIl6o24wEN+8vr3hWgZgfYndUH49dX4LfX5O/z/gnVmsHpg1Ih4uEJA9+U5AVAr2fh\nk17yPUd2hRl3y3kCa0LVKPALhoUvwJqJ0O0hWQayZ7H8Tierr4XDB/74EMJaSKWFp68kSCrk6vlY\nvRWMmpGVxLgW7vld4nYDZxMY+S01KWzfGsCBXF/HAB3P2aYBgDFmGeAAnrfWznUyphKXmJrO7vgk\nBrWskfPk3iWQFAvNr3dfYEoppVQZYYxJ4K9PTXlfAqy1NjCf15xirT2d6+8/GmP+a4ypaq09b02G\ntXY8MB6gXbt2paY7WZPwQOqH+jNz3UH3JTBy8w2S8uY6V+Z9PiMdpt8B858GDHS53y3hKaVKqcxM\nOLZT+gP6BhV9yMHmWTDjXkmSHlojF+59Xyr8OPOfkaRD72choBrU7iYJjJ7/LHzf3YugzhXg8JKv\nfQNl/y2zoc1tUKWetA34eqRUN/R+FlqPAv8QOHsGfn0Zfv8Aor+HxtdKe4HkE1IhcfSc3tOR3aBi\n1Zyv63aHRS/DH+MledH6Vuj2sJx758+SXGhwtSRVct80r9lWqjR+ewMyXpaqutvnQ0Suy+6dC2Hu\nk9LzyMNTEkLdH5OkSY028v1u+BZWfSYTWG6bI1Uf56reGm6dId+Lm5IX4HwCY5Ux5k1kSQjAfcDq\nYjp/FNADqAn8Zoxpbq3N0367tNwl+auBZ81cn602TpNMXdTVbotLKaWUKiustQGuOrYxJgw4aq21\nxpgOyA2YMtW8wRjDda2q88b87cScOEPNSu77kHhBDk8Y+omUUc9/ShqANr3O3VEppUoDa2HKSNie\ndV/aq4JUdXW6Ry62PRz573Niryxp2LUI1n8FNdrCDRNh+Xuw4gNJKPTIt60iZKRJVdjWOdDrGQgM\nl+ebDYfZD8DhdXIBnvt8B9dIcsDTWyoiTuyFTvflPW6bW2Ha7fB+W0kOpJySfW+dnne5iHcFuPpF\naDpEkhDRM2HtJHmtagMYMl4SwYlHIeEIhDXPe546V8Kil+CnRyW5MeBNiavbQ/K4kF5Pw54l0Oom\nicHHP+/r9XvDPcvg8AYIaXj+6yDLTNrdLu+jp3fB56rRRh5u5GwC42/IaLNvkLsmC5AkxoUcBGrl\n+rpm1nO5xQB/WGvTgD3GmO1IQmNl7o1Ky12S7AaezbKXkCQdg80zpfeFl5+7wlJKKaXKBWPM18hN\nj6rGmBjgOcALwFr7P2A4cI8xJh1IBkZYW4pmvzlpcKsavDF/OzPXHeK+nvXdHU7BHJ4w7BOI3QzL\n39UEhlKXi5TTeZdAFNWaLyR50eleCKwuyyu2/QjfjoJKdeRCuUFfubA/myiNg//4CI7vkv29KkKH\nO+Vi3NMH+r4i41B/fUWaavqHSfVCWHOofYVUWkwdIxUUXR6QyoVsja+FH/4uVRjVW8vyj7WTZUlF\n7DktkowDoq7K+1yzYZJI2bFAkh1pZ6R5ZpV6+X/vNdrC0I8gLTlrqYhDvtfspE12YuVc1dvITfGK\nVeHGLy+cRDhXaGN4fK9MmSqIw0uqNS7EmKKd102Mq/5dN8Z4AtuB3kjiYiVwU+5mWsaYfsBIa+1t\nxpiqwFqglbW2wLsl7dq1s6tWrXJJzIV5aMpaVuw+zop/9pYn5jwi89PvWe5cYxillFLqMmCMWW2t\nbefuOIqLOz9bFGTYh8tJTEln3sNXFr6xu/3xEfz0GIxb5PY7c0qpC0g/K8mFxoPkoj8/0d9LMqD3\ns3DFI0U/x4m98GFX+V1w68yci+rMDFkOsfw9OJj1+zaoliRLUk/JsoaWI6ShZUhjSZDmlpkhFQox\nq6TpZMJhSM4aSuXhCRi49m1ofcv5MX11o/TwaTdGlngkn5BkRptRkqDw8JTEhvGQJS/uErNaEhyB\n1d0Xgxs5+9nC2SkkC4Drs5d2GGMqAVOstX0L2sdam26MuR+Yh/S3+MxaG22M+Rewylo7K+u1q40x\nm4EM4NELJS/cbePBUznVF0c2wuoJ0H6cJi+UUkopVayua1WdZ2ZGs+XwaRqHX8Kd0JLQcgT8/IKM\n8tMEhlKlU3oqfHsbbP8JVn4Co3+EilXybnP2DMx7WiZiLHwBzibJ8gRn+1dkZsKM+wADgz/IWxHg\n4ZAqrabXSZPJnT9LbwbvinI9Vav9hY/t4ZCkSjZr4cQe2LtMGg03GwaRnfPft9kwqQj55UVo0A+u\nfDSnUWc274rOfY+uVFiFhAKcX0JSNXdfCmdHnlprf+Scme7W2mdz/d0Cj2Q9SrU8DTytlUYovkEF\nr8NSSimllLpIA1pU54XZm5mx7mDpT2D4BsmIvfVfS8m3XyV3R6TU5W3tJKgYIksTnJGeCt/cCjvm\nQYe7pApj0lC4bVbehpC/vw+nY6SJ48ZvZRxpagL0eaHw5fIpp6Wp776lMOj9C4/ZDI6QZSTtbncu\n/vwYA5XryoNbL7xtk8EyOaleL5mmoco0ZxMYmcaYCGvtfgBjTG3y7yB+2Yo+eCqngeeWWTJ9pP8b\necfLKKWUUkoVg8oVvbmyQQiz1x3i8b6N8PAoYgf/ktZ+rFSmrvsKOhfWJk0pddGWvy+NcwFa3QL9\nXpF+FXHbJUFRvQ3U7pqzfWKcjNbc+bM0hmw/Vpo6TrkJvhoBN06SSozTh2DpW3KxX+cKmb7hHSDN\nMzdOlfGgLW6AM8el8iH5hCQiKteDuK0w7ylpUNnpvvyXcbiTp8/FLYdRpZKzCYyngKXGmMXImLMr\nyJoKUl781cCzegBMeA5Cm0DbMW6OSimllFKXqyGta/C3rbEs3hFHz4ZuXJftjLDmUKsTrPwUOt5z\n4WZySpUmZ5NgwbNQralMrLjY5pWpCXDgT6jbs+Cf/7RkGS0aUF1ughZ1tOi6ryV50WQwVImCpW/C\nnt+kiuLoxpztmg6Vqokd82Hhv+R7HPi29IAAqdwYOh6+uwPebiYjQk/HSJ+JPv+SbYyBfi9Do/6w\n4kNY9racryDhrWBk1uQQpVzIqQSGtXauMaYdkrRYC8xAunuXG5sOniIs0JfQ+D8l6zj0k/Obyyil\nlFJKFZO+TcMIDfDhs6V7Sn8CA6D9HTD9Dlj2FnR5UD8nlaTspvxFvSBW8MM/ZGQnSBVBs6Fw1Qsy\nDcJZpw/D5OFwdJNcyF/zb4jolHebA3/C9HHS5BLA0w/CmuU0kjy3B0NmplR8H98tTSaTj0uvmTrd\nYejHUlUQdbWM3XT4QL9/S2Ji/RRJNkRPl+PUuVKqxkMa5j1+s2FQrRksfRtWfgyZ6dDtERkVmlvt\nbvI4sU/iCQiHynVkqdjJ/XBsl/zcNR6U/3hUpYqZU1NIjDF3AA8io1DXAZ2A3621vVwb3vnc1Sn8\nqjcXU7tKRT4JGA/b5sI/tunoVKWUUuWSTiEpOR8s2snr87Yx76EraRgW4O5wLiz9LHxzs9z1rdZM\nLpoKaqqnitfU0ZCRJssBNImRV2KcXOznV1mxdjLMvBeufEyaO675QhIAYc2kD4R3BdkuKR42TpOl\nGWHN8x4jbhtMGiZLKro8IBMKEw5BwwGSxAhtAjEr4bfXIagGdH9cqjVOxUgTy7gt4BMIDa+RbUMb\nQ/x2WPWZJC9yq9EWRs0En0J+F5zYB3+Ol6a6TYcW/jNxcj9snwetbs75npUqYc5+tnA2gbERaA+s\nsNa2MsY0Al621g699FCLxh0fMtIyMmn8zFzu7xLKQ+sGSrfta98u0RiUUkqp0kITGCXnRNJZOr+6\nkMEta/Dv4S3cHU7hrJVeYXP/KSXpTa6TyQFV6rk7srLLWkhPKfjG2a5f4Msh8vebpkKDq0sutkuR\nmXlxS422/QSpiTLNwuFV8HZnk2Dxv2VsJkCNdlCvJ0R2kUTAyf0wvqdMoxg1M6d6YOsPMOVmaDQA\nbpgIR6OlX8SpA/J6rU7SCyL1tCQYtsyWCombp0mDyLNJ0ktizZeQeCQnnpYjpTIjd9NMa2H/Cukf\ns3tx3u1rdZJ+FZFdwGbK8o6gWlrZpC5bxTpGFUix1qYYYzDG+FhrtxpjGha+2+Vh//EzpGdarji7\nBNKTS19jGqWUUkpdlipV9GZom5pMWx3Do/0aUtXfx90hXZgxsj6//lWw7B1Y/h5snSN9w7o+cOHJ\nBOp81sK3o+Qi944F55f3Z2bCz89DUIQkAxa+IO+9O3uQpKdKUuVUjDR1zMyAFjdCaCN5PW47zH0c\nDq6Bq56DNqMlXmvh0FpJClSNgqoN8iZtMtJh4fPyMwXwy7+g60OyFMI3SH72MjNlqff+FfDrK5J0\naHUL+IfC7kXw66uABeOQJRs+/jDsk7xLHxoNgH6vSoxTbsrqMREsSY4jG2UE6Q9ZDSErVIXwltJf\nonIdec67oowe7fW0NLyM3SLHP3dJCUjMkZ1zKpWST0DsVlmekf1+KaXycLYC43tgDPAQ0As4AXhZ\na/u7NrzzueMuyYLNRxk3cRXREW9QMTMJ7vtDy/OUUkqVW1qBUbJ2xiZy1ZuLefiqBjx4VZS7wyma\nhCNy0bhmImDl4rDj3RDZ1fWfpTIz5Zznrss/c1zW+/uXkr4i1hb8Xix/T0ZTenhBlfowdn7epRCb\nvoNpt8OQj6QK4Lux0h+hxQ35nwecf99Pxch5K1Z1vrdB3DaJ4UhWQ0njIY/MdBlhWbmeVBt4VZQk\nxcFVULO9LHNY/zUc2ZBzLOMBVRtK/4XILrK8Y/ev0H6cHGvJf2R/AK8K4F8NzhyTygiQ5RgD3sy7\njOnMcYhZBTF/wuEN0PXBvBM7cpv7JKz4L9TsIEtzAqrJ85mZcHyXnO9iG34qpc5TrEtIzjlwdyAI\nmGutPXuR8V00d3zI+N/iXUydu5CFPo9KZ96uD5bo+ZVSSqnSRBMYJW/0hD/ZdPAUSx/vha9XGWyU\nd3K/TChZ84XcZa7WHDreBc2Hu6an2Jnj0lQxMwPG/JjTIDHhKIzvDgmHZYpD7W7QdIg0OiyOhMrZ\nM3JxbDzkIt0Y6WdwdJOMqQxvJecMrA6bpsvY2RN7ZMRj57+Bp3fOsfavgAn9JenT7nbps1D/Khj5\ntSQUMtLggw7SDPLuJYCB8VdCymm4f1XOsY7tkr4M676S3gv+ofKo3kb6LtS+Imfb5JMQ/T2s/RIO\nrpbnjAMqVJFlDGnJkHE2q5FjbakIqVRH/kw8Kk0mvStk9T/pAhVD5L/36gnw5yeyTetboPdzkhjZ\n8I00zjwTL31T2o6WSoX4HTKaM2aVvA9pSeDwhoFv5VRCWwt7l0rVRuJRSZb5BUtFRFgL6VVxKU0l\nMzOk+iKyi/TQUEq5lMsSGO7mjg8Zj05dT7Mtb3KbnQ2PbMnJwCqllFLlkCYwSt6K3ccYMX4FT17T\niLu6l+F+EmfPwMap8MdHEBsN3gFyIRxYQx4hDSGkkVzMVqxy4WNZK4mB7XNleUH7O8A/RJIXEwfL\nBXBGmiQohn8mF6QTB8uFedcH4dAauThOPS09Ea74OzS4pujLL6yVvgwbp0osaWfO38bhIxfzp2Py\nPl+9jTy/Y54smejxpIzXtJkw4z65cL5rsSyRWPmpLF2of5UkDRKPSP+F3H0vdvwMk4dB/T5SkXEq\nRsZrGockKyrXhcRYaTJ5YKUsjfb2lwRP8knISJXjhDaRng1efpIcSIyV43n5SVLg9CGZpnF8jyQf\nstXrBdd9CAFh578H6Wch5ZT8N8ot5ZRM8QhpmH8SKSNNkhQVq0r8SqnLUnH3wCjXdscn8XfzB9Tr\nrckLpZRSSpW4TnWr0LNhCO8v2skN7WpRqaJ34TuVRt4VoO1tMjpy3zKpQjgVA6cPwv7f5WIW5IK7\n5QhJKpzbAPTYLqnk2DQ9q7GikQvf5e9KEmP3r7KUYUTWkoSFL0D11nKhvW+pLLdoOUKOlZYiSxeW\nvS39DkIaSzVE06HnN0tMOQV7lkB4i5xeHmeOw4x7YftPUqXQ4kapmPD0kWRNZroslahcT46XcESq\nBk7ug4b9ZeIEwPb58OM/YNqYnPM5fKTvRXbTx/ZjZf/Vn0sSJiMdGg2EqD45+9TvLc/tWy5VHgHh\n0pOk9S0QGJ73+0lLlsaRO3+GzDQ5j28w1O0uiRVnK1JSE2TqRWoC1OpYcALI0/v85AVknTfo/Of/\neh+8oFYH52JRSl32tAKjENZaerzwHYsZq8tHlFJKKbQCw122HUngmnd+Y0zXOjwzsIm7wyl+1srd\n/ritMrJ+9QRZrlC/j9x9d3jDsZ2wd4kkOKL6SLIgqq9UUSx+TaogHN4w8iupVLAWpt4mlQo2U5Zi\nDHzr/HNnpEP0dFjypoy1DI6UaoKgGpKY2L1YqivSU2R5SMP+0KAvLHoFkuLkM2KHOy9tQkRaMhxe\nL5UiWIkhuNbFH08ppcoQrcAoJseTzhJ5djt4I9l7pZRSSik3aBgWwPVtazHx972M7lKbWpUruDuk\n4mWMLD0ICIO6PaDbw1JVsX2ujLLMSJU79b2ehta35l2mEFANhn0M3R+XpEe1JjnHHPxfWerg6SvT\nJfLj8JTGl82GSzXFig9lHOyZY/J6hapSNdKwP+xZDKu/kOkqletKlURxfEb08st/UoVSSqm/aAKj\nELvjk2hm9sgX4S3dG4xSSimlyrWH+zRg5vqDvDZvG++NvMxvrARUg74vycNZVeuf/5yPP4xbJMmM\nwpo6enhIVUejAfJ1WrL0fwisLksZAOr1lETJgT+kd4ZPgPPxKaWUuiRuHBJdNuyKTaSFxx7Sgute\neH2eUkoppZSLhQX5Mu6Kusxef4hlO+ML30EJh+fFTaTw8oNKkTnJi9zP1+2hyQullCphmsAoxO74\nJFp47MZRs427Q1FKKaWU4t4e9alTtSKPTdtAYmq6u8NRSimlSowmMAoRe/gA1c0xPLT/hVJKKaVK\nAT9vB68Pb8GhU8m8+tMWd4ejlFJKlRhNYBTCO3aD/KV6K/cGopRSSimVpV3tyoztWodJK/azXJeS\nKKWUKic0gXEBqekZhCdtxWIgrIW7w1FKKaWU+svfr25InaoVeXTaBk6eOevucJRSSimX0wTGBew/\ndoamZjeJ/nXAN9Dd4SillFJK/cXP28GbN7QkNiGFB6esIyPTujskpZRSyqU0gXEBu+KSaO6xh/Rq\nWn2hlFJKqdKndUQlXhjUjMXb43hzwTZ3h6OUUkq5lCYwLuBwzB7CzXEq1G7v7lCUUkoppfJ1U8cI\nRnaoxQeLdvHTxsPuDkcppZRyGU1gXEDGwbUA+ES0dXMkSimllFIFe35QU1rVCuaRb9ezau9xd4ej\nlFJKuYQmMC6g4rFNZGIgrLm7Q1FKKaWUKpCPp4OPR7UjPMiXMRNWsjHmlLtDUkoppYqdJjAuoGby\nVmJ9IsHH392hKKWUUkpdUEiAD5Pu6Eignxe3fvYH244kuDskpZRSqlhpAqMAZ9MzqZ+5hxOBjd0d\nilJKKaWUU6oH+/HVuI74eHpw08cr2HRQKzGUUkpdPjSBUYC4o4cIN8dJrdLE3aEopZRSSjktskpF\nvhrXCR9PD0aMX8Hvu465OySllFKqWGgCowCn960DwBHezM2RKKWUUkoVTb0Qf767twthQb7cNuFP\nnU6ilFLqsqAJjAKkH9oIgH9kKzdHopRSSilVdOFBfky9qzNNqwdyz+Q1PD8rmpS0DHeHpZRSSl00\nTWAUwCs+mjgbRGh4hLtDUUoppZS6KJUqevP1uE7c3rUOny/fy3UfLGP7UW3uqZRSqmzSBEYBAk9t\nZ4eJpKKPp7tDUUoppZS6aL5eDp69tgkTxrQnPjGVa99bype/78Va6+7QlFJKqSLRBEZ+MtIJSdnN\nIZ967o5EKaWUUqpY9GwYyk8PXknnelV4ZmY04yau4lhiqrvDUkoppZymCYz8HNuBl03juH+UuyNR\nSimllCo2IQE+TBjdnueubcJv2+Pp89ZvfLvqAJmZWo2hlFKq9NMERn6ORgOQoiNUlVJKKXWZMcYw\npmsdZv+tG3WrVuSxaRu44aPf2Rhzyt2hKaWUUhekCYx8pB/awFnrwBHS0N2hKKWUUkq5RMOwAL69\nqzOvD2/B7vgkrn1/Kbd++gfLd8VrfwyllFKlknaozMfZQxvZZ2tQrXKgu0NRSimllHIZDw/D9e1q\n0bdZGJNX7OfTpXu46eM/aFkrmHu61+PqJtXw8DDuDlMppZQCtAIjX47YaDbbCKoH+bo7FKWUUkop\nlwv09eKeHvVY+nhPXryuGSeSznL3pNX0eWsxX/6+l5Nnzro7RKWUUsq1CQxjTD9jzDZjzE5jzBP5\nvD7aGBNnjFmX9bjDlfE4JekYPslH2ZoZQXiwn7ujUUoppZQqMb5eDm7pFMkvf+/OuyNb4+vl4JmZ\n0XR4aSH3TV7Doq2xpGdkujtMpZRS5ZTLlpAYYxzAB0AfIAZYaYyZZa3dfM6m31hr73dVHEV2dBMA\nW2wk4VqBoZRSSqlyyNPhwaCW1bm2RTjRh07z3ZoYZq47xA8bDxMS4MOQ1jXoWr8qjcMDCPH3wRhd\nZqKUUsr1XNkDowOw01q7G8AYMwUYDJybwChdshIYR3zr4evlcHMwSimllMpmjPkMGAjEWmub5fO6\nAd4B+gNngNHW2jUlG+XlxRhDsxpBNKsRxJPXNGbRtlimrY7hs6V7GP/bbkBGs751Qyu6RVV1c7RK\nKaUud65cQlIDOJDr65is5841zBizwRgzzRhTy4XxOOdoNKc8KuETHObuSJRSSimV1+dAvwu8fg0Q\nlfW4E/iwBGIqN7w9PejbNIyPR7Vj9TN9+HpcJ54d2ARfLw9emB1NZqZOLlFKKeVa7m7iORuoba1t\nASwAvshvI2PMncaYVcaYVXFxca6NKH47uz1qER6k/S+UUkqp0sRa+xtw/AKbDAYmWrHmm6y/AAAg\nAElEQVQCCDbGhJdMdOVLkJ8XnetV4fZudXi0byN2xCbyw8bD7g5LKaXUZc6VCYyDQO6KippZz/3F\nWnvMWpua9eUnQNv8DmStHW+tbWetbRcSEuKSYP+ScISY9GCqB2v/C6WUUqqMcbb6UxWjAc3DiQr1\n592FO8jQKgyllFIu5MoExkogyhhTxxjjDYwAZuXe4Jy7IoOALS6Mp3DWYhOPcjA9SCswlFJKqctY\niVZ3XuYcHoYHekexIzaRH7UKQymllAu5LIFhrU0H7gfmIYmJb6210caYfxljBmVt9oAxJtoYsx54\nABjtqnicknwCk3GWWKsVGEoppVQZVGj1Z7YSre4sB/prFYZSSqkS4NIeGNbaH621Day19ay1L2U9\n96y1dlbW35+01ja11ra01va01m51ZTyFSjgCwP+3d9/hUVdp/8ffZybJpE0SUggpQEIJvQcEARXX\nigtixbL2+rOsZV13fdzVLT66u/rY1q7YEBUrKmJFaSJI6B1CTSCVQEggPef3x0xi6C1hkuHzuq5c\n5lvm5NxzcHK+d07Jt1EagSEiItLyfA5cbTwGA8XWWg0JOA6cDsNdZ3hGYXw8P9vX1RERET/VlNuo\ntjwlnj5Onm1FQqRGYIiIiDQnxpj3gNOAWGNMNvAwEAhgrX0JmIJnC9VMPNuoXuebmp6YRvZMYFDK\nJv4xeQVDOsbQNjrU11USERE/owRGQ6V5ABQQRXyEEhgiIiLNibX28kNct8Dtx6k6sheHw/B/l/Zh\n5DMzuWfiIt6/eTABTl9veCciIv5Ev1Ua8k4hqQmLJyhAb42IiIjIkWgbHco/xvQgY9N2Xpq+ztfV\nERERP6On9IZK8ygzoURHRfm6JiIiIiIt0pi+SYzqk8jT369l2up8X1dHRET8iBIYDZXkss3RilZh\nQb6uiYiIiEiLZIzhkfN70ql1ODe8lcH4OZt8XSUREfETSmA0VJpHoW1FuEtLg4iIiIgcrcjQQD76\nfydzalocf520jL99vpzqmlpfV0tERFo4JTAaKsklz0biDlYCQ0RERORYhLsCePXqdG4Ylsqbszdy\n4YuzWZtX4utqiYhIC6YERh1roTSPnJoojcAQERERaQROh+Gvv+3OC1f2J3t7Gef9dxavzFin0Rgi\nInJUlMCoU1ECVbvZWhNBmBIYIiIiIo1mZK8Evrn7FE5Li+PRKasY/dxPLNi83dfVEhGRFkYJjDql\neQDkaQ0MERERkUYX53bx8lUDeOHK/hTtquTCF2bzp4+WULSr0tdVExGRFkIJjDolOQDk00prYIiI\niIg0AWMMI3slMPUPp3LLKR34eEE2p//fNN77ZTO1tdbX1RMRkWZOCYw6JZ4RGPk2inBXoI8rIyIi\nIuK/wlwBPDCyG1PuGk5avJsHPlnKBS/OZv6mIl9XTUREmjElMOqU5gJQYKMIczl9XBkRERER/5cW\n72bizYN5amwfcnaUcdGLP3Pr+PmsLyj1ddVERKQZ0lyJOiW51Dhd7CRUU0hEREREjhNjDBf0S+bs\nHm0YN3MDL01fx3cr87hiUDvuOqMzseEuX1dRRESaCY3AqFOaR4UrDjCaQiIiIiJynIUGBXDnbzoz\n/f4RXDGoHe/+splT//MjT323htzi8ib5mTvLq6iormmSskVEpPEpgVGnJJfdrlgAwjUCQ0RERMQn\nYsNd/HNMT7695xSGdY7lmalrGfKvqVw1bi5fL8vB2sZZ7LO6ppbznp3JvR8sbpTyRESk6SmBUac0\nj5JAbwIjSAkMEREREV/qGBfOy1elM+2+07hzRCfWF+zi1ncWcMe7CyneXXXM5X+/Mo+sojK+XJLD\n8q3FjVBjERFpakpg1CnJo9gZA6BFPEVERESaiZTYMO49qwsz7h/Bn87pyjfLcznnmRlMW51/TKMx\nxs/ZRJuIYNzBATzz/dpGrLGIiDQVDTUAqCqDimK2O1oREugkwKm8joiIiEhz4nQY/t9pHRnWKZa7\n3l/ItW/Mo210CBf0TeLM7m1IjQsj3HV4Xdt1BaX8lLmN+85Ko7rW8vT3a1m2pZieSZFNHIWIiBwL\nJTAASjxbqBaaaK1/ISIiItKM9UqO5MvfD2fK0hw+XbiF//6YybM/ZAIQ53aREhNK+5gwUmJCSU+J\n5qTUaIwxe5QxYc5mAp2GSwe2xRXg5PVZG3hm6lpevTrdFyGJiMhh0tM61Ccw8ok67My9iIiIiPhG\nSJCTiwYkc9GAZPJ2lpOxcTsbt+1i07ZdbNy2m5lrC/hofgUAPRIjuGl4B87rnUCg08Huymo+nJ/F\nOT0TaO0OBuCGYR146vs1jT4Ko7K6lqAAjewVEWkseloHKPUkMHJrIpXAEBEREWlB4iOCOa93wj7n\nd1VUM3nJVl6duYG7Jy7in5NXMLJXAqEuJyXl1Vw1uH39vdcNS+GN2Ru4+e0MXrk6vVGSGF8vy+WO\ndxcwum8i953VhcSokGMuU0TkRKeUMEBJHgBbayKUwBARERHxA2GuAMYObMe3d5/CG9cOZHDHGD7I\nyOLl6etJiw9nYEqr+nsjggN554aTsMAlL/3MlKU5x/Szi3ZV8uCnS2ntdjF5SQ4jnpjGv75axdYd\nZccYlYjIiU1P6+AZgeEIIKcyjKRwvSUiIiIi/sLhMIzo2poRXVtTWlHNj6vySYt377MuRs+kSD67\nYyi3jp/PbRMWcP3QVO47O43QIE/fcO76bTz7w1quGtyec3ruO+KjoYc/X87O8iq+uHMY4a4Anvx2\nDS/PWMcrM9ZxSlocI3sl4DCGsspqyqpq2F1ZQ1llDZGhgVwzJIUw/UFNRGS/9OkInhEY4fGUVNZo\nBIaIiIiInwp3BTCqT+IBr7d2B/PezYP55+QVvP7TBr5dkctfzuvGj6sKmJiRRYDDMGd9Ec9fwQGT\nGF8vy+WLxVv5w5lpdG0TAcCTY/tyz5lpfJiRxQcZ2UxbXbDP61wBDiqqa5kwZzOPXNCTEV1aN07Q\nIiJ+RE/r4BmBER5PaW61EhgiIiIiJzBXgJNHxvRiVO9EHvh0Kbe+swCnw3DLqR24cVgHbhmfwR3v\nLuTF3zk4s3t8/euqa2qZvqaAv0xaRo/ECG49reMe5baNDuXes7pw1xlpbCgsJcjpJCTISWiQk+BA\nJ06HIWNjEX/+ZCnXvTGPU9Pi6NrGTVKrENrHhNE3OYrI0MDj/XaIiDQrxlrr6zockfT0dJuRkdG4\nhe4ugspSOj++jBuHd+BP53Rt3PJFRET8iDFmvrXWb/abbJK+hfiF8qoaPpyfTXr7VnRL8IymKCmv\n4nfjfmHF1mIGpUaTHBVKmCuAr5blkFNcTmu3i7dvGFQ/+uJIVVTX8OK0dUxauIWtO8qprKmtv9Yx\nLoyhnWK5NL1to+6WIiLia4fbt9BwA4DQaCqCIqmqWaoRGCIiIiICQHCgc4/dSgDcwYG8ff0g/vXV\nSlbllvDD6ny2lVYwvHMcD4/qzm+6xRPoPPp18l0BTu4+I427z0ijttaybVcla/NKWLB5Ows272Di\nvCze/nkTPZMiGNIhhqoaS0V1LcVlleQUl5NXXE6v5EgeGdOLOLfrWN+CZqeiugbwvE8icuLR07pX\naXk1gBIYIiIiInJQkSGBPHZh7/rj2lqLw2EO8oqj43AY4twu4twuTu4UC0Dx7io+W7yF93/xJDKC\nAhy4AhxEBAeSEBXMgJRovl2ey7nPzOCJS/rQKymSKcty+WppDtZC5/hwOrcOp1dyFD0SI44p2VJn\ny44ynvthLXee3nmP7WKnLM3hjZ828Ozl/UiIbJxtZG96ez7WWsbfcFKjlCciLYue1r1KK5TAEBER\nEZEj1xTJiwOJDA3k6iEpXD0k5YD3rMkr4ffvLeTaN+bhdBhqai0d48JwBwfyyYIt9f3e4EAHfZKj\nOLljLKekxdI7OQrnUcTy0KRlTF2Vz9wNRXx4yxBiwl3MXlfIXe8vpKrGctuEBUy8eQhBAceWLMnb\nWc7MtQVY64kxLd59TOWJSMujp3Wv+gRGsN4SEREREWm50uLdTLp9KC9PX095dQ2jeifSLcGzday1\nlpzichZl7WDexiLmbSzi6alreOr7NUSFBjIwJZr09q1IT4mmX9uoQyZnfliVx9RV+VzQL4kpS3O4\n5o1feHhUD255ez4pMWFcPyyVBz5ZyqNTVvK30T2OKa66USROh2HCnE38/fyex1SeiLQ8elr3qptC\n4tYIDBERERFp4YIDndx1Rud9zhtjSIwKITEqhJG9PFvBFu2qZFZmITPXFDBvYxHfrcgDoENsGDcO\n78CF/ZMIDtx3zYnyqhr+/sUKOsSF8e+LejO6byI3vZXBJS/9TJuIYN66fhCJUSFk5pcybtYG+rdv\nxeiDbGN7KF8uzaFrGzdd27j5ZMEW/nRuV0KDGrfvvrFwF+1jQjHm+I2qEZHDp6d1r7oRGGFKYIiI\niIjICSQ6LIjRfRLrkwsFJRXMyizg9Vkb+Z9Pl/L4N6vo0sZNnDuYeLeL9JRoTu4Uw/ifN7Fp227e\nvn4QQQEORnRpzTOX9eO5HzN5amyf+vUw/nxuV5Zk7+C+DxeTVbSbm4Z3OOLpJLnF5czbuJ17z0xj\nSMcYJi3ayheLtzJ2YLtGex+WZhcz6rlZPHZhLy4f1Hjlikjj0dO6l6aQiIiIiIhAnNvFBf2SGdM3\nibkbipg4L4vs7btZmr2D73aW89qsDTgdBoeBs3vEc0paXP1rz+udwHm9E/YoL9Dp4KXfDeAvk5bx\n+DermbRwC/8zsht920bRKiyI2lrLsq3FTF9dgNNpuH5o6j4jPr5algPAyF4JdIwLo0u8mwlzNzdq\nAuODjCwAXp2xnrHpbY/r2iYicnj0tO5Vl8DQFBIREREREc90k8EdYhjcIab+XFVNLQs372DGmgJW\n5e7koVGHt65FTLiLF383gB9W5fHXScu57s15gGf0B3imsdT5bOFWnhrbl+6JEfXnvlzimT7SqXU4\nAFcObsdDny1nSfYOeidHHXOsFdU1fL54K/ERLtYX7mLqqnzO7B5/zOWKSOPS07pX3RoYmkIiIiIi\nIrJ/gU4Hg1KjGZQafVSvP71rPEPujeXn9YWsL9jFuoJSKqstwzrHMLxzHMu2FPPHj5Yw5vmfuG1E\nR64ekkJldS0Zm7bzhzPT6ssZ0y+Jx6as4rEpq3jhyv608iZCjtYPK/MpLqviqbHp/OXTZbw2c70S\nGCLN0LFv/HwQxphzjDGrjTGZxpg/H+S+i4wx1hiT3pT1OZjSimqMgdCgfRcoEhERERGRxhES5OT0\nrvHcOLwDj13Ym/+7tA8X9EsmNtzFaV1a883dp3BG99Y8/f1ahjw2lZvHZwAwssHUlIjgQB4a1Z2M\nTUWc/fQMZqwpOKY6fbwgm/gIF6emtea6oanM3VDE0uziYypTRBpfkyUwjDFO4HngXKA7cLkxpvt+\n7nMDdwFzm6ouh6OkvJpwV4BWHBYRERER8aHosCBeuHIA39x9ChcNSGZtXil92kbRMS58j/suH9SO\nSbcPJTIkkKtf/4U/fbSEnOKyI/55haUVTFtdwJh+STgdhrGD2hLuCuC1WesbKyQRaSRNOQJjEJBp\nrV1vra0E3gfO3899/wT+DZQ3YV0OaVdFtda/EBERERFpJrq0cfPoBb2Y95czmHDjSfu9p0diJF/c\nOYybhqfyycJsTn18Go9OWUlW0e7D/jmfLdpKda3l4v7JgGd0x9iBbZm8JOeIyhGRpteUT+xJQFaD\n42xgj08eY0x/oK219ktjzB+bsC6HVFpRrfUvRERERESamfBD9NGDA508eF53rh6SwtPfr+XVmet5\nZcZ6kqJCGJQaTU2tZdO2XWRtLyMhMpiBKdH0b9+KiOAArIWJ8zbTOzmSzvHu+jJvGJbKxHlZ3PHu\nAibeMmSfXVFExDd89sRujHEATwLXHsa9NwM3A7Rr1zR7MpdWVGsLVRERERGRFqptdCj/d2kf7ji9\nE9NX5zN3QxGzMgsJcjpIjQ3jrO4RbNq2m4nzsnhz9sY9XvvImJ57HCdGhfDEJX249Z35/P2L5Tx2\nYe/jGImIHEhTPrFvAdo2OE72nqvjBnoC07zrTrQBPjfGjLbWZjQsyFr7CvAKQHp6um2KypZWVB8y\nuysiIiIiIs1bamwYqbGpXDs0db/Xq2pqWZNXQkV1LQ5jCHI66NrGvc995/Rsw22ndeSFaevolhBB\na3cwXyzeypItOxjTN4nrhqYSHRZE8e4qPlmYzercEsYObEu/dq2OqL7FZVU4DLiDA48qXpETSVM+\nsc8DOhtjUvEkLi4Drqi7aK0tBmLrjo0x04D79k5eHC+l5dUkRAb74keLiIjIYTDGnAM8AziB16y1\n/9rr+rXA4/z6B5PnrLWvHddKikizF+h00CMx8rDu/cNZXVi6pZiHPlsOQExYEF0T3Pz3h0zGzdrA\nyR1jmJVZSHlVLcGBDt6fl8XwzrHcMaITg1Kj6zcIqKm1TFmaw7yNRQQ4HAQFOCjaVcGCzTvIzC8l\nKSqEL+4cRvQxbgfbVMqrasjYuJ1hnWMPfbNIE2qyBIa1ttoYcwfwDZ6OxuvW2uXGmH8AGdbaz5vq\nZx+N0opqwoI0AkNERKQ5arC72Zl41tWaZ4z53Fq7Yq9bJ1pr7zjuFRQRv+R0GP57eT/GzdrAwJRo\nTu4YQ4DTwdq8El6Yto5ZmYVc2D+ZKwa1IzU2jHfmbOKVGesZ+8ocOsSFcfEAz/awL01fx/qCXfUj\nviurawlzOenXrhVn94jn1RkbuHviIt68diAOR/PbFfGZqWt5cdo6PrntZPof4QgTkcbUpE/s1top\nwJS9zj10gHtPa8q6HEppudbAEBERacbqdzcDMMbU7W62dwJDRKRRRYUG8YezuuxxrnO8m6fG9t3n\n3ltO7chVQ9rzxeKtfDx/C//5ejUAXdu4ef6K/pzbs81+ExSJUSE8+Okynv8xkzt/07lR679w83a6\ntHETepR/rC0uq2L8z5sA+Hh+thIY4lN6YgestZRWahtVERGRZuyQu5t5XWSMOQVYA9xjrc3azz0i\nIk0mNCiAsQPbMXZgOzYW7iJvZzkDU6IPOrLiikHtmLehiCe/X0NVTS3ZO8pYml1MVU0tbaNDSW4V\nSlRoIA4DDmMoLK0kq2g3W3aUMSglmj+e04XYcNceZVpreer7tTw7dS192kbx1nUDiQo98ikq43/e\nSGlFNX3aRvH54q389bfdtSuL+IzD1xVoDnZX1mAtGoEhIiLSsn0BpFhrewPfAW8d6EZjzM3GmAxj\nTEZBQcFxq6CInFhSYsM4qUPMIaeFGGP43wt60SkunGd/yGTGmkLaRYfSIymSnWVVfLM8l3EzN/Dy\n9PU892MmXy/LoaSimo5xYXy8IJvTn5jG+J83UlldC3iSF//75UqenbqWU9LiWLl1J2NfnkP+znLK\nKmv4MCOLW8fPZ1HWjoPWa3dlNa//tJHTu7bm/rO7UFJezXcr8hrr7RE5Ynpix7P+BUCYRmCIiIg0\nV4fa3Qxr7bYGh68B/zlQYcdjhzMRkSMR5grgk9tOpsS7uUDdAqCHkplfwkOfLeevny3nn5NX0i3B\njTs4kFmZhVwzpD0Pj+rBz+u3cdPbGZz//E+UVlRTUl5NkNPBjLUFvHzVAIZ3jttv2e/9kkXRrkpu\nH9GRfm1bkRgZzMcLshnVJ7ExQ28SVTW1BDr193p/oyd2oKTck8DQNqoiIiLN1kF3NwMwxiRYa3O8\nh6OBlce3iiIix8YdHHjE26l2au1mwo0nMW1NAXPWbWNx9g5W5e7kztM7ce+ZaRhjGNoplvE3nMS9\nHyxiREprrjzJs+jo1a//wvVvzuN/x/TC6TD8sDqfpdnFdGnj5qTUaF6buYHBHaIZ0D4agAv7J/PC\ntEzydpYTH9F8d3BcsXUnF774E63dwQzuEM3QTrH8tncizma4QKocGT2xA7u8IzDcmkIiIiLSLB3m\n7ma/N8aMBqqBIuBan1VYROQ4MsYwoktrRnRpfcB7BrRvxfQ/jtjj3MRbhnDTWxnc//ESAOLcLvq1\njWJ1Xkn9VJHHL+ldf/+F/ZN47sdMPl24hVtP7XjIeu0sr+K/U9eSU1zOjcM70Ldt1NGEd0Rqay0P\nTlpKWFAA3RLcfLsijw8yssnML91nMVZpefTEzq9TSMJdR5btFBERkePnULubWWsfAB443vUSEWmp\nIkMCefuGQXy9LJeOceH0SIyoX68jt7icrcVle+w60iEunAHtWzH+503sLKuiqqaWiOBALklvS5vI\nX0dkWGuZvCSHf0xeQWFpBW5XAJOX5DCiSxwXDUgmzBVASKCTDnFhtHbvO5Ijv6ScaasKmL6mgJKK\nasKCnIS7ArhycPt9kiAbCneREBlcv7Do+/OyWLh5B09e2ocL+ydTW2u576PFvDBtHb/pFn9ckihH\nKr+knN+/t5CRvRK4ekhKo5VbVllDSJB/LbiqBAa/TiEJc/lX44qIiIiIiBxMcKCTMf2S9jnfJjJ4\nj6REnWtOTuGeiYt4deZ6Ap0OyqpqeGbqWkb3SWRop1gyNm1n9rpCNm3bTc+kCMZdk06HuHDe/nkj\nr8xYz4+rf1042ekwnNktnquGtMcdHMDUlfn8uDqfJdnFnjpEBBMfGczWHWXkFZfz7Yo8Jt0+lNTY\nMACmLM3h9ncXkBoTxuOX9KF9TCj/+molgztEc4E3JofD8LfRPZizbhv3frCIKb8ffti7qOyqqGbj\ntl10axNxyIVYj1ZOcRlXvjqX9YW7yMwv5bKB7QgKOPa1O2avK+Tqcb/w7k2DGZQafdTlfLcij58y\nC3l4VPfDXpelKSmBwa8jMNwagSEiIiIiInJAo/skMqp3Qv3DbFbRbsbN2sAHGVl8snALblcAJ3WI\n5rbTOnLxgLb1607cdlonrj05hY2FuymvrqGssoYZawr4ICOLr5fnAmAM9G/Xij+e3YURXVrTLcFd\n/3M2b9vN+c/P4sa35vHp7UNZml3M3e8voldSJNtKK7nkpdl0iAunrKqGR8b02uNhOyI4kMcv6cOV\nr83l31+v4uFRPQ4Z5+zMQu7/eAnZ28voEBfGdSenMDA1mqkr85m8JIea2lqevLQvPZMij/q9zCra\nzRWvzWH7riru+k1nnpm6lq+X5zL6EIukVtfUMjOzkIEp0Qdcx/GVGeuprrX894e1jL9hf7uOH1pN\nreWRL1ewadtuuidGcGl620O/qIkpgcGva2BoG1UREREREZGDa5gcaBsdyt9G9+CeM9PI3r6bLvFu\nAg6w+0doUADdEyPqj4d2iuWeM9P4dkUetbWWU9LiiA4L2u9r28WE8sKVA7hq3FxueHMeK7buJDU2\njPHXn4TDAY9OWcV7v2zmztM70al1+D6vH9oplmuGtOeNnzayadtuxvRL4sxu8ZRX1bC1uIzC0kqq\nqmuprrXMXFvAhLmbSY0N46HfduezRVv462fL68vq3y6K3OJKLn5pNv+5uM8hEw77s3xrMde/OY/y\nqlom3HgSvZIi+XThFt6Zs+mg5c1YU8AjX65gTV4pXdu4GXftQJKiQva4JzO/lGmrC2gXHcrMtYUs\nztpBn6OYOvP9yjw2bdtNTFgQj01ZyRnd4g/YPseLnthpuI2qppCIiIiIiIgcqciQQCJDjnw0QnCg\n87ATAEM6xvD383vw4KfLSIoK4a3rBxEZ6hlF/9iFvbjj9E4k7mfaS50HRnYjzBXApwu38MOq/APe\nZwzcMCyV+87qQkiQk+uGprBg8w7W5JVwalociVEhFJRUcNuE+fz+vYV8sXgrBs+ipdU1lpAgJ6FB\nThIiQxiYEs3A1FZ7rPUxfU0Bt70zn4iQQCbeMpiubTxJnStOase/vlrFmrwS0uLde9QpM7+UR6es\n5IdV+bSLDuX+c7rw4o/rGPP8T4y7Jp3eyb8mKN6avZEgp4O3rx/E6Odm8cK0TF6+Kv2w3uOGxs3a\nQFJUCK9dk86o/87i0SkreeKSPkdcTmNSAgPq90F2BSiBISIiIiIi0lxdeVJ7YsKC6JUctc8aHXuP\nRNhbcKCT+8/pyn1ndWHuhiJ+XldIVGgQCZHBxLldBAU4cDoM0WFBJET+WpYxhgHtWzGg/a8Lmsa5\nXUy4cTCPTlnJdyvycAcHEBEcSKDTQUl5Nfk7K5ixppA3Z28EPOt5pMSGEh8RzOQlOaTFu3nj2oF7\nxHDJgGSe/HYNE+Zs4u/n9wRgx+5Knv5+Le/M2URIoJMHzu3KtUNTcAU4OaNbPNe9MY9LX/6ZZy7r\nx9k92lBcVsXHC7IZ3TeRlNgwrj05hWd/yGRtXgmd90qKHMzS7GJ+2VDEX87rRreECG4+pQMvTFvH\nRf2TGdIx5rDLaWxKYOCZQqLpIyIiIiIiIs3fOT0Tjun1DodhSMeYY34QDwpw8LfRPfjb6P2vqVFV\nU8uyLcXM21jEqtwSNhbu4qfMQs7sFs8Tl/bZZ/2KmHAXI3u14eMFW7hsUDs+mp/NB/Oy2FVZzeWD\n2nHPmWnEhrvq70+LdzPp9qHc9HYGt74znwfO7YrBsLuyhuuGpgBw7dBUXp25gRenrePJsX33qd/y\nrTvJLS6noLQCpzGM6pOAOziQcbPWExbk5NKBnnUv7jy9M18s2cqDk5by1V3DffbHfz2145lCcqDF\nT0RERERERESOVKDTQb92rejXYCvaQ7lqSHsmLdrKuc/MJMBhGNkrgdtGdKyfZrK3OLeL928ezL0f\nLOLRKasIcjoYlBpNj0TPdJ7osCCuOKkdb87eiNNbXlobNx9lZPPuL5vI21mxR3mPfbWSS9PbMnlJ\nDlcPSSEi2DNFJyTIyWMX9GbrjjICHce+S8rR0lM7nikkSmCIiIiIiIiIL/Vv14rrh6YS7nJy5eD2\nxEcceE2POsGBTp67vD9PxKzmhWnruPXUDntcv/P0TmzfXcnXy3L5cH52/flT0uL4y3nJpMSE0TrC\nRU5xOa/MWMfrP23AQP0ojjrDOsc2RojHxFhrfV2HI5Kenm4zMjIatcwPMrLYVapu4IoAAAmZSURB\nVFHNdUNTG7VcERERf2SMmW+tPfLVwJqppuhbiIiI+EJxWRWRIYH7vVZRXcPszG2szN3JuT0TSI0N\n2+99Gwp3sa20gvSU6Kas6h4Ot2+hYQfQLPazFRERERERETkWB0peALgCnIzo2poRXVsftIzU2LAD\nJjd8zXeTV0REREREREREDpMSGCIiIiIiIiLS7CmBISIiIiIiIiLNnhIYIiIiIiIiItLsKYEhIiIi\nIiIiIs2eEhgiIiIiIiIi0uwpgSEiIiIiIiIizZ4SGCIiIiIiIiLS7CmBISIiIiIiIiLNnhIYIiIi\nIiIiItLsGWutr+twRIwxBcCmJig6FihsgnKbI8XqnxSrf1Ks/qmlx9reWhvn60o0FvUtGoVi9U+K\n1T8pVv/U0mM9rL5Fi0tgNBVjTIa1Nt3X9TgeFKt/Uqz+SbH6pxMp1hPZidTOitU/KVb/pFj904kS\nq6aQiIiIiIiIiEizpwSGiIiIiIiIiDR7SmD86hVfV+A4Uqz+SbH6J8Xqn06kWE9kJ1I7K1b/pFj9\nk2L1TydErFoDQ0RERERERESaPY3AEBEREREREZFmTwkMwBhzjjFmtTEm0xjzZ1/Xp7EYY9oaY340\nxqwwxiw3xtzlPR9tjPnOGLPW+99Wvq5rYzHGOI0xC40xk73HqcaYud62nWiMCfJ1HRuDMSbKGPOR\nMWaVMWalMWaIv7arMeYe77/fZcaY94wxwf7UrsaY140x+caYZQ3O7bctjcez3riXGGP6+67mR+4A\nsT7u/Xe8xBjzqTEmqsG1B7yxrjbGnO2bWh+d/cXa4NofjDHWGBPrPW7R7Sr78td+Bahv4T32m99B\nDalv4R/tqn6F+hUtvV0P5YRPYBhjnMDzwLlAd+ByY0x339aq0VQDf7DWdgcGA7d7Y/szMNVa2xmY\n6j32F3cBKxsc/xt4ylrbCdgO3OCTWjW+Z4CvrbVdgT54Yva7djXGJAG/B9KttT0BJ3AZ/tWubwLn\n7HXuQG15LtDZ+3Uz8OJxqmNjeZN9Y/0O6Gmt7Q2sAR4A8H5WXQb08L7mBe/ndUvxJvvGijGmLXAW\nsLnB6ZbertKAn/crQH0L8K/fQQ2pb+Ef7fom6leoX9Gy2/WgTvgEBjAIyLTWrrfWVgLvA+f7uE6N\nwlqbY61d4P2+BM8voiQ88b3lve0tYIxvati4jDHJwHnAa95jA5wOfOS9xS9iNcZEAqcA4wCstZXW\n2h34absCAUCIMSYACAVy8KN2tdbOAIr2On2gtjwfeNt6zAGijDEJx6emx25/sVprv7XWVnsP5wDJ\n3u/PB9631lZYazcAmXg+r1uEA7QrwFPA/UDDBahadLvKPvy2XwHqW6hv0fJj9fLbvoX6FepX0MLb\n9VCUwPD80s1qcJztPedXjDEpQD9gLhBvrc3xXsoF4n1Urcb2NJ7/gWu9xzHAjgYfYv7StqlAAfCG\nd0jra8aYMPywXa21W4An8GSVc4BiYD7+2a4NHagt/f3z6nrgK+/3fherMeZ8YIu1dvFel/wu1hPc\nCdOe6lsA/tO+6lv4Z7vWUb/CD2M9UfsVSmCcAIwx4cDHwN3W2p0Nr1nPNjQtfisaY8xvgXxr7Xxf\n1+U4CAD6Ay9aa/sBu9hrSKcftWsrPFnkVCARCGM/w+f8mb+05aEYYx7EMzR9gq/r0hSMMaHA/wAP\n+bouIo1BfQu/o77FCcJf2vFQ1K/wX0pgwBagbYPjZO85v2CMCcTTwZhgrf3EezqvbhiR97/5vqpf\nIxoKjDbGbMQzXPd0PHM5o7zDA8F/2jYbyLbWzvUef4Sn0+GP7XoGsMFaW2CtrQI+wdPW/tiuDR2o\nLf3y88oYcy3wW+BK++ve3v4Wa0c8neXF3s+pZGCBMaYN/hfric7v21N9C7/8HaS+hX+2ax31K/wv\n1hO2X6EEBswDOntXHg7Cs7jL5z6uU6PwztMcB6y01j7Z4NLnwDXe768BPjvedWts1toHrLXJ1toU\nPG34g7X2SuBH4GLvbf4Say6QZYzp4j31G2AFftiueIZ3DjbGhHr/PdfF6nftupcDteXnwNXe1aUH\nA8UNhoS2SMaYc/AMzx5trd3d4NLnwGXGGJcxJhXPQlS/+KKOjcFau9Ra29pam+L9nMoG+nv/f/a7\ndj3B+W2/AtS3UN+i5cfKidm3UL9C/YoW3a57sNae8F/ASDyr1K4DHvR1fRoxrmF4hogtARZ5v0bi\nmb85FVgLfA9E+7qujRz3acBk7/cd8Hw4ZQIfAi5f16+RYuwLZHjbdhLQyl/bFfg7sApYBowHXP7U\nrsB7eObgVuH55XPDgdoSMHh2N1gHLMWzgrrPYzjGWDPxzNOs+4x6qcH9D3pjXQ2c6+v6H2use13f\nCMT6Q7vqa7/t75f9Cm9s6lv40e+gvWJU38IP2lX9CvUrWnq7HurLeIMUEREREREREWm2NIVERERE\nRERERJo9JTBEREREREREpNlTAkNEREREREREmj0lMERERERERESk2VMCQ0RERERERESaPSUwRKTZ\nMcacZoyZ7Ot6iIiIiH9Q30LEPyiBISIiIiIiIiLNnhIYInLUjDG/M8b8YoxZZIx52RjjNMaUGmOe\nMsYsN8ZMNcbEee/ta4yZY4xZYoz51BjTynu+kzHme2PMYmPMAmNMR2/x4caYj4wxq4wxE4wxxmeB\nioiIyHGhvoWIHIwSGCJyVIwx3YCxwFBrbV+gBrgSCAMyrLU9gOnAw96XvA38yVrbG1ja4PwE4Hlr\nbR/gZCDHe74fcDfQHegADG3yoERERMRn1LcQkUMJ8HUFRKTF+g0wAJjn/QNGCJAP1AITvfe8A3xi\njIkEoqy1073n3wI+NMa4gSRr7acA1tpyAG95v1hrs73Hi4AUYFbThyUiIiI+or6FiByUEhgicrQM\n8Ja19oE9Thrz173us0dZfkWD72vQ55WIiIi/U99CRA5KU0hE5GhNBS42xrQGMMZEG2Pa4/lcudh7\nzxXALGttMbDdGDPce/4qYLq1tgTINsaM8ZbhMsaEHtcoREREpLlQ30JEDkpZRxE5KtbaFcaYvwDf\nGmMcQBVwO7ALGOS9lo9nLivANcBL3k7EeuA67/mrgJeNMf/wlnHJcQxDREREmgn1LUTkUIy1RzsC\nS0RkX8aYUmttuK/rISIiIv5BfQsRqaMpJCIiIiIiIiLS7GkEhoiIiIiIiIg0exqBISIiIiIiIiLN\nnhIYIiIiIiIiItLsKYEhIiIiIiIiIs2eEhgiIiIiIiIi0uwpgSEiIiIiIiIizZ4SGCIiIiIiIiLS\n7P1/WJd3eQg4+acAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96a9ccceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize model learning\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Training history of root model\", fontsize=16)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load best performance model\n",
    "best_model = load_model(\"models/embeddings8-Mel2-Cho2-FC2_150ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33435, 135, 14)\n",
      "(33435, 7, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody_test.shape)\n",
    "print(X_chords_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord prediction: 0.7584\n",
      "Kappa score of combined chord prediction: 0.7524\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of labels\n",
    "\n",
    "# Predict chords from each test sample melody\n",
    "Y_chord_pred = model.predict([X_melody_test, X_chords_test])\n",
    "\n",
    "# Compute accuracy and kappa score \n",
    "print(\"Categorical accuracy of combined chord prediction: {0:.4f}\".format(harmoutil.compute_accuracy_score(Y_chord_test, Y_chord_pred)))\n",
    "print(\"Kappa score of combined chord prediction: {0:.4f}\".format(harmoutil.compute_kappa_score(Y_chord_test, Y_chord_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord pitch prediction: 0.9147\n",
      "TP: 113409 TN: 253581 FP: 17186 FN: 17044\n",
      "Kappa score of combined chord pitch prediction: 0.8056\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of pitches\n",
    "\n",
    "def label_to_pitch_tensors(predictions):\n",
    "    predicted_chords = [int_to_chord[np.argmax(ch)] for ch in predictions]\n",
    "    pitch_chords = [harmoutil.chord_to_notes(label) for label in predicted_chords]\n",
    "    \n",
    "    Y_pitches = np.zeros((predictions.shape[0], 12), dtype='float32')\n",
    "    for i, chord_pitches in enumerate(pitch_chords):\n",
    "        for j, pitch_presence in enumerate(chord_pitches):\n",
    "            Y_pitches[i, j] = pitch_presence\n",
    "\n",
    "    return Y_pitches\n",
    "\n",
    "Y_pitch_pred = label_to_pitch_tensors(Y_chord_pred)\n",
    "Y_pitch_test = label_to_pitch_tensors(Y_chord_test)\n",
    "\n",
    "print(\"Categorical accuracy of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_accuracy_score(Y_pitch_test, Y_pitch_pred)))\n",
    "print(\"Kappa score of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_kappa_score(Y_pitch_test, Y_pitch_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
