{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, GRU, concatenate\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# Custom library for the project\n",
    "import sys\n",
    "sys.path.insert(0, '../../src')\n",
    "import harmoutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'harmoutil' from '../../src/harmoutil.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Remove when done with kernel\n",
    "import importlib\n",
    "importlib.reload(harmoutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = harmoutil.load_pickled_data(\"../../data/refined_data.pkl\") # lists of (chord label, melody seqs) by sections\n",
    "augmented_data = harmoutil.transpose_and_augment_data(raw_data)\n",
    "data = [harmoutil.to_sevenths(section) for section in augmented_data]\n",
    "data = [harmoutil.melody_to_octave_range(section) for section in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chords: 334344 | Sample chord: E6\n",
      "Number of melody notes in the data: 2209944 | Sample melody note: 4\n",
      "Unique notes: [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Unique notes: ['A', 'A+', 'A+7', 'A+j7', 'A-', 'A-6', 'A-7', 'A-j7', 'A6', 'A7', 'Ab', 'Ab+', 'Ab+7', 'Ab+j7', 'Ab-', 'Ab-6', 'Ab-7', 'Ab-j7', 'Ab6', 'Ab7', 'Abj7', 'Abm7b5', 'Abo', 'Abo7', 'Absus', 'Absus7', 'Aj7', 'Am7b5', 'Ao', 'Ao7', 'Asus', 'Asus7', 'B', 'B+', 'B+7', 'B+j7', 'B-', 'B-6', 'B-7', 'B-j7', 'B6', 'B7', 'Bb', 'Bb+', 'Bb+7', 'Bb+j7', 'Bb-', 'Bb-6', 'Bb-7', 'Bb-j7', 'Bb6', 'Bb7', 'Bbj7', 'Bbm7b5', 'Bbo', 'Bbo7', 'Bbsus', 'Bbsus7', 'Bj7', 'Bm7b5', 'Bo', 'Bo7', 'Bsus', 'Bsus7', 'C', 'C+', 'C+7', 'C+j7', 'C-', 'C-6', 'C-7', 'C-j7', 'C6', 'C7', 'Cj7', 'Cm7b5', 'Co', 'Co7', 'Csus', 'Csus7', 'D', 'D+', 'D+7', 'D+j7', 'D-', 'D-6', 'D-7', 'D-j7', 'D6', 'D7', 'Db', 'Db+', 'Db+7', 'Db+j7', 'Db-', 'Db-6', 'Db-7', 'Db-j7', 'Db6', 'Db7', 'Dbj7', 'Dbm7b5', 'Dbo', 'Dbo7', 'Dbsus', 'Dbsus7', 'Dj7', 'Dm7b5', 'Do', 'Do7', 'Dsus', 'Dsus7', 'E', 'E+', 'E+7', 'E+j7', 'E-', 'E-6', 'E-7', 'E-j7', 'E6', 'E7', 'Eb', 'Eb+', 'Eb+7', 'Eb+j7', 'Eb-', 'Eb-6', 'Eb-7', 'Eb-j7', 'Eb6', 'Eb7', 'Ebj7', 'Ebm7b5', 'Ebo', 'Ebo7', 'Ebsus', 'Ebsus7', 'Ej7', 'Em7b5', 'Eo', 'Eo7', 'Esus', 'Esus7', 'F', 'F+', 'F+7', 'F+j7', 'F-', 'F-6', 'F-7', 'F-j7', 'F6', 'F7', 'Fj7', 'Fm7b5', 'Fo', 'Fo7', 'Fsus', 'Fsus7', 'G', 'G+', 'G+7', 'G+j7', 'G-', 'G-6', 'G-7', 'G-j7', 'G6', 'G7', 'Gb', 'Gb+', 'Gb+7', 'Gb+j7', 'Gb-', 'Gb-6', 'Gb-7', 'Gb-j7', 'Gb6', 'Gb7', 'Gbj7', 'Gbm7b5', 'Gbo', 'Gbo7', 'Gbsus', 'Gbsus7', 'Gj7', 'Gm7b5', 'Go', 'Go7', 'Gsus', 'Gsus7', 'NC']\n"
     ]
    }
   ],
   "source": [
    "# Isolate relevant data\n",
    "def get_notes_by_chord(beats):\n",
    "    return [note for beat in beats for note in beat]\n",
    "\n",
    "def get_chords_by_section(section):\n",
    "    return [chord_info[0] for chord_info in section]\n",
    "\n",
    "# def check_if_augmented_major(section):\n",
    "#     section_chords = get_chords_by_section(section)\n",
    "#     for ch in section_chords:\n",
    "#         if \"+j7\" in ch:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "# data = [section for section in data if not check_if_augmented_major(section)]\n",
    "# print(\"---Remove sections with augmented major chord---\")\n",
    "# print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections_bf_augmaj7 = [get_chords_by_section(section) for section in data]\n",
    "chords = [chord_info[0] for section in data for chord_info in section]\n",
    "unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords_bf_augmaj7 = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "notes = [note for chord_notes in notes_by_chords_bf_augmaj7 for note in chord_notes]\n",
    "unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "# print(sum([len(section) for section in chords_by_sections]))\n",
    "# print(\"Number of sections: {} | Sample section chords: {}\".format(len(chords_by_sections), chords_by_sections[0]))\n",
    "print(\"Number of chords: {} | Sample chord: {}\".format(len(chords), chords[0]))\n",
    "# print(\"Number of melodies {} | Sample melody: {}\".format(len(notes_by_chords), notes_by_chords[0]))\n",
    "print(\"Number of melody notes in the data: {} | Sample melody note: {}\".format(len(notes), notes[0]))\n",
    "print(\"Unique notes: {}\".format(unique_notes))\n",
    "print(\"Unique notes: {}\".format(unique_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melody note to integer mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, '<pad>': 13, -1: 12}\n",
      "\n",
      "Integer to melody note mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: -1, 13: '<pad>'}\n",
      "\n",
      "Chord label to integer mapping:\n",
      " {'Fo7': 157, 'B-': 36, 'F-6': 149, 'Ab-6': 15, 'Ebo7': 135, 'A-j7': 7, 'Ebsus7': 137, 'Bb': 42, 'Ab-7': 16, 'E+7': 114, 'Gbsus': 184, 'Bb-j7': 49, '<bos>': 193, 'Dsus': 110, 'D': 80, 'C6': 72, 'Gb+7': 172, 'Aj7': 26, 'G+': 161, 'G+j7': 163, 'E+': 113, 'Gb-': 174, 'Bo': 60, 'Db+j7': 93, 'Gb7': 179, 'Gb6': 178, 'F7': 153, 'D6': 88, 'D-j7': 87, 'Bsus': 62, 'Ab': 10, 'F': 144, 'Db+7': 92, 'Ej7': 138, 'F+j7': 147, 'E6': 120, 'B7': 41, 'Ab+': 11, 'D+': 81, 'Fo': 156, 'Abo7': 23, 'Bbo': 54, 'Ab+j7': 13, 'E-6': 117, 'Ab6': 18, 'Gbo': 182, 'Dbo': 102, 'Ebo': 134, 'Bbsus': 56, 'Bb6': 50, 'G': 160, 'Abj7': 20, 'Ab+7': 12, 'A+j7': 3, 'Dbsus7': 105, 'Db+': 91, 'D-': 84, 'Fsus': 158, 'Db-': 94, 'F6': 152, 'Asus7': 31, 'Eb6': 130, 'E': 112, 'Asus': 30, 'G+7': 162, 'Dbj7': 100, 'Gsus7': 191, 'Esus7': 143, 'Eb-7': 128, 'G6': 168, 'Gb-7': 176, 'Ao': 28, 'Go': 188, 'Gb-j7': 177, 'A+7': 2, 'Bb-6': 47, 'A-6': 5, 'F+': 145, 'G7': 169, 'C-': 68, 'Eb-6': 127, 'Bb+': 43, 'F-j7': 151, 'D-6': 85, 'E-7': 118, 'C+7': 66, 'Bb+7': 44, 'Ab-': 14, 'C-j7': 71, 'Eb-': 126, 'Gsus': 190, 'Bbo7': 55, 'Eb+j7': 125, 'Dbm7b5': 101, 'Bj7': 58, 'Ab-j7': 17, 'Bbm7b5': 53, 'G-7': 166, 'C-7': 70, 'C+j7': 67, 'A+': 1, 'G-6': 165, 'G-': 164, 'Ebm7b5': 133, 'Co': 76, 'Bbj7': 52, 'Bb-7': 48, 'Eo7': 141, 'Co7': 77, 'D+7': 82, 'Bb7': 51, 'F-': 148, 'E-': 116, 'Eb+7': 124, 'Bb-': 46, 'Eb-j7': 129, 'Dj7': 106, 'Bo7': 61, 'Do7': 109, 'Gbo7': 183, 'B': 32, 'Dm7b5': 107, 'Eb7': 131, 'G-j7': 167, 'F-7': 150, 'Csus7': 79, 'F+7': 146, 'D+j7': 83, 'Dsus7': 111, 'B+': 33, 'Db': 90, '<eos>': 194, 'NC': 192, 'A': 0, 'B+j7': 35, 'Db7': 99, 'Esus': 142, 'Absus': 24, 'Gbsus7': 185, 'E+j7': 115, 'D7': 89, 'C7': 73, 'Gbm7b5': 181, 'Abo': 22, 'Fm7b5': 155, 'Cj7': 74, 'Gb+j7': 173, 'Bbsus7': 57, 'Gb': 170, 'Ab7': 19, 'Gj7': 186, 'B6': 40, 'Bsus7': 63, 'Csus': 78, 'B-7': 38, 'Fj7': 154, 'Eo': 140, 'D-7': 86, 'Db6': 98, 'Fsus7': 159, 'Gb+': 171, 'Eb+': 123, 'Ao7': 29, 'Gb-6': 175, 'Gm7b5': 187, 'B+7': 34, 'A-': 4, 'Am7b5': 27, 'Dbo7': 103, 'E-j7': 119, 'Bb+j7': 45, 'E7': 121, 'Cm7b5': 75, 'Absus7': 25, 'Dbsus': 104, 'C': 64, 'Db-6': 95, 'Bm7b5': 59, 'B-6': 37, 'Em7b5': 139, 'A7': 9, 'Db-7': 96, 'C-6': 69, 'Gbj7': 180, 'Ebj7': 132, 'Eb': 122, 'A-7': 6, 'Do': 108, 'Go7': 189, 'Ebsus': 136, 'A6': 8, 'B-j7': 39, 'C+': 65, 'Abm7b5': 21, 'Db-j7': 97}\n",
      "\n",
      "Integer to chord label mapping:\n",
      " {0: 'A', 1: 'A+', 2: 'A+7', 3: 'A+j7', 4: 'A-', 5: 'A-6', 6: 'A-7', 7: 'A-j7', 8: 'A6', 9: 'A7', 10: 'Ab', 11: 'Ab+', 12: 'Ab+7', 13: 'Ab+j7', 14: 'Ab-', 15: 'Ab-6', 16: 'Ab-7', 17: 'Ab-j7', 18: 'Ab6', 19: 'Ab7', 20: 'Abj7', 21: 'Abm7b5', 22: 'Abo', 23: 'Abo7', 24: 'Absus', 25: 'Absus7', 26: 'Aj7', 27: 'Am7b5', 28: 'Ao', 29: 'Ao7', 30: 'Asus', 31: 'Asus7', 32: 'B', 33: 'B+', 34: 'B+7', 35: 'B+j7', 36: 'B-', 37: 'B-6', 38: 'B-7', 39: 'B-j7', 40: 'B6', 41: 'B7', 42: 'Bb', 43: 'Bb+', 44: 'Bb+7', 45: 'Bb+j7', 46: 'Bb-', 47: 'Bb-6', 48: 'Bb-7', 49: 'Bb-j7', 50: 'Bb6', 51: 'Bb7', 52: 'Bbj7', 53: 'Bbm7b5', 54: 'Bbo', 55: 'Bbo7', 56: 'Bbsus', 57: 'Bbsus7', 58: 'Bj7', 59: 'Bm7b5', 60: 'Bo', 61: 'Bo7', 62: 'Bsus', 63: 'Bsus7', 64: 'C', 65: 'C+', 66: 'C+7', 67: 'C+j7', 68: 'C-', 69: 'C-6', 70: 'C-7', 71: 'C-j7', 72: 'C6', 73: 'C7', 74: 'Cj7', 75: 'Cm7b5', 76: 'Co', 77: 'Co7', 78: 'Csus', 79: 'Csus7', 80: 'D', 81: 'D+', 82: 'D+7', 83: 'D+j7', 84: 'D-', 85: 'D-6', 86: 'D-7', 87: 'D-j7', 88: 'D6', 89: 'D7', 90: 'Db', 91: 'Db+', 92: 'Db+7', 93: 'Db+j7', 94: 'Db-', 95: 'Db-6', 96: 'Db-7', 97: 'Db-j7', 98: 'Db6', 99: 'Db7', 100: 'Dbj7', 101: 'Dbm7b5', 102: 'Dbo', 103: 'Dbo7', 104: 'Dbsus', 105: 'Dbsus7', 106: 'Dj7', 107: 'Dm7b5', 108: 'Do', 109: 'Do7', 110: 'Dsus', 111: 'Dsus7', 112: 'E', 113: 'E+', 114: 'E+7', 115: 'E+j7', 116: 'E-', 117: 'E-6', 118: 'E-7', 119: 'E-j7', 120: 'E6', 121: 'E7', 122: 'Eb', 123: 'Eb+', 124: 'Eb+7', 125: 'Eb+j7', 126: 'Eb-', 127: 'Eb-6', 128: 'Eb-7', 129: 'Eb-j7', 130: 'Eb6', 131: 'Eb7', 132: 'Ebj7', 133: 'Ebm7b5', 134: 'Ebo', 135: 'Ebo7', 136: 'Ebsus', 137: 'Ebsus7', 138: 'Ej7', 139: 'Em7b5', 140: 'Eo', 141: 'Eo7', 142: 'Esus', 143: 'Esus7', 144: 'F', 145: 'F+', 146: 'F+7', 147: 'F+j7', 148: 'F-', 149: 'F-6', 150: 'F-7', 151: 'F-j7', 152: 'F6', 153: 'F7', 154: 'Fj7', 155: 'Fm7b5', 156: 'Fo', 157: 'Fo7', 158: 'Fsus', 159: 'Fsus7', 160: 'G', 161: 'G+', 162: 'G+7', 163: 'G+j7', 164: 'G-', 165: 'G-6', 166: 'G-7', 167: 'G-j7', 168: 'G6', 169: 'G7', 170: 'Gb', 171: 'Gb+', 172: 'Gb+7', 173: 'Gb+j7', 174: 'Gb-', 175: 'Gb-6', 176: 'Gb-7', 177: 'Gb-j7', 178: 'Gb6', 179: 'Gb7', 180: 'Gbj7', 181: 'Gbm7b5', 182: 'Gbo', 183: 'Gbo7', 184: 'Gbsus', 185: 'Gbsus7', 186: 'Gj7', 187: 'Gm7b5', 188: 'Go', 189: 'Go7', 190: 'Gsus', 191: 'Gsus7', 192: 'NC', 193: '<bos>', 194: '<eos>'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create categorical data mappings\n",
    "note_to_int = dict([(c, i) for i, c in enumerate(unique_notes[1:])])\n",
    "note_to_int[-1] = len(note_to_int)\n",
    "note_to_int['<pad>'] = len(note_to_int)\n",
    "\n",
    "int_to_note = dict([(k, v) for v, k in note_to_int.items()])\n",
    "\n",
    "chord_to_int = dict([(c, i) for i, c in enumerate(unique_chords)])\n",
    "chord_to_int['<bos>'] = len(chord_to_int)\n",
    "chord_to_int['<eos>'] = len(chord_to_int)\n",
    "\n",
    "int_to_chord = dict([(k, v) for v, k in chord_to_int.items()])\n",
    "\n",
    "print(\"Melody note to integer mapping:\\n {}\\n\".format(note_to_int))\n",
    "print(\"Integer to melody note mapping:\\n {}\\n\".format(int_to_note))\n",
    "print(\"Chord label to integer mapping:\\n {}\\n\".format(chord_to_int))\n",
    "print(\"Integer to chord label mapping:\\n {}\\n\".format(int_to_chord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 334344\n",
      "Number of distinct melody notes: 14\n",
      "Number of distinct chord labels: 195\n",
      "Maximum length of melody sequences for one chord: 135\n",
      "Number of past chords given as input: 7\n"
     ]
    }
   ],
   "source": [
    "# Define numerical variables\n",
    "\n",
    "n_samples = len(chords)\n",
    "n_chords = len(chord_to_int)\n",
    "n_notes = len(note_to_int)\n",
    "max_mel_len = max([len(mel) for mel in notes_by_chords_bf_augmaj7])\n",
    "chord_context_len = 7\n",
    "\n",
    "# print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Number of distinct melody notes: {}\".format(n_notes))\n",
    "print(\"Number of distinct chord labels: {}\".format(n_chords))\n",
    "print(\"Maximum length of melody sequences for one chord: {}\".format(max_mel_len))\n",
    "print(\"Number of past chords given as input: {}\".format(chord_context_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [4]]\n"
     ]
    }
   ],
   "source": [
    "mel_by_sections = [mel for section in data for ch, mel in section]\n",
    "print(mel_by_sections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Remove sections with augmented major chord---\n",
      "Number of sections: 28836\n",
      "\n",
      "Sample input melody sequence: [8, 3, 6, '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "\n",
      "Sample input chord sequence: ['<bos>', '<bos>', 'E6', 'Db7', 'Gb-7', 'B7', 'E']\n",
      "\n",
      "Sample target chord: Db-7\n",
      "\n",
      "Input melody: 333480, Input chords: 333480, Target chords: 333480\n"
     ]
    }
   ],
   "source": [
    "# Prepare tensor data\n",
    "\n",
    "\n",
    "def check_if_augmented_major(section):\n",
    "    section_chords = get_chords_by_section(section)\n",
    "    for ch in section_chords:\n",
    "        if \"+j7\" in ch:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "data = [section for section in data if not check_if_augmented_major(section)]\n",
    "print(\"---Remove sections with augmented major chord---\")\n",
    "print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections = [get_chords_by_section(section) for section in data]\n",
    "# chords = [chord_info[0] for section in data for chord_info in section]\n",
    "# unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "# notes = [note for chord_notes in notes_by_chords for note in chord_notes]\n",
    "# unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "\n",
    "\n",
    "def pad_melody(melody, max_len):\n",
    "    return melody + (max_len-len(melody))*['<pad>']\n",
    "\n",
    "def build_input_chord_sequences(chord_seq, context_len):\n",
    "    padded_sequence = context_len*['<bos>'] + chord_seq\n",
    "    formatted_sequences = [padded_sequence[i:i+context_len+1] for i in range(len(chord_seq))]\n",
    "    return formatted_sequences\n",
    "\n",
    "# Melody\n",
    "input_melody_data = [pad_melody(melody, max_mel_len) for melody in notes_by_chords]\n",
    "print(\"Sample input melody sequence: {}\\n\".format(input_melody_data[5]))\n",
    "\n",
    "# Chords\n",
    "formatted_chords_data = []\n",
    "for section_chords in chords_by_sections:\n",
    "    formatted_chords_data += build_input_chord_sequences(section_chords, chord_context_len)\n",
    "    \n",
    "input_chords_data = [ch[:-1] for ch in formatted_chords_data]\n",
    "target_chords_data = [ch[-1] for ch in formatted_chords_data]\n",
    "print(\"Sample input chord sequence: {}\\n\".format(input_chords_data[5]))\n",
    "print(\"Sample target chord: {}\\n\".format(target_chords_data[5]))\n",
    "\n",
    "print(\"Input melody: {}, Input chords: {}, Target chords: {}\".format(len(input_melody_data), len(input_chords_data), len(target_chords_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 16)\n"
     ]
    }
   ],
   "source": [
    "# Load embedding vectors\n",
    "\n",
    "num_dim = 16\n",
    "num_ch = 192\n",
    "num_notes = 12\n",
    "\n",
    "# Define embedding training model and load weights\n",
    "input_layer = Input(shape=(num_ch,)) \n",
    "embeddings_layer = Dense(num_dim, activation='linear', name=\"embeddings\")(input_layer)\n",
    "root_output_layer = Dense(num_notes, activation='softmax')(embeddings_layer)\n",
    "interval_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "pitch_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "melody_output_layer = Dense(num_notes, activation='relu')(embeddings_layer)\n",
    "embeddings_model = Model(input_layer, [root_output_layer, interval_output_layer, pitch_output_layer, melody_output_layer])\n",
    "\n",
    "embeddings_model.load_weights(\"../Skipgram & WJD/weights/combined_weights_dim16.h5\")\n",
    "\n",
    "X_chords_embeddings = embeddings_model.layers[1].get_weights()[0]\n",
    "print(X_chords_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embedding vector for each chord: 16\n"
     ]
    }
   ],
   "source": [
    "# Build tensors\n",
    "\n",
    "n_dimensions = X_chords_embeddings.shape[1]\n",
    "print(\"Size of embedding vector for each chord: {}\".format(n_dimensions))\n",
    "\n",
    "X_melody = np.zeros((n_samples, max_mel_len, n_notes), dtype='float32')\n",
    "X_chords = np.zeros((n_samples, chord_context_len, n_dimensions), dtype='float32')\n",
    "Y_chord = np.zeros((n_samples, n_chords), dtype='float32')\n",
    "\n",
    "for i, (input_mel, input_ch, target_ch) in enumerate(zip(input_melody_data, input_chords_data, target_chords_data)):\n",
    "    Y_chord[i, chord_to_int[target_ch]] = 1\n",
    "    for j, chord in enumerate(input_ch):\n",
    "#         X_chords[i, j, chord_to_int[chord]] = 1\n",
    "        chord_index = chord_to_int[chord]\n",
    "        if (chord_index < num_ch):\n",
    "            X_chords[i, j, :] = X_chords_embeddings[chord_index, :]\n",
    "    \n",
    "    for j, note in enumerate(input_mel):\n",
    "        X_melody[i, j, note_to_int[note]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334344, 135, 14)\n",
      "(334344, 7, 16)\n",
      "(334344, 195)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody.shape)\n",
    "print(X_chords.shape)\n",
    "print(Y_chord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset into 80%-10%-10% train-valid-test sets\n",
    "seed = 0\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "\n",
    "for train_index, aux_index in sss.split(X_chords, Y_chord):\n",
    "    X_melody_train, X_melody_aux = X_melody[train_index], X_melody[aux_index]\n",
    "    X_chords_train, X_chords_aux = X_chords[train_index], X_chords[aux_index]\n",
    "    Y_chord_train, Y_chord_aux = Y_chord[train_index], Y_chord[aux_index]\n",
    "    \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)\n",
    "\n",
    "for valid_index, test_index in sss.split(X_chords_aux, Y_chord_aux):\n",
    "    X_melody_valid, X_melody_test = X_melody[valid_index], X_melody[test_index]\n",
    "    X_chords_valid, X_chords_test = X_chords[valid_index], X_chords[test_index]\n",
    "    Y_chord_valid, Y_chord_test = Y_chord[valid_index], Y_chord[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 135, 14)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 7, 16)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_1 (GRU)                      (None, 135, 128)      54912       input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      (None, 7, 128)        55680       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_2 (GRU)                      (None, 135, 128)      98688       gru_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_5 (GRU)                      (None, 7, 128)        98688       gru_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_3 (GRU)                      (None, 128)           98688       gru_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_6 (GRU)                      (None, 128)           98688       gru_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 256)           0           gru_3[0][0]                      \n",
      "                                                                   gru_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 128)           32896       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 128)           16512       dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 195)           25155       dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 579,907\n",
      "Trainable params: 579,907\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define neual net architecture\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "melody_input = Input(shape=(max_mel_len, n_notes))\n",
    "melody_gru1 = GRU(latent_dim, return_sequences=True)(melody_input)\n",
    "melody_gru2 = GRU(latent_dim, return_sequences=True)(melody_gru1)\n",
    "melody_gru3 = GRU(latent_dim)(melody_gru2)\n",
    "\n",
    "chords_input = Input(shape=(chord_context_len, n_dimensions))\n",
    "chords_gru1 = GRU(latent_dim, return_sequences=True)(chords_input)\n",
    "chords_gru2 = GRU(latent_dim, return_sequences=True)(chords_gru1)\n",
    "chords_gru3 = GRU(latent_dim)(chords_gru2)\n",
    "\n",
    "concat = concatenate([melody_gru3, chords_gru3])\n",
    "\n",
    "chord_dense1 = Dense(latent_dim, activation='relu')(concat)\n",
    "chord_dense2 = Dense(latent_dim, activation='relu')(chord_dense1)\n",
    "chord_dense3 = Dense(n_chords, activation='softmax')(chord_dense2)\n",
    "\n",
    "model = Model([melody_input, chords_input], chord_dense3)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Introduce Best-Performance callbacks\n",
    "# es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "filepath = \"models/embeddings16-Mel3-Cho3-FC3_150ep.h5\"\n",
    "bp = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267475 samples, validate on 33434 samples\n",
      "Epoch 1/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.9035 - acc: 0.3340Epoch 00000: val_acc improved from -inf to 0.42663, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 507s - loss: 2.9030 - acc: 0.3340 - val_loss: 2.4556 - val_acc: 0.4266\n",
      "Epoch 2/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.1934 - acc: 0.4756Epoch 00001: val_acc improved from 0.42663 to 0.50724, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 509s - loss: 2.1935 - acc: 0.4756 - val_loss: 2.1523 - val_acc: 0.5072\n",
      "Epoch 3/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.9118 - acc: 0.5386Epoch 00002: val_acc improved from 0.50724 to 0.54466, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 508s - loss: 1.9119 - acc: 0.5386 - val_loss: 1.9882 - val_acc: 0.5447\n",
      "Epoch 4/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.7136 - acc: 0.5852Epoch 00003: val_acc improved from 0.54466 to 0.56757, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 507s - loss: 1.7136 - acc: 0.5852 - val_loss: 1.8788 - val_acc: 0.5676\n",
      "Epoch 5/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.5657 - acc: 0.6190Epoch 00004: val_acc improved from 0.56757 to 0.58922, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 501s - loss: 1.5657 - acc: 0.6190 - val_loss: 1.7850 - val_acc: 0.5892\n",
      "Epoch 6/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.4535 - acc: 0.6443Epoch 00005: val_acc improved from 0.58922 to 0.60112, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 502s - loss: 1.4536 - acc: 0.6443 - val_loss: 1.7274 - val_acc: 0.6011\n",
      "Epoch 7/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.3640 - acc: 0.6632Epoch 00006: val_acc improved from 0.60112 to 0.61434, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 502s - loss: 1.3641 - acc: 0.6631 - val_loss: 1.6780 - val_acc: 0.6143\n",
      "Epoch 8/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2948 - acc: 0.6785Epoch 00007: val_acc improved from 0.61434 to 0.62185, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 503s - loss: 1.2947 - acc: 0.6785 - val_loss: 1.6423 - val_acc: 0.6219\n",
      "Epoch 9/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2406 - acc: 0.6900Epoch 00008: val_acc improved from 0.62185 to 0.63486, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 504s - loss: 1.2405 - acc: 0.6900 - val_loss: 1.5980 - val_acc: 0.6349\n",
      "Epoch 10/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1979 - acc: 0.6990Epoch 00009: val_acc improved from 0.63486 to 0.64213, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 504s - loss: 1.1978 - acc: 0.6990 - val_loss: 1.5760 - val_acc: 0.6421\n",
      "Epoch 11/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1617 - acc: 0.7060Epoch 00010: val_acc improved from 0.64213 to 0.64623, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 505s - loss: 1.1617 - acc: 0.7060 - val_loss: 1.5607 - val_acc: 0.6462\n",
      "Epoch 12/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1320 - acc: 0.7121Epoch 00011: val_acc improved from 0.64623 to 0.64997, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 506s - loss: 1.1321 - acc: 0.7121 - val_loss: 1.5466 - val_acc: 0.6500\n",
      "Epoch 13/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1089 - acc: 0.7157Epoch 00012: val_acc improved from 0.64997 to 0.65188, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 505s - loss: 1.1090 - acc: 0.7157 - val_loss: 1.5376 - val_acc: 0.6519\n",
      "Epoch 14/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0880 - acc: 0.7206Epoch 00013: val_acc improved from 0.65188 to 0.66405, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 500s - loss: 1.0880 - acc: 0.7206 - val_loss: 1.5063 - val_acc: 0.6641\n",
      "Epoch 15/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0701 - acc: 0.7230Epoch 00014: val_acc improved from 0.66405 to 0.66543, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 490s - loss: 1.0702 - acc: 0.7229 - val_loss: 1.4910 - val_acc: 0.6654\n",
      "Epoch 16/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0568 - acc: 0.7259Epoch 00015: val_acc did not improve\n",
      "267475/267475 [==============================] - 492s - loss: 1.0569 - acc: 0.7259 - val_loss: 1.4869 - val_acc: 0.6648\n",
      "Epoch 17/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0437 - acc: 0.7282Epoch 00016: val_acc improved from 0.66543 to 0.66869, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 492s - loss: 1.0435 - acc: 0.7283 - val_loss: 1.4914 - val_acc: 0.6687\n",
      "Epoch 18/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0326 - acc: 0.7299Epoch 00017: val_acc did not improve\n",
      "267475/267475 [==============================] - 492s - loss: 1.0325 - acc: 0.7299 - val_loss: 1.4884 - val_acc: 0.6683\n",
      "Epoch 19/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0254 - acc: 0.7313Epoch 00018: val_acc improved from 0.66869 to 0.67545, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 493s - loss: 1.0254 - acc: 0.7313 - val_loss: 1.4624 - val_acc: 0.6755\n",
      "Epoch 20/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0138 - acc: 0.7341Epoch 00019: val_acc did not improve\n",
      "267475/267475 [==============================] - 492s - loss: 1.0138 - acc: 0.7341 - val_loss: 1.4701 - val_acc: 0.6727\n",
      "Epoch 21/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0043 - acc: 0.7359Epoch 00020: val_acc improved from 0.67545 to 0.67745, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 493s - loss: 1.0044 - acc: 0.7359 - val_loss: 1.4617 - val_acc: 0.6775\n",
      "Epoch 22/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9997 - acc: 0.7367Epoch 00021: val_acc did not improve\n",
      "267475/267475 [==============================] - 493s - loss: 0.9997 - acc: 0.7366 - val_loss: 1.4615 - val_acc: 0.6761\n",
      "Epoch 23/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9942 - acc: 0.7374Epoch 00022: val_acc did not improve\n",
      "267475/267475 [==============================] - 493s - loss: 0.9944 - acc: 0.7374 - val_loss: 1.4725 - val_acc: 0.6762\n",
      "Epoch 24/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9876 - acc: 0.7379Epoch 00023: val_acc did not improve\n",
      "267475/267475 [==============================] - 493s - loss: 0.9875 - acc: 0.7379 - val_loss: 1.4548 - val_acc: 0.6771\n",
      "Epoch 25/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9834 - acc: 0.7391Epoch 00024: val_acc improved from 0.67745 to 0.68042, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 494s - loss: 0.9832 - acc: 0.7392 - val_loss: 1.4602 - val_acc: 0.6804\n",
      "Epoch 26/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9789 - acc: 0.7400Epoch 00025: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9790 - acc: 0.7399 - val_loss: 1.4687 - val_acc: 0.6803\n",
      "Epoch 27/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9767 - acc: 0.7405Epoch 00026: val_acc improved from 0.68042 to 0.68149, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 494s - loss: 0.9768 - acc: 0.7404 - val_loss: 1.4500 - val_acc: 0.6815\n",
      "Epoch 28/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9711 - acc: 0.7412Epoch 00027: val_acc improved from 0.68149 to 0.68508, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 494s - loss: 0.9711 - acc: 0.7412 - val_loss: 1.4493 - val_acc: 0.6851\n",
      "Epoch 29/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9682 - acc: 0.7419Epoch 00028: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9682 - acc: 0.7419 - val_loss: 1.4466 - val_acc: 0.6840\n",
      "Epoch 30/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9645 - acc: 0.7421Epoch 00029: val_acc did not improve\n",
      "267475/267475 [==============================] - 491s - loss: 0.9644 - acc: 0.7422 - val_loss: 1.4497 - val_acc: 0.6838\n",
      "Epoch 31/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9618 - acc: 0.7424Epoch 00030: val_acc did not improve\n",
      "267475/267475 [==============================] - 492s - loss: 0.9617 - acc: 0.7424 - val_loss: 1.4445 - val_acc: 0.6850\n",
      "Epoch 32/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9580 - acc: 0.7443Epoch 00031: val_acc improved from 0.68508 to 0.68783, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 492s - loss: 0.9578 - acc: 0.7444 - val_loss: 1.4439 - val_acc: 0.6878\n",
      "Epoch 33/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9575 - acc: 0.7432Epoch 00032: val_acc did not improve\n",
      "267475/267475 [==============================] - 493s - loss: 0.9575 - acc: 0.7432 - val_loss: 1.4505 - val_acc: 0.6857\n",
      "Epoch 34/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9526 - acc: 0.7441Epoch 00033: val_acc improved from 0.68783 to 0.68966, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 493s - loss: 0.9525 - acc: 0.7441 - val_loss: 1.4405 - val_acc: 0.6897\n",
      "Epoch 35/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9509 - acc: 0.7451Epoch 00034: val_acc did not improve\n",
      "267475/267475 [==============================] - 493s - loss: 0.9508 - acc: 0.7451 - val_loss: 1.4494 - val_acc: 0.6875\n",
      "Epoch 36/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9496 - acc: 0.7452Epoch 00035: val_acc did not improve\n",
      "267475/267475 [==============================] - 493s - loss: 0.9496 - acc: 0.7452 - val_loss: 1.4512 - val_acc: 0.6876\n",
      "Epoch 37/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9474 - acc: 0.7449Epoch 00036: val_acc did not improve\n",
      "267475/267475 [==============================] - 493s - loss: 0.9474 - acc: 0.7449 - val_loss: 1.4464 - val_acc: 0.6878\n",
      "Epoch 38/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9474 - acc: 0.7454Epoch 00037: val_acc did not improve\n",
      "267475/267475 [==============================] - 493s - loss: 0.9475 - acc: 0.7453 - val_loss: 1.4463 - val_acc: 0.6888\n",
      "Epoch 39/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9463 - acc: 0.7449Epoch 00038: val_acc did not improve\n",
      "267475/267475 [==============================] - 493s - loss: 0.9463 - acc: 0.7449 - val_loss: 1.4364 - val_acc: 0.6895\n",
      "Epoch 40/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9444 - acc: 0.7460Epoch 00039: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9446 - acc: 0.7460 - val_loss: 1.4504 - val_acc: 0.6885\n",
      "Epoch 41/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9423 - acc: 0.7464Epoch 00040: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9424 - acc: 0.7464 - val_loss: 1.4525 - val_acc: 0.6847\n",
      "Epoch 42/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9403 - acc: 0.7462Epoch 00041: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9404 - acc: 0.7462 - val_loss: 1.4522 - val_acc: 0.6851\n",
      "Epoch 43/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9395 - acc: 0.7457Epoch 00042: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9395 - acc: 0.7457 - val_loss: 1.4517 - val_acc: 0.6870\n",
      "Epoch 44/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9371 - acc: 0.7471Epoch 00043: val_acc did not improve\n",
      "267475/267475 [==============================] - 492s - loss: 0.9371 - acc: 0.7471 - val_loss: 1.4521 - val_acc: 0.6873\n",
      "Epoch 45/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9377 - acc: 0.7470Epoch 00044: val_acc improved from 0.68966 to 0.69148, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 492s - loss: 0.9377 - acc: 0.7470 - val_loss: 1.4364 - val_acc: 0.6915\n",
      "Epoch 46/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9357 - acc: 0.7472Epoch 00045: val_acc did not improve\n",
      "267475/267475 [==============================] - 493s - loss: 0.9358 - acc: 0.7472 - val_loss: 1.4370 - val_acc: 0.6911\n",
      "Epoch 47/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9327 - acc: 0.7477Epoch 00046: val_acc did not improve\n",
      "267475/267475 [==============================] - 493s - loss: 0.9327 - acc: 0.7477 - val_loss: 1.4482 - val_acc: 0.6867\n",
      "Epoch 48/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9416 - acc: 0.7449Epoch 00047: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9415 - acc: 0.7449 - val_loss: 1.5210 - val_acc: 0.6696\n",
      "Epoch 49/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9664 - acc: 0.7395Epoch 00048: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9664 - acc: 0.7394 - val_loss: 1.4568 - val_acc: 0.6891\n",
      "Epoch 50/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9385 - acc: 0.7473Epoch 00049: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9384 - acc: 0.7473 - val_loss: 1.4445 - val_acc: 0.6896\n",
      "Epoch 51/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9387 - acc: 0.7463Epoch 00050: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.9388 - acc: 0.7462 - val_loss: 1.4631 - val_acc: 0.6898\n",
      "Epoch 52/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9363 - acc: 0.7468Epoch 00051: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9363 - acc: 0.7468 - val_loss: 1.4718 - val_acc: 0.6883\n",
      "Epoch 53/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9370 - acc: 0.7462Epoch 00052: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9370 - acc: 0.7462 - val_loss: 1.4563 - val_acc: 0.6880\n",
      "Epoch 54/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9293 - acc: 0.7482Epoch 00053: val_acc improved from 0.69148 to 0.69163, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 495s - loss: 0.9294 - acc: 0.7482 - val_loss: 1.4468 - val_acc: 0.6916\n",
      "Epoch 55/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9179 - acc: 0.7499Epoch 00054: val_acc did not improve\n",
      "267475/267475 [==============================] - 496s - loss: 0.9180 - acc: 0.7499 - val_loss: 1.4464 - val_acc: 0.6898\n",
      "Epoch 56/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9099 - acc: 0.7505Epoch 00055: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.9099 - acc: 0.7505 - val_loss: 1.4288 - val_acc: 0.6903\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8930 - acc: 0.7524Epoch 00056: val_acc improved from 0.69163 to 0.69292, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 496s - loss: 0.8930 - acc: 0.7524 - val_loss: 1.4061 - val_acc: 0.6929\n",
      "Epoch 58/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8923 - acc: 0.7523Epoch 00057: val_acc improved from 0.69292 to 0.69962, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 494s - loss: 0.8925 - acc: 0.7523 - val_loss: 1.3911 - val_acc: 0.6996\n",
      "Epoch 59/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8690 - acc: 0.7566Epoch 00058: val_acc improved from 0.69962 to 0.70219, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 494s - loss: 0.8690 - acc: 0.7567 - val_loss: 1.3808 - val_acc: 0.7022\n",
      "Epoch 60/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9223 - acc: 0.7467Epoch 00059: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9222 - acc: 0.7467 - val_loss: 1.4023 - val_acc: 0.6971\n",
      "Epoch 61/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8950 - acc: 0.7513Epoch 00060: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.8951 - acc: 0.7513 - val_loss: 1.4079 - val_acc: 0.6967\n",
      "Epoch 62/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8647 - acc: 0.7580Epoch 00061: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.8648 - acc: 0.7580 - val_loss: 1.3892 - val_acc: 0.6996\n",
      "Epoch 63/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8543 - acc: 0.7595Epoch 00062: val_acc improved from 0.70219 to 0.70276, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 495s - loss: 0.8543 - acc: 0.7596 - val_loss: 1.3725 - val_acc: 0.7028\n",
      "Epoch 64/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8445 - acc: 0.7613Epoch 00063: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8445 - acc: 0.7613 - val_loss: 1.3764 - val_acc: 0.7024\n",
      "Epoch 65/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8388 - acc: 0.7636Epoch 00064: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8388 - acc: 0.7636 - val_loss: 1.3691 - val_acc: 0.7019\n",
      "Epoch 66/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8302 - acc: 0.7656Epoch 00065: val_acc improved from 0.70276 to 0.70790, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 495s - loss: 0.8302 - acc: 0.7656 - val_loss: 1.3514 - val_acc: 0.7079\n",
      "Epoch 67/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8219 - acc: 0.7676Epoch 00066: val_acc improved from 0.70790 to 0.71263, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 496s - loss: 0.8220 - acc: 0.7676 - val_loss: 1.3469 - val_acc: 0.7126\n",
      "Epoch 68/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8108 - acc: 0.7707Epoch 00067: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8108 - acc: 0.7708 - val_loss: 1.3524 - val_acc: 0.7113\n",
      "Epoch 69/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8042 - acc: 0.7723Epoch 00068: val_acc improved from 0.71263 to 0.71469, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 496s - loss: 0.8042 - acc: 0.7723 - val_loss: 1.3361 - val_acc: 0.7147\n",
      "Epoch 70/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7934 - acc: 0.7750Epoch 00069: val_acc improved from 0.71469 to 0.71711, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 496s - loss: 0.7934 - acc: 0.7750 - val_loss: 1.3349 - val_acc: 0.7171\n",
      "Epoch 71/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7888 - acc: 0.7769Epoch 00070: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.7888 - acc: 0.7769 - val_loss: 1.3638 - val_acc: 0.7103\n",
      "Epoch 72/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7848 - acc: 0.7769Epoch 00071: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.7847 - acc: 0.7769 - val_loss: 1.3429 - val_acc: 0.7159\n",
      "Epoch 73/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7778 - acc: 0.7789Epoch 00072: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.7780 - acc: 0.7788 - val_loss: 1.3511 - val_acc: 0.7140\n",
      "Epoch 74/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9464 - acc: 0.7421Epoch 00073: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.9463 - acc: 0.7421 - val_loss: 1.4932 - val_acc: 0.6832\n",
      "Epoch 75/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8584 - acc: 0.7606Epoch 00074: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.8584 - acc: 0.7606 - val_loss: 1.3814 - val_acc: 0.7061\n",
      "Epoch 76/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8246 - acc: 0.7675Epoch 00075: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8246 - acc: 0.7675 - val_loss: 1.3857 - val_acc: 0.7053\n",
      "Epoch 77/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8208 - acc: 0.7687Epoch 00076: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8208 - acc: 0.7687 - val_loss: 1.3722 - val_acc: 0.7079\n",
      "Epoch 78/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8049 - acc: 0.7723Epoch 00077: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.8050 - acc: 0.7723 - val_loss: 1.3541 - val_acc: 0.7152\n",
      "Epoch 79/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8080 - acc: 0.7723Epoch 00078: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.8079 - acc: 0.7723 - val_loss: 1.3853 - val_acc: 0.7071\n",
      "Epoch 80/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8044 - acc: 0.7724Epoch 00079: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8043 - acc: 0.7724 - val_loss: 1.3606 - val_acc: 0.7135\n",
      "Epoch 81/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7864 - acc: 0.7770Epoch 00080: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.7866 - acc: 0.7769 - val_loss: 1.3620 - val_acc: 0.7127\n",
      "Epoch 82/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7765 - acc: 0.7795Epoch 00081: val_acc improved from 0.71711 to 0.71813, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 495s - loss: 0.7766 - acc: 0.7795 - val_loss: 1.3537 - val_acc: 0.7181\n",
      "Epoch 83/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7674 - acc: 0.7817Epoch 00082: val_acc improved from 0.71813 to 0.71816, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 495s - loss: 0.7675 - acc: 0.7817 - val_loss: 1.3472 - val_acc: 0.7182\n",
      "Epoch 84/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7609 - acc: 0.7831Epoch 00083: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.7611 - acc: 0.7831 - val_loss: 1.3578 - val_acc: 0.7173\n",
      "Epoch 85/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7871 - acc: 0.7772Epoch 00084: val_acc did not improve\n",
      "267475/267475 [==============================] - 496s - loss: 0.7873 - acc: 0.7771 - val_loss: 1.4462 - val_acc: 0.6957\n",
      "Epoch 86/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8694 - acc: 0.7578Epoch 00085: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8696 - acc: 0.7578 - val_loss: 1.3992 - val_acc: 0.7061\n",
      "Epoch 87/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8379 - acc: 0.7657Epoch 00086: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.8379 - acc: 0.7657 - val_loss: 1.4105 - val_acc: 0.7021\n",
      "Epoch 88/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8323 - acc: 0.7667Epoch 00087: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.8322 - acc: 0.7667 - val_loss: 1.3864 - val_acc: 0.7105\n",
      "Epoch 89/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8192 - acc: 0.7695Epoch 00088: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.8193 - acc: 0.7695 - val_loss: 1.3800 - val_acc: 0.7081\n",
      "Epoch 90/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8204 - acc: 0.7698Epoch 00089: val_acc did not improve\n",
      "267475/267475 [==============================] - 494s - loss: 0.8204 - acc: 0.7698 - val_loss: 1.3978 - val_acc: 0.7056\n",
      "Epoch 91/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8174 - acc: 0.7700Epoch 00090: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8175 - acc: 0.7700 - val_loss: 1.3768 - val_acc: 0.7144\n",
      "Epoch 92/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8212 - acc: 0.7695Epoch 00091: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8213 - acc: 0.7695 - val_loss: 1.4131 - val_acc: 0.7026\n",
      "Epoch 93/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8262 - acc: 0.7682Epoch 00092: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8262 - acc: 0.7682 - val_loss: 1.3837 - val_acc: 0.7086\n",
      "Epoch 94/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8409 - acc: 0.7655Epoch 00093: val_acc did not improve\n",
      "267475/267475 [==============================] - 496s - loss: 0.8410 - acc: 0.7654 - val_loss: 1.4462 - val_acc: 0.6921\n",
      "Epoch 95/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8772 - acc: 0.7567Epoch 00094: val_acc did not improve\n",
      "267475/267475 [==============================] - 496s - loss: 0.8772 - acc: 0.7566 - val_loss: 1.4329 - val_acc: 0.6974\n",
      "Epoch 96/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8596 - acc: 0.7611Epoch 00095: val_acc did not improve\n",
      "267475/267475 [==============================] - 496s - loss: 0.8596 - acc: 0.7611 - val_loss: 1.4024 - val_acc: 0.7008\n",
      "Epoch 97/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8529 - acc: 0.7620Epoch 00096: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.8530 - acc: 0.7619 - val_loss: 1.4045 - val_acc: 0.7021\n",
      "Epoch 98/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8402 - acc: 0.7646Epoch 00097: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.8402 - acc: 0.7646 - val_loss: 1.4077 - val_acc: 0.7040\n",
      "Epoch 99/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8308 - acc: 0.7676Epoch 00098: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.8307 - acc: 0.7676 - val_loss: 1.4069 - val_acc: 0.7050\n",
      "Epoch 100/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8253 - acc: 0.7680Epoch 00099: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.8254 - acc: 0.7680 - val_loss: 1.4117 - val_acc: 0.7001\n",
      "Epoch 101/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8371 - acc: 0.7644Epoch 00100: val_acc did not improve\n",
      "267475/267475 [==============================] - 496s - loss: 0.8371 - acc: 0.7644 - val_loss: 1.4086 - val_acc: 0.7016\n",
      "Epoch 102/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8290 - acc: 0.7668Epoch 00101: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8290 - acc: 0.7669 - val_loss: 1.4052 - val_acc: 0.7051\n",
      "Epoch 103/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8303 - acc: 0.7673Epoch 00102: val_acc did not improve\n",
      "267475/267475 [==============================] - 495s - loss: 0.8303 - acc: 0.7673 - val_loss: 1.3919 - val_acc: 0.7044\n",
      "Epoch 104/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8278 - acc: 0.7673Epoch 00103: val_acc did not improve\n",
      "267475/267475 [==============================] - 496s - loss: 0.8279 - acc: 0.7673 - val_loss: 1.4160 - val_acc: 0.7013\n",
      "Epoch 105/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8116 - acc: 0.7713Epoch 00104: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.8116 - acc: 0.7713 - val_loss: 1.4051 - val_acc: 0.7025\n",
      "Epoch 106/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8180 - acc: 0.7695Epoch 00105: val_acc did not improve\n",
      "267475/267475 [==============================] - 496s - loss: 0.8181 - acc: 0.7695 - val_loss: 1.4017 - val_acc: 0.7051\n",
      "Epoch 107/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8077 - acc: 0.7724Epoch 00106: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.8076 - acc: 0.7724 - val_loss: 1.3866 - val_acc: 0.7104\n",
      "Epoch 108/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7821 - acc: 0.7786Epoch 00107: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.7821 - acc: 0.7786 - val_loss: 1.3661 - val_acc: 0.7124\n",
      "Epoch 109/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7682 - acc: 0.7822Epoch 00108: val_acc improved from 0.71816 to 0.71879, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 498s - loss: 0.7682 - acc: 0.7822 - val_loss: 1.3497 - val_acc: 0.7188\n",
      "Epoch 110/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7634 - acc: 0.7831Epoch 00109: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.7635 - acc: 0.7830 - val_loss: 1.3658 - val_acc: 0.7180\n",
      "Epoch 111/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7591 - acc: 0.7844Epoch 00110: val_acc improved from 0.71879 to 0.71912, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 497s - loss: 0.7591 - acc: 0.7843 - val_loss: 1.3534 - val_acc: 0.7191\n",
      "Epoch 112/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7593 - acc: 0.7840Epoch 00111: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.7593 - acc: 0.7840 - val_loss: 1.4389 - val_acc: 0.6985\n",
      "Epoch 113/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8103 - acc: 0.7709Epoch 00112: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.8104 - acc: 0.7708 - val_loss: 1.4036 - val_acc: 0.7063\n",
      "Epoch 114/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7962 - acc: 0.7750Epoch 00113: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.7963 - acc: 0.7749 - val_loss: 1.4012 - val_acc: 0.7102\n",
      "Epoch 115/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7793 - acc: 0.7789Epoch 00114: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.7793 - acc: 0.7789 - val_loss: 1.3739 - val_acc: 0.7143\n",
      "Epoch 116/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7678 - acc: 0.7821Epoch 00115: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.7678 - acc: 0.7821 - val_loss: 1.3691 - val_acc: 0.7168\n",
      "Epoch 117/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7564 - acc: 0.7850Epoch 00116: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 497s - loss: 0.7565 - acc: 0.7850 - val_loss: 1.3769 - val_acc: 0.7175\n",
      "Epoch 118/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7511 - acc: 0.7858Epoch 00117: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.7512 - acc: 0.7858 - val_loss: 1.3692 - val_acc: 0.7175\n",
      "Epoch 119/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7530 - acc: 0.7856Epoch 00118: val_acc improved from 0.71912 to 0.72334, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 497s - loss: 0.7530 - acc: 0.7856 - val_loss: 1.3551 - val_acc: 0.7233\n",
      "Epoch 120/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7418 - acc: 0.7886Epoch 00119: val_acc improved from 0.72334 to 0.72648, saving model to models/embeddings16-Mel3-Cho3-FC3_150ep.h5\n",
      "267475/267475 [==============================] - 498s - loss: 0.7419 - acc: 0.7886 - val_loss: 1.3451 - val_acc: 0.7265\n",
      "Epoch 121/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7312 - acc: 0.7913Epoch 00120: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.7313 - acc: 0.7913 - val_loss: 1.3536 - val_acc: 0.7214\n",
      "Epoch 122/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7927 - acc: 0.7767Epoch 00121: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.7929 - acc: 0.7767 - val_loss: 1.5493 - val_acc: 0.6792\n",
      "Epoch 123/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8944 - acc: 0.7536Epoch 00122: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.8945 - acc: 0.7536 - val_loss: 1.4620 - val_acc: 0.6974\n",
      "Epoch 124/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8459 - acc: 0.7651Epoch 00123: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.8459 - acc: 0.7652 - val_loss: 1.4338 - val_acc: 0.7008\n",
      "Epoch 125/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8331 - acc: 0.7677Epoch 00124: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.8331 - acc: 0.7677 - val_loss: 1.4308 - val_acc: 0.7040\n",
      "Epoch 126/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8298 - acc: 0.7681Epoch 00125: val_acc did not improve\n",
      "267475/267475 [==============================] - 500s - loss: 0.8298 - acc: 0.7681 - val_loss: 1.4317 - val_acc: 0.7023\n",
      "Epoch 127/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8165 - acc: 0.7700Epoch 00126: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.8165 - acc: 0.7700 - val_loss: 1.4161 - val_acc: 0.7022\n",
      "Epoch 128/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8221 - acc: 0.7682Epoch 00127: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.8220 - acc: 0.7682 - val_loss: 1.3974 - val_acc: 0.7057\n",
      "Epoch 129/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8060 - acc: 0.7713Epoch 00128: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.8060 - acc: 0.7713 - val_loss: 1.4577 - val_acc: 0.6964\n",
      "Epoch 130/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8289 - acc: 0.7676Epoch 00129: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.8289 - acc: 0.7676 - val_loss: 1.4234 - val_acc: 0.7035\n",
      "Epoch 131/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8146 - acc: 0.7702Epoch 00130: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.8144 - acc: 0.7702 - val_loss: 1.3827 - val_acc: 0.7133\n",
      "Epoch 132/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8011 - acc: 0.7731Epoch 00131: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.8011 - acc: 0.7731 - val_loss: 1.4083 - val_acc: 0.7073\n",
      "Epoch 133/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8040 - acc: 0.7724Epoch 00132: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.8038 - acc: 0.7724 - val_loss: 1.4088 - val_acc: 0.7057\n",
      "Epoch 134/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7976 - acc: 0.7743Epoch 00133: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.7976 - acc: 0.7743 - val_loss: 1.3989 - val_acc: 0.7114\n",
      "Epoch 135/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7917 - acc: 0.7762Epoch 00134: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.7917 - acc: 0.7762 - val_loss: 1.3861 - val_acc: 0.7128\n",
      "Epoch 136/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7913 - acc: 0.7759Epoch 00135: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.7913 - acc: 0.7759 - val_loss: 1.4117 - val_acc: 0.7095\n",
      "Epoch 137/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7767 - acc: 0.7795Epoch 00136: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.7768 - acc: 0.7795 - val_loss: 1.3811 - val_acc: 0.7167\n",
      "Epoch 138/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7818 - acc: 0.7786Epoch 00137: val_acc did not improve\n",
      "267475/267475 [==============================] - 500s - loss: 0.7819 - acc: 0.7786 - val_loss: 1.3911 - val_acc: 0.7084\n",
      "Epoch 139/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7891 - acc: 0.7767Epoch 00138: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.7892 - acc: 0.7767 - val_loss: 1.3897 - val_acc: 0.7090\n",
      "Epoch 140/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7878 - acc: 0.7773Epoch 00139: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.7877 - acc: 0.7773 - val_loss: 1.4024 - val_acc: 0.7109\n",
      "Epoch 141/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7793 - acc: 0.7788Epoch 00140: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.7793 - acc: 0.7788 - val_loss: 1.3852 - val_acc: 0.7107\n",
      "Epoch 142/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7850 - acc: 0.7778Epoch 00141: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.7850 - acc: 0.7778 - val_loss: 1.4119 - val_acc: 0.7044\n",
      "Epoch 143/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8021 - acc: 0.7742Epoch 00142: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.8022 - acc: 0.7741 - val_loss: 1.3875 - val_acc: 0.7162\n",
      "Epoch 144/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7799 - acc: 0.7793Epoch 00143: val_acc did not improve\n",
      "267475/267475 [==============================] - 497s - loss: 0.7800 - acc: 0.7793 - val_loss: 1.4025 - val_acc: 0.7136\n",
      "Epoch 145/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8123 - acc: 0.7723Epoch 00144: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.8123 - acc: 0.7723 - val_loss: 1.4773 - val_acc: 0.6939\n",
      "Epoch 146/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8491 - acc: 0.7622Epoch 00145: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.8491 - acc: 0.7622 - val_loss: 1.4047 - val_acc: 0.7071\n",
      "Epoch 147/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7959 - acc: 0.7757Epoch 00146: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.7958 - acc: 0.7757 - val_loss: 1.3903 - val_acc: 0.7173\n",
      "Epoch 148/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7804 - acc: 0.7789Epoch 00147: val_acc did not improve\n",
      "267475/267475 [==============================] - 499s - loss: 0.7804 - acc: 0.7789 - val_loss: 1.3990 - val_acc: 0.7116\n",
      "Epoch 149/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7730 - acc: 0.7806Epoch 00148: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.7731 - acc: 0.7806 - val_loss: 1.3910 - val_acc: 0.7127\n",
      "Epoch 150/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7718 - acc: 0.7805Epoch 00149: val_acc did not improve\n",
      "267475/267475 [==============================] - 498s - loss: 0.7717 - acc: 0.7805 - val_loss: 1.3709 - val_acc: 0.7165\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 256\n",
    "epochs = 150\n",
    "\n",
    "history = model.fit([X_melody_train, X_chords_train], Y_chord_train, epochs=epochs, validation_data=([X_melody_valid, X_chords_valid], Y_chord_valid), batch_size=batch_size, callbacks=[bp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73048354a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFkCAYAAADWs8tQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEREREZGwpwKGiIiIiIiIiIS9/w/JY4+F+9mqegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7304835c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize model learning\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Training history of root model\", fontsize=16)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load best performance model\n",
    "best_model = load_model(\"models/embeddings16-Mel3-Cho3-FC3_150ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33435, 135, 14)\n",
      "(33435, 7, 16)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody_test.shape)\n",
    "print(X_chords_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord prediction: 0.7146\n",
      "Kappa score of combined chord prediction: 0.7074\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of labels\n",
    "\n",
    "# Predict chords from each test sample melody\n",
    "Y_chord_pred = model.predict([X_melody_test, X_chords_test])\n",
    "\n",
    "# Compute accuracy and kappa score \n",
    "print(\"Categorical accuracy of combined chord prediction: {0:.4f}\".format(harmoutil.compute_accuracy_score(Y_chord_test, Y_chord_pred)))\n",
    "print(\"Kappa score of combined chord prediction: {0:.4f}\".format(harmoutil.compute_kappa_score(Y_chord_test, Y_chord_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord pitch prediction: 0.8977\n",
      "TP: 110203 TN: 249992 FP: 20775 FN: 20250\n",
      "Kappa score of combined chord pitch prediction: 0.7672\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of pitches\n",
    "\n",
    "def label_to_pitch_tensors(predictions):\n",
    "    predicted_chords = [int_to_chord[np.argmax(ch)] for ch in predictions]\n",
    "    pitch_chords = [harmoutil.chord_to_notes(label) for label in predicted_chords]\n",
    "    \n",
    "    Y_pitches = np.zeros((predictions.shape[0], 12), dtype='float32')\n",
    "    for i, chord_pitches in enumerate(pitch_chords):\n",
    "        for j, pitch_presence in enumerate(chord_pitches):\n",
    "            Y_pitches[i, j] = pitch_presence\n",
    "\n",
    "    return Y_pitches\n",
    "\n",
    "Y_pitch_pred = label_to_pitch_tensors(Y_chord_pred)\n",
    "Y_pitch_test = label_to_pitch_tensors(Y_chord_test)\n",
    "\n",
    "print(\"Categorical accuracy of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_accuracy_score(Y_pitch_test, Y_pitch_pred)))\n",
    "print(\"Kappa score of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_kappa_score(Y_pitch_test, Y_pitch_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
