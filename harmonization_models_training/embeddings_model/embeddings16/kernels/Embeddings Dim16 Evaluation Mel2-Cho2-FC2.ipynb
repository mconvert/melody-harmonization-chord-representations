{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, GRU, concatenate\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# Custom library for the project\n",
    "import sys\n",
    "sys.path.insert(0, '../../src')\n",
    "import harmoutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'harmoutil' from '../../src/harmoutil.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Remove when done with kernel\n",
    "import importlib\n",
    "importlib.reload(harmoutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = harmoutil.load_pickled_data(\"../../data/refined_data.pkl\") # lists of (chord label, melody seqs) by sections\n",
    "augmented_data = harmoutil.transpose_and_augment_data(raw_data)\n",
    "data = [harmoutil.to_sevenths(section) for section in augmented_data]\n",
    "data = [harmoutil.melody_to_octave_range(section) for section in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chords: 334344 | Sample chord: E6\n",
      "Number of melody notes in the data: 2209944 | Sample melody note: 4\n",
      "Unique notes: [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Unique notes: ['A', 'A+', 'A+7', 'A+j7', 'A-', 'A-6', 'A-7', 'A-j7', 'A6', 'A7', 'Ab', 'Ab+', 'Ab+7', 'Ab+j7', 'Ab-', 'Ab-6', 'Ab-7', 'Ab-j7', 'Ab6', 'Ab7', 'Abj7', 'Abm7b5', 'Abo', 'Abo7', 'Absus', 'Absus7', 'Aj7', 'Am7b5', 'Ao', 'Ao7', 'Asus', 'Asus7', 'B', 'B+', 'B+7', 'B+j7', 'B-', 'B-6', 'B-7', 'B-j7', 'B6', 'B7', 'Bb', 'Bb+', 'Bb+7', 'Bb+j7', 'Bb-', 'Bb-6', 'Bb-7', 'Bb-j7', 'Bb6', 'Bb7', 'Bbj7', 'Bbm7b5', 'Bbo', 'Bbo7', 'Bbsus', 'Bbsus7', 'Bj7', 'Bm7b5', 'Bo', 'Bo7', 'Bsus', 'Bsus7', 'C', 'C+', 'C+7', 'C+j7', 'C-', 'C-6', 'C-7', 'C-j7', 'C6', 'C7', 'Cj7', 'Cm7b5', 'Co', 'Co7', 'Csus', 'Csus7', 'D', 'D+', 'D+7', 'D+j7', 'D-', 'D-6', 'D-7', 'D-j7', 'D6', 'D7', 'Db', 'Db+', 'Db+7', 'Db+j7', 'Db-', 'Db-6', 'Db-7', 'Db-j7', 'Db6', 'Db7', 'Dbj7', 'Dbm7b5', 'Dbo', 'Dbo7', 'Dbsus', 'Dbsus7', 'Dj7', 'Dm7b5', 'Do', 'Do7', 'Dsus', 'Dsus7', 'E', 'E+', 'E+7', 'E+j7', 'E-', 'E-6', 'E-7', 'E-j7', 'E6', 'E7', 'Eb', 'Eb+', 'Eb+7', 'Eb+j7', 'Eb-', 'Eb-6', 'Eb-7', 'Eb-j7', 'Eb6', 'Eb7', 'Ebj7', 'Ebm7b5', 'Ebo', 'Ebo7', 'Ebsus', 'Ebsus7', 'Ej7', 'Em7b5', 'Eo', 'Eo7', 'Esus', 'Esus7', 'F', 'F+', 'F+7', 'F+j7', 'F-', 'F-6', 'F-7', 'F-j7', 'F6', 'F7', 'Fj7', 'Fm7b5', 'Fo', 'Fo7', 'Fsus', 'Fsus7', 'G', 'G+', 'G+7', 'G+j7', 'G-', 'G-6', 'G-7', 'G-j7', 'G6', 'G7', 'Gb', 'Gb+', 'Gb+7', 'Gb+j7', 'Gb-', 'Gb-6', 'Gb-7', 'Gb-j7', 'Gb6', 'Gb7', 'Gbj7', 'Gbm7b5', 'Gbo', 'Gbo7', 'Gbsus', 'Gbsus7', 'Gj7', 'Gm7b5', 'Go', 'Go7', 'Gsus', 'Gsus7', 'NC']\n"
     ]
    }
   ],
   "source": [
    "# Isolate relevant data\n",
    "def get_notes_by_chord(beats):\n",
    "    return [note for beat in beats for note in beat]\n",
    "\n",
    "def get_chords_by_section(section):\n",
    "    return [chord_info[0] for chord_info in section]\n",
    "\n",
    "# def check_if_augmented_major(section):\n",
    "#     section_chords = get_chords_by_section(section)\n",
    "#     for ch in section_chords:\n",
    "#         if \"+j7\" in ch:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "# data = [section for section in data if not check_if_augmented_major(section)]\n",
    "# print(\"---Remove sections with augmented major chord---\")\n",
    "# print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections_bf_augmaj7 = [get_chords_by_section(section) for section in data]\n",
    "chords = [chord_info[0] for section in data for chord_info in section]\n",
    "unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords_bf_augmaj7 = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "notes = [note for chord_notes in notes_by_chords_bf_augmaj7 for note in chord_notes]\n",
    "unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "# print(sum([len(section) for section in chords_by_sections]))\n",
    "# print(\"Number of sections: {} | Sample section chords: {}\".format(len(chords_by_sections), chords_by_sections[0]))\n",
    "print(\"Number of chords: {} | Sample chord: {}\".format(len(chords), chords[0]))\n",
    "# print(\"Number of melodies {} | Sample melody: {}\".format(len(notes_by_chords), notes_by_chords[0]))\n",
    "print(\"Number of melody notes in the data: {} | Sample melody note: {}\".format(len(notes), notes[0]))\n",
    "print(\"Unique notes: {}\".format(unique_notes))\n",
    "print(\"Unique notes: {}\".format(unique_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melody note to integer mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, '<pad>': 13, -1: 12}\n",
      "\n",
      "Integer to melody note mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: -1, 13: '<pad>'}\n",
      "\n",
      "Chord label to integer mapping:\n",
      " {'Bj7': 58, 'A+j7': 3, 'Bb+7': 44, 'C-7': 70, 'Ebm7b5': 133, 'D-6': 85, 'Abo': 22, 'Gbj7': 180, 'C-j7': 71, 'Eb-j7': 129, 'Bbj7': 52, 'D-': 84, 'Eb6': 130, 'B-j7': 39, 'Gbsus7': 185, 'Eo7': 141, 'Fm7b5': 155, 'A-j7': 7, 'Bb-j7': 49, 'Do': 108, 'Ebj7': 132, 'Db+': 91, 'Gb6': 178, 'Bbsus7': 57, 'F': 144, 'B': 32, 'Gb-6': 175, 'Gb-7': 176, 'Dm7b5': 107, 'Gbsus': 184, 'F+j7': 147, 'NC': 192, 'C6': 72, 'Db': 90, 'Ab-': 14, 'A+7': 2, 'E7': 121, 'Cj7': 74, 'F-j7': 151, 'C': 64, 'Gb+7': 172, 'D6': 88, 'G': 160, 'C-6': 69, 'Bm7b5': 59, 'A-7': 6, 'E-7': 118, 'A7': 9, 'Dbj7': 100, 'Abo7': 23, 'Bb-': 46, 'D+7': 82, 'Asus': 30, 'Ebsus': 136, 'A-': 4, 'Db-7': 96, 'Db-': 94, 'Ab-7': 16, 'B-': 36, 'F-': 148, 'Eo': 140, 'Bb+j7': 45, 'F6': 152, 'Dsus': 110, 'Cm7b5': 75, 'Db+j7': 93, 'A6': 8, 'Db-6': 95, 'Absus7': 25, 'Ab+7': 12, 'Db6': 98, 'Bsus': 62, '<bos>': 193, 'B-6': 37, 'G6': 168, 'Gm7b5': 187, 'Esus7': 143, 'Gb7': 179, 'G-7': 166, 'F-6': 149, 'Bb+': 43, 'Dbm7b5': 101, 'Bb-6': 47, 'D': 80, 'A+': 1, 'D7': 89, 'Ab+': 11, 'C+7': 66, 'Bb6': 50, 'C+': 65, 'Co7': 77, 'Gb+': 171, 'Ao': 28, 'A': 0, 'D+j7': 83, 'Em7b5': 139, 'Bo7': 61, 'G7': 169, 'Eb-': 126, 'Eb': 122, 'Go': 188, 'F7': 153, 'D+': 81, 'C-': 68, 'E+7': 114, 'Ab': 10, 'G+j7': 163, 'B7': 41, 'Eb+j7': 125, 'Ao7': 29, 'B-7': 38, 'Ebsus7': 137, 'Abm7b5': 21, 'C+j7': 67, 'B+7': 34, 'Ebo7': 135, 'F+': 145, 'Bbsus': 56, 'E-6': 117, 'Dsus7': 111, 'E-': 116, 'G-6': 165, 'Gbo': 182, 'Gb-j7': 177, 'Abj7': 20, 'Ab+j7': 13, 'Gsus7': 191, 'Bsus7': 63, 'Eb-7': 128, 'B+': 33, 'G+7': 162, 'D-7': 86, 'Aj7': 26, 'Ab7': 19, 'Db+7': 92, 'B+j7': 35, 'E+j7': 115, 'Dj7': 106, 'Bo': 60, 'Fsus7': 159, 'Dbo7': 103, '<eos>': 194, 'Bb': 42, 'Csus7': 79, 'Fo7': 157, 'E+': 113, 'Gj7': 186, 'Go7': 189, 'Ab-j7': 17, 'Bbo': 54, 'Eb-6': 127, 'C7': 73, 'Gb-': 174, 'Gb': 170, 'Asus7': 31, 'E6': 120, 'E-j7': 119, 'Bbm7b5': 53, 'Gb+j7': 173, 'E': 112, 'G-': 164, 'Dbo': 102, 'F-7': 150, 'Ebo': 134, 'Bb-7': 48, 'Ej7': 138, 'Eb+7': 124, 'Db7': 99, 'A-6': 5, 'Bb7': 51, 'Dbsus': 104, 'G+': 161, 'Fo': 156, 'Fsus': 158, 'Ab-6': 15, 'Gsus': 190, 'Ab6': 18, 'Gbo7': 183, 'Esus': 142, 'B6': 40, 'Dbsus7': 105, 'Db-j7': 97, 'Bbo7': 55, 'Eb+': 123, 'Am7b5': 27, 'Absus': 24, 'G-j7': 167, 'Fj7': 154, 'Do7': 109, 'Csus': 78, 'Gbm7b5': 181, 'Eb7': 131, 'D-j7': 87, 'Co': 76, 'F+7': 146}\n",
      "\n",
      "Integer to chord label mapping:\n",
      " {0: 'A', 1: 'A+', 2: 'A+7', 3: 'A+j7', 4: 'A-', 5: 'A-6', 6: 'A-7', 7: 'A-j7', 8: 'A6', 9: 'A7', 10: 'Ab', 11: 'Ab+', 12: 'Ab+7', 13: 'Ab+j7', 14: 'Ab-', 15: 'Ab-6', 16: 'Ab-7', 17: 'Ab-j7', 18: 'Ab6', 19: 'Ab7', 20: 'Abj7', 21: 'Abm7b5', 22: 'Abo', 23: 'Abo7', 24: 'Absus', 25: 'Absus7', 26: 'Aj7', 27: 'Am7b5', 28: 'Ao', 29: 'Ao7', 30: 'Asus', 31: 'Asus7', 32: 'B', 33: 'B+', 34: 'B+7', 35: 'B+j7', 36: 'B-', 37: 'B-6', 38: 'B-7', 39: 'B-j7', 40: 'B6', 41: 'B7', 42: 'Bb', 43: 'Bb+', 44: 'Bb+7', 45: 'Bb+j7', 46: 'Bb-', 47: 'Bb-6', 48: 'Bb-7', 49: 'Bb-j7', 50: 'Bb6', 51: 'Bb7', 52: 'Bbj7', 53: 'Bbm7b5', 54: 'Bbo', 55: 'Bbo7', 56: 'Bbsus', 57: 'Bbsus7', 58: 'Bj7', 59: 'Bm7b5', 60: 'Bo', 61: 'Bo7', 62: 'Bsus', 63: 'Bsus7', 64: 'C', 65: 'C+', 66: 'C+7', 67: 'C+j7', 68: 'C-', 69: 'C-6', 70: 'C-7', 71: 'C-j7', 72: 'C6', 73: 'C7', 74: 'Cj7', 75: 'Cm7b5', 76: 'Co', 77: 'Co7', 78: 'Csus', 79: 'Csus7', 80: 'D', 81: 'D+', 82: 'D+7', 83: 'D+j7', 84: 'D-', 85: 'D-6', 86: 'D-7', 87: 'D-j7', 88: 'D6', 89: 'D7', 90: 'Db', 91: 'Db+', 92: 'Db+7', 93: 'Db+j7', 94: 'Db-', 95: 'Db-6', 96: 'Db-7', 97: 'Db-j7', 98: 'Db6', 99: 'Db7', 100: 'Dbj7', 101: 'Dbm7b5', 102: 'Dbo', 103: 'Dbo7', 104: 'Dbsus', 105: 'Dbsus7', 106: 'Dj7', 107: 'Dm7b5', 108: 'Do', 109: 'Do7', 110: 'Dsus', 111: 'Dsus7', 112: 'E', 113: 'E+', 114: 'E+7', 115: 'E+j7', 116: 'E-', 117: 'E-6', 118: 'E-7', 119: 'E-j7', 120: 'E6', 121: 'E7', 122: 'Eb', 123: 'Eb+', 124: 'Eb+7', 125: 'Eb+j7', 126: 'Eb-', 127: 'Eb-6', 128: 'Eb-7', 129: 'Eb-j7', 130: 'Eb6', 131: 'Eb7', 132: 'Ebj7', 133: 'Ebm7b5', 134: 'Ebo', 135: 'Ebo7', 136: 'Ebsus', 137: 'Ebsus7', 138: 'Ej7', 139: 'Em7b5', 140: 'Eo', 141: 'Eo7', 142: 'Esus', 143: 'Esus7', 144: 'F', 145: 'F+', 146: 'F+7', 147: 'F+j7', 148: 'F-', 149: 'F-6', 150: 'F-7', 151: 'F-j7', 152: 'F6', 153: 'F7', 154: 'Fj7', 155: 'Fm7b5', 156: 'Fo', 157: 'Fo7', 158: 'Fsus', 159: 'Fsus7', 160: 'G', 161: 'G+', 162: 'G+7', 163: 'G+j7', 164: 'G-', 165: 'G-6', 166: 'G-7', 167: 'G-j7', 168: 'G6', 169: 'G7', 170: 'Gb', 171: 'Gb+', 172: 'Gb+7', 173: 'Gb+j7', 174: 'Gb-', 175: 'Gb-6', 176: 'Gb-7', 177: 'Gb-j7', 178: 'Gb6', 179: 'Gb7', 180: 'Gbj7', 181: 'Gbm7b5', 182: 'Gbo', 183: 'Gbo7', 184: 'Gbsus', 185: 'Gbsus7', 186: 'Gj7', 187: 'Gm7b5', 188: 'Go', 189: 'Go7', 190: 'Gsus', 191: 'Gsus7', 192: 'NC', 193: '<bos>', 194: '<eos>'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create categorical data mappings\n",
    "note_to_int = dict([(c, i) for i, c in enumerate(unique_notes[1:])])\n",
    "note_to_int[-1] = len(note_to_int)\n",
    "note_to_int['<pad>'] = len(note_to_int)\n",
    "\n",
    "int_to_note = dict([(k, v) for v, k in note_to_int.items()])\n",
    "\n",
    "chord_to_int = dict([(c, i) for i, c in enumerate(unique_chords)])\n",
    "chord_to_int['<bos>'] = len(chord_to_int)\n",
    "chord_to_int['<eos>'] = len(chord_to_int)\n",
    "\n",
    "int_to_chord = dict([(k, v) for v, k in chord_to_int.items()])\n",
    "\n",
    "print(\"Melody note to integer mapping:\\n {}\\n\".format(note_to_int))\n",
    "print(\"Integer to melody note mapping:\\n {}\\n\".format(int_to_note))\n",
    "print(\"Chord label to integer mapping:\\n {}\\n\".format(chord_to_int))\n",
    "print(\"Integer to chord label mapping:\\n {}\\n\".format(int_to_chord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 334344\n",
      "Number of distinct melody notes: 14\n",
      "Number of distinct chord labels: 195\n",
      "Maximum length of melody sequences for one chord: 135\n",
      "Number of past chords given as input: 7\n"
     ]
    }
   ],
   "source": [
    "# Define numerical variables\n",
    "\n",
    "n_samples = len(chords)\n",
    "n_chords = len(chord_to_int)\n",
    "n_notes = len(note_to_int)\n",
    "max_mel_len = max([len(mel) for mel in notes_by_chords_bf_augmaj7])\n",
    "chord_context_len = 7\n",
    "\n",
    "# print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Number of distinct melody notes: {}\".format(n_notes))\n",
    "print(\"Number of distinct chord labels: {}\".format(n_chords))\n",
    "print(\"Maximum length of melody sequences for one chord: {}\".format(max_mel_len))\n",
    "print(\"Number of past chords given as input: {}\".format(chord_context_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [4]]\n"
     ]
    }
   ],
   "source": [
    "mel_by_sections = [mel for section in data for ch, mel in section]\n",
    "print(mel_by_sections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Remove sections with augmented major chord---\n",
      "Number of sections: 28836\n",
      "\n",
      "Sample input melody sequence: [8, 3, 6, '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "\n",
      "Sample input chord sequence: ['<bos>', '<bos>', 'E6', 'Db7', 'Gb-7', 'B7', 'E']\n",
      "\n",
      "Sample target chord: Db-7\n",
      "\n",
      "Input melody: 333480, Input chords: 333480, Target chords: 333480\n"
     ]
    }
   ],
   "source": [
    "# Prepare tensor data\n",
    "\n",
    "\n",
    "def check_if_augmented_major(section):\n",
    "    section_chords = get_chords_by_section(section)\n",
    "    for ch in section_chords:\n",
    "        if \"+j7\" in ch:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "data = [section for section in data if not check_if_augmented_major(section)]\n",
    "print(\"---Remove sections with augmented major chord---\")\n",
    "print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections = [get_chords_by_section(section) for section in data]\n",
    "# chords = [chord_info[0] for section in data for chord_info in section]\n",
    "# unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "# notes = [note for chord_notes in notes_by_chords for note in chord_notes]\n",
    "# unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "\n",
    "\n",
    "def pad_melody(melody, max_len):\n",
    "    return melody + (max_len-len(melody))*['<pad>']\n",
    "\n",
    "def build_input_chord_sequences(chord_seq, context_len):\n",
    "    padded_sequence = context_len*['<bos>'] + chord_seq\n",
    "    formatted_sequences = [padded_sequence[i:i+context_len+1] for i in range(len(chord_seq))]\n",
    "    return formatted_sequences\n",
    "\n",
    "# Melody\n",
    "input_melody_data = [pad_melody(melody, max_mel_len) for melody in notes_by_chords]\n",
    "print(\"Sample input melody sequence: {}\\n\".format(input_melody_data[5]))\n",
    "\n",
    "# Chords\n",
    "formatted_chords_data = []\n",
    "for section_chords in chords_by_sections:\n",
    "    formatted_chords_data += build_input_chord_sequences(section_chords, chord_context_len)\n",
    "    \n",
    "input_chords_data = [ch[:-1] for ch in formatted_chords_data]\n",
    "target_chords_data = [ch[-1] for ch in formatted_chords_data]\n",
    "print(\"Sample input chord sequence: {}\\n\".format(input_chords_data[5]))\n",
    "print(\"Sample target chord: {}\\n\".format(target_chords_data[5]))\n",
    "\n",
    "print(\"Input melody: {}, Input chords: {}, Target chords: {}\".format(len(input_melody_data), len(input_chords_data), len(target_chords_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 16)\n"
     ]
    }
   ],
   "source": [
    "# Load embedding vectors\n",
    "\n",
    "num_dim = 16\n",
    "num_ch = 192\n",
    "num_notes = 12\n",
    "\n",
    "# Define embedding training model and load weights\n",
    "input_layer = Input(shape=(num_ch,)) \n",
    "embeddings_layer = Dense(num_dim, activation='linear', name=\"embeddings\")(input_layer)\n",
    "root_output_layer = Dense(num_notes, activation='softmax')(embeddings_layer)\n",
    "interval_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "pitch_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "melody_output_layer = Dense(num_notes, activation='relu')(embeddings_layer)\n",
    "embeddings_model = Model(input_layer, [root_output_layer, interval_output_layer, pitch_output_layer, melody_output_layer])\n",
    "\n",
    "embeddings_model.load_weights(\"../Skipgram & WJD/weights/combined_weights_dim16.h5\")\n",
    "\n",
    "X_chords_embeddings = embeddings_model.layers[1].get_weights()[0]\n",
    "print(X_chords_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embedding vector for each chord: 16\n"
     ]
    }
   ],
   "source": [
    "# Build tensors\n",
    "\n",
    "n_dimensions = X_chords_embeddings.shape[1]\n",
    "print(\"Size of embedding vector for each chord: {}\".format(n_dimensions))\n",
    "\n",
    "X_melody = np.zeros((n_samples, max_mel_len, n_notes), dtype='float32')\n",
    "X_chords = np.zeros((n_samples, chord_context_len, n_dimensions), dtype='float32')\n",
    "Y_chord = np.zeros((n_samples, n_chords), dtype='float32')\n",
    "\n",
    "for i, (input_mel, input_ch, target_ch) in enumerate(zip(input_melody_data, input_chords_data, target_chords_data)):\n",
    "    Y_chord[i, chord_to_int[target_ch]] = 1\n",
    "    for j, chord in enumerate(input_ch):\n",
    "#         X_chords[i, j, chord_to_int[chord]] = 1\n",
    "        chord_index = chord_to_int[chord]\n",
    "        if (chord_index < num_ch):\n",
    "            X_chords[i, j, :] = X_chords_embeddings[chord_index, :]\n",
    "    \n",
    "    for j, note in enumerate(input_mel):\n",
    "        X_melody[i, j, note_to_int[note]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334344, 135, 14)\n",
      "(334344, 7, 16)\n",
      "(334344, 195)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody.shape)\n",
    "print(X_chords.shape)\n",
    "print(Y_chord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset into 80%-10%-10% train-valid-test sets\n",
    "seed = 0\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "\n",
    "for train_index, aux_index in sss.split(X_chords, Y_chord):\n",
    "    X_melody_train, X_melody_aux = X_melody[train_index], X_melody[aux_index]\n",
    "    X_chords_train, X_chords_aux = X_chords[train_index], X_chords[aux_index]\n",
    "    Y_chord_train, Y_chord_aux = Y_chord[train_index], Y_chord[aux_index]\n",
    "    \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)\n",
    "\n",
    "for valid_index, test_index in sss.split(X_chords_aux, Y_chord_aux):\n",
    "    X_melody_valid, X_melody_test = X_melody[valid_index], X_melody[test_index]\n",
    "    X_chords_valid, X_chords_test = X_chords[valid_index], X_chords[test_index]\n",
    "    Y_chord_valid, Y_chord_test = Y_chord[valid_index], Y_chord[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 135, 14)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 7, 16)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_1 (GRU)                      (None, 135, 128)      54912       input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_3 (GRU)                      (None, 7, 128)        55680       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_2 (GRU)                      (None, 128)           98688       gru_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      (None, 128)           98688       gru_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 256)           0           gru_2[0][0]                      \n",
      "                                                                   gru_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 128)           32896       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 195)           25155       dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 366,019\n",
      "Trainable params: 366,019\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define neual net architecture\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "melody_input = Input(shape=(max_mel_len, n_notes))\n",
    "melody_gru1 = GRU(latent_dim, return_sequences=True)(melody_input)\n",
    "melody_gru2 = GRU(latent_dim)(melody_gru1)\n",
    "\n",
    "chords_input = Input(shape=(chord_context_len, n_dimensions))\n",
    "chords_gru1 = GRU(latent_dim, return_sequences=True)(chords_input)\n",
    "chords_gru2 = GRU(latent_dim)(chords_gru1)\n",
    "\n",
    "concat = concatenate([melody_gru2, chords_gru2])\n",
    "\n",
    "chord_dense1 = Dense(latent_dim, activation='relu')(concat)\n",
    "chord_dense2 = Dense(n_chords, activation='softmax')(chord_dense1)\n",
    "\n",
    "model = Model([melody_input, chords_input], chord_dense2)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Introduce Best-Performance callbacks\n",
    "# es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "filepath = \"models/embeddings16-Mel2-Cho2-FC2_150ep.h5\"\n",
    "bp = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267475 samples, validate on 33434 samples\n",
      "Epoch 1/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.8309 - acc: 0.3606Epoch 00000: val_acc improved from -inf to 0.43435, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 331s - loss: 2.8307 - acc: 0.3606 - val_loss: 2.4482 - val_acc: 0.4343\n",
      "Epoch 2/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.2142 - acc: 0.4739Epoch 00001: val_acc improved from 0.43435 to 0.49348, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 331s - loss: 2.2139 - acc: 0.4740 - val_loss: 2.1820 - val_acc: 0.4935\n",
      "Epoch 3/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.9533 - acc: 0.5310Epoch 00002: val_acc improved from 0.49348 to 0.53906, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 331s - loss: 1.9530 - acc: 0.5311 - val_loss: 2.0127 - val_acc: 0.5391\n",
      "Epoch 4/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.7658 - acc: 0.5755Epoch 00003: val_acc improved from 0.53906 to 0.56323, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 331s - loss: 1.7660 - acc: 0.5754 - val_loss: 1.8946 - val_acc: 0.5632\n",
      "Epoch 5/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.6229 - acc: 0.6091Epoch 00004: val_acc improved from 0.56323 to 0.58572, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 332s - loss: 1.6230 - acc: 0.6091 - val_loss: 1.8211 - val_acc: 0.5857\n",
      "Epoch 6/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.5135 - acc: 0.6342Epoch 00005: val_acc improved from 0.58572 to 0.59885, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 331s - loss: 1.5133 - acc: 0.6342 - val_loss: 1.7554 - val_acc: 0.5989\n",
      "Epoch 7/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.4251 - acc: 0.6531Epoch 00006: val_acc improved from 0.59885 to 0.61016, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 332s - loss: 1.4252 - acc: 0.6530 - val_loss: 1.7039 - val_acc: 0.6102\n",
      "Epoch 8/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.3557 - acc: 0.6690Epoch 00007: val_acc improved from 0.61016 to 0.62185, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 332s - loss: 1.3557 - acc: 0.6690 - val_loss: 1.6689 - val_acc: 0.6219\n",
      "Epoch 9/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2983 - acc: 0.6803Epoch 00008: val_acc improved from 0.62185 to 0.62828, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 332s - loss: 1.2985 - acc: 0.6803 - val_loss: 1.6359 - val_acc: 0.6283\n",
      "Epoch 10/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2505 - acc: 0.6903Epoch 00009: val_acc improved from 0.62828 to 0.63361, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 334s - loss: 1.2504 - acc: 0.6903 - val_loss: 1.6125 - val_acc: 0.6336\n",
      "Epoch 11/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2126 - acc: 0.6980Epoch 00010: val_acc improved from 0.63361 to 0.64105, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 334s - loss: 1.2127 - acc: 0.6980 - val_loss: 1.5813 - val_acc: 0.6411\n",
      "Epoch 12/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1802 - acc: 0.7049Epoch 00011: val_acc improved from 0.64105 to 0.64485, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 335s - loss: 1.1802 - acc: 0.7049 - val_loss: 1.5706 - val_acc: 0.6449\n",
      "Epoch 13/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1530 - acc: 0.7102Epoch 00012: val_acc improved from 0.64485 to 0.65308, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 335s - loss: 1.1530 - acc: 0.7101 - val_loss: 1.5546 - val_acc: 0.6531\n",
      "Epoch 14/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1301 - acc: 0.7145Epoch 00013: val_acc improved from 0.65308 to 0.65897, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 335s - loss: 1.1301 - acc: 0.7145 - val_loss: 1.5319 - val_acc: 0.6590\n",
      "Epoch 15/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1083 - acc: 0.7183Epoch 00014: val_acc improved from 0.65897 to 0.66283, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 336s - loss: 1.1082 - acc: 0.7183 - val_loss: 1.5270 - val_acc: 0.6628\n",
      "Epoch 16/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0906 - acc: 0.7210Epoch 00015: val_acc improved from 0.66283 to 0.66516, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 336s - loss: 1.0906 - acc: 0.7210 - val_loss: 1.5133 - val_acc: 0.6652\n",
      "Epoch 17/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0746 - acc: 0.7248Epoch 00016: val_acc did not improve\n",
      "267475/267475 [==============================] - 336s - loss: 1.0745 - acc: 0.7249 - val_loss: 1.5188 - val_acc: 0.6648\n",
      "Epoch 18/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0621 - acc: 0.7268Epoch 00017: val_acc improved from 0.66516 to 0.67171, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 337s - loss: 1.0620 - acc: 0.7268 - val_loss: 1.5046 - val_acc: 0.6717\n",
      "Epoch 19/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0489 - acc: 0.7288Epoch 00018: val_acc did not improve\n",
      "267475/267475 [==============================] - 338s - loss: 1.0488 - acc: 0.7288 - val_loss: 1.5035 - val_acc: 0.6692\n",
      "Epoch 20/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0383 - acc: 0.7304Epoch 00019: val_acc improved from 0.67171 to 0.67452, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 337s - loss: 1.0384 - acc: 0.7303 - val_loss: 1.4801 - val_acc: 0.6745\n",
      "Epoch 21/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0277 - acc: 0.7327Epoch 00020: val_acc improved from 0.67452 to 0.67497, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 337s - loss: 1.0277 - acc: 0.7327 - val_loss: 1.4840 - val_acc: 0.6750\n",
      "Epoch 22/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0197 - acc: 0.7345Epoch 00021: val_acc improved from 0.67497 to 0.68039, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 337s - loss: 1.0197 - acc: 0.7345 - val_loss: 1.4859 - val_acc: 0.6804\n",
      "Epoch 23/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0115 - acc: 0.7353Epoch 00022: val_acc did not improve\n",
      "267475/267475 [==============================] - 338s - loss: 1.0114 - acc: 0.7353 - val_loss: 1.4801 - val_acc: 0.6799\n",
      "Epoch 24/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0049 - acc: 0.7359Epoch 00023: val_acc did not improve\n",
      "267475/267475 [==============================] - 337s - loss: 1.0049 - acc: 0.7359 - val_loss: 1.4807 - val_acc: 0.6762\n",
      "Epoch 25/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9988 - acc: 0.7375Epoch 00024: val_acc did not improve\n",
      "267475/267475 [==============================] - 338s - loss: 0.9988 - acc: 0.7376 - val_loss: 1.4711 - val_acc: 0.6798\n",
      "Epoch 26/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9917 - acc: 0.7393Epoch 00025: val_acc improved from 0.68039 to 0.68212, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 338s - loss: 0.9918 - acc: 0.7393 - val_loss: 1.4739 - val_acc: 0.6821\n",
      "Epoch 27/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9871 - acc: 0.7398Epoch 00026: val_acc did not improve\n",
      "267475/267475 [==============================] - 337s - loss: 0.9871 - acc: 0.7399 - val_loss: 1.4769 - val_acc: 0.6782\n",
      "Epoch 28/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9828 - acc: 0.7407Epoch 00027: val_acc did not improve\n",
      "267475/267475 [==============================] - 338s - loss: 0.9827 - acc: 0.7407 - val_loss: 1.4796 - val_acc: 0.6786\n",
      "Epoch 29/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9771 - acc: 0.7418Epoch 00028: val_acc improved from 0.68212 to 0.68442, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 337s - loss: 0.9769 - acc: 0.7419 - val_loss: 1.4777 - val_acc: 0.6844\n",
      "Epoch 30/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9734 - acc: 0.7415Epoch 00029: val_acc did not improve\n",
      "267475/267475 [==============================] - 338s - loss: 0.9735 - acc: 0.7414 - val_loss: 1.4766 - val_acc: 0.6844\n",
      "Epoch 31/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9705 - acc: 0.7425Epoch 00030: val_acc improved from 0.68442 to 0.68616, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 338s - loss: 0.9706 - acc: 0.7425 - val_loss: 1.4665 - val_acc: 0.6862\n",
      "Epoch 32/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9651 - acc: 0.7439Epoch 00031: val_acc did not improve\n",
      "267475/267475 [==============================] - 339s - loss: 0.9652 - acc: 0.7439 - val_loss: 1.4734 - val_acc: 0.6854\n",
      "Epoch 33/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9638 - acc: 0.7435Epoch 00032: val_acc improved from 0.68616 to 0.68643, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 338s - loss: 0.9637 - acc: 0.7435 - val_loss: 1.4629 - val_acc: 0.6864\n",
      "Epoch 34/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9585 - acc: 0.7443Epoch 00033: val_acc improved from 0.68643 to 0.68906, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 338s - loss: 0.9585 - acc: 0.7443 - val_loss: 1.4657 - val_acc: 0.6891\n",
      "Epoch 35/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9581 - acc: 0.7446Epoch 00034: val_acc did not improve\n",
      "267475/267475 [==============================] - 339s - loss: 0.9581 - acc: 0.7446 - val_loss: 1.4713 - val_acc: 0.6841\n",
      "Epoch 36/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9541 - acc: 0.7453Epoch 00035: val_acc did not improve\n",
      "267475/267475 [==============================] - 339s - loss: 0.9541 - acc: 0.7453 - val_loss: 1.4680 - val_acc: 0.6873\n",
      "Epoch 37/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9512 - acc: 0.7460Epoch 00036: val_acc improved from 0.68906 to 0.69061, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 339s - loss: 0.9512 - acc: 0.7460 - val_loss: 1.4595 - val_acc: 0.6906\n",
      "Epoch 38/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9655 - acc: 0.7437Epoch 00037: val_acc did not improve\n",
      "267475/267475 [==============================] - 339s - loss: 0.9656 - acc: 0.7437 - val_loss: 1.4752 - val_acc: 0.6825\n",
      "Epoch 39/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9498 - acc: 0.7465Epoch 00038: val_acc did not improve\n",
      "267475/267475 [==============================] - 340s - loss: 0.9499 - acc: 0.7464 - val_loss: 1.4604 - val_acc: 0.6874\n",
      "Epoch 40/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9513 - acc: 0.7462Epoch 00039: val_acc did not improve\n",
      "267475/267475 [==============================] - 340s - loss: 0.9513 - acc: 0.7462 - val_loss: 1.4750 - val_acc: 0.6892\n",
      "Epoch 41/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9424 - acc: 0.7479Epoch 00040: val_acc did not improve\n",
      "267475/267475 [==============================] - 339s - loss: 0.9425 - acc: 0.7479 - val_loss: 1.4807 - val_acc: 0.6848\n",
      "Epoch 42/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9424 - acc: 0.7475Epoch 00041: val_acc did not improve\n",
      "267475/267475 [==============================] - 340s - loss: 0.9425 - acc: 0.7475 - val_loss: 1.4683 - val_acc: 0.6859\n",
      "Epoch 43/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9376 - acc: 0.7489Epoch 00042: val_acc improved from 0.69061 to 0.69229, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 339s - loss: 0.9375 - acc: 0.7489 - val_loss: 1.4628 - val_acc: 0.6923\n",
      "Epoch 44/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9329 - acc: 0.7496Epoch 00043: val_acc improved from 0.69229 to 0.69292, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 340s - loss: 0.9328 - acc: 0.7496 - val_loss: 1.4598 - val_acc: 0.6929\n",
      "Epoch 45/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9309 - acc: 0.7498Epoch 00044: val_acc did not improve\n",
      "267475/267475 [==============================] - 340s - loss: 0.9309 - acc: 0.7498 - val_loss: 1.4600 - val_acc: 0.6912\n",
      "Epoch 46/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9234 - acc: 0.7513Epoch 00045: val_acc did not improve\n",
      "267475/267475 [==============================] - 340s - loss: 0.9233 - acc: 0.7513 - val_loss: 1.4548 - val_acc: 0.6914\n",
      "Epoch 47/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9186 - acc: 0.7530Epoch 00046: val_acc did not improve\n",
      "267475/267475 [==============================] - 340s - loss: 0.9187 - acc: 0.7530 - val_loss: 1.4494 - val_acc: 0.6921\n",
      "Epoch 48/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9307 - acc: 0.7490Epoch 00047: val_acc improved from 0.69292 to 0.69504, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 340s - loss: 0.9305 - acc: 0.7490 - val_loss: 1.4337 - val_acc: 0.6950\n",
      "Epoch 49/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9139 - acc: 0.7522Epoch 00048: val_acc improved from 0.69504 to 0.69630, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 340s - loss: 0.9138 - acc: 0.7522 - val_loss: 1.4291 - val_acc: 0.6963\n",
      "Epoch 50/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8993 - acc: 0.7554Epoch 00049: val_acc did not improve\n",
      "267475/267475 [==============================] - 340s - loss: 0.8994 - acc: 0.7554 - val_loss: 1.4229 - val_acc: 0.6938\n",
      "Epoch 51/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8839 - acc: 0.7577Epoch 00050: val_acc improved from 0.69630 to 0.70195, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 340s - loss: 0.8840 - acc: 0.7577 - val_loss: 1.3903 - val_acc: 0.7020\n",
      "Epoch 52/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8656 - acc: 0.7607Epoch 00051: val_acc improved from 0.70195 to 0.70279, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 342s - loss: 0.8656 - acc: 0.7606 - val_loss: 1.3810 - val_acc: 0.7028\n",
      "Epoch 53/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8501 - acc: 0.7627Epoch 00052: val_acc improved from 0.70279 to 0.70527, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 341s - loss: 0.8501 - acc: 0.7627 - val_loss: 1.3790 - val_acc: 0.7053\n",
      "Epoch 54/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8404 - acc: 0.7652Epoch 00053: val_acc improved from 0.70527 to 0.70826, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 341s - loss: 0.8403 - acc: 0.7652 - val_loss: 1.3586 - val_acc: 0.7083\n",
      "Epoch 55/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8311 - acc: 0.7668Epoch 00054: val_acc improved from 0.70826 to 0.71236, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 341s - loss: 0.8313 - acc: 0.7667 - val_loss: 1.3536 - val_acc: 0.7124\n",
      "Epoch 56/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8240 - acc: 0.7684Epoch 00055: val_acc did not improve\n",
      "267475/267475 [==============================] - 341s - loss: 0.8239 - acc: 0.7684 - val_loss: 1.3604 - val_acc: 0.7091\n",
      "Epoch 57/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8161 - acc: 0.7704Epoch 00056: val_acc did not improve\n",
      "267475/267475 [==============================] - 341s - loss: 0.8161 - acc: 0.7704 - val_loss: 1.3374 - val_acc: 0.7098\n",
      "Epoch 58/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8047 - acc: 0.7735Epoch 00057: val_acc improved from 0.71236 to 0.71601, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 340s - loss: 0.8047 - acc: 0.7735 - val_loss: 1.3250 - val_acc: 0.7160\n",
      "Epoch 59/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7939 - acc: 0.7761Epoch 00058: val_acc did not improve\n",
      "267475/267475 [==============================] - 341s - loss: 0.7938 - acc: 0.7761 - val_loss: 1.3397 - val_acc: 0.7120\n",
      "Epoch 60/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7841 - acc: 0.7782Epoch 00059: val_acc improved from 0.71601 to 0.72014, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 341s - loss: 0.7843 - acc: 0.7781 - val_loss: 1.3189 - val_acc: 0.7201\n",
      "Epoch 61/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7719 - acc: 0.7811Epoch 00060: val_acc did not improve\n",
      "267475/267475 [==============================] - 342s - loss: 0.7718 - acc: 0.7811 - val_loss: 1.3224 - val_acc: 0.7200\n",
      "Epoch 62/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7630 - acc: 0.7841Epoch 00061: val_acc improved from 0.72014 to 0.72369, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 342s - loss: 0.7629 - acc: 0.7841 - val_loss: 1.3098 - val_acc: 0.7237\n",
      "Epoch 63/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7486 - acc: 0.7874Epoch 00062: val_acc improved from 0.72369 to 0.72420, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 341s - loss: 0.7487 - acc: 0.7874 - val_loss: 1.3099 - val_acc: 0.7242\n",
      "Epoch 64/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7423 - acc: 0.7883Epoch 00063: val_acc did not improve\n",
      "267475/267475 [==============================] - 341s - loss: 0.7423 - acc: 0.7883 - val_loss: 1.3090 - val_acc: 0.7233\n",
      "Epoch 65/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7489 - acc: 0.7867Epoch 00064: val_acc did not improve\n",
      "267475/267475 [==============================] - 341s - loss: 0.7490 - acc: 0.7867 - val_loss: 1.3275 - val_acc: 0.7238\n",
      "Epoch 66/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7228 - acc: 0.7938Epoch 00065: val_acc improved from 0.72420 to 0.73090, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 342s - loss: 0.7229 - acc: 0.7938 - val_loss: 1.2948 - val_acc: 0.7309\n",
      "Epoch 67/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7090 - acc: 0.7970Epoch 00066: val_acc did not improve\n",
      "267475/267475 [==============================] - 342s - loss: 0.7089 - acc: 0.7970 - val_loss: 1.2909 - val_acc: 0.7299\n",
      "Epoch 68/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7061 - acc: 0.7979Epoch 00067: val_acc did not improve\n",
      "267475/267475 [==============================] - 342s - loss: 0.7061 - acc: 0.7979 - val_loss: 1.3518 - val_acc: 0.7158\n",
      "Epoch 69/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6996 - acc: 0.7994Epoch 00068: val_acc did not improve\n",
      "267475/267475 [==============================] - 342s - loss: 0.6996 - acc: 0.7994 - val_loss: 1.3062 - val_acc: 0.7285\n",
      "Epoch 70/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6805 - acc: 0.8042Epoch 00069: val_acc improved from 0.73090 to 0.73180, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 342s - loss: 0.6805 - acc: 0.8042 - val_loss: 1.3001 - val_acc: 0.7318\n",
      "Epoch 71/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6718 - acc: 0.8063Epoch 00070: val_acc improved from 0.73180 to 0.73288, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 342s - loss: 0.6718 - acc: 0.8064 - val_loss: 1.3020 - val_acc: 0.7329\n",
      "Epoch 72/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6608 - acc: 0.8101Epoch 00071: val_acc did not improve\n",
      "267475/267475 [==============================] - 342s - loss: 0.6608 - acc: 0.8101 - val_loss: 1.2977 - val_acc: 0.7322\n",
      "Epoch 73/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6482 - acc: 0.8132Epoch 00072: val_acc improved from 0.73288 to 0.73674, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 342s - loss: 0.6482 - acc: 0.8132 - val_loss: 1.2981 - val_acc: 0.7367\n",
      "Epoch 74/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6490 - acc: 0.8121Epoch 00073: val_acc improved from 0.73674 to 0.73730, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 342s - loss: 0.6490 - acc: 0.8121 - val_loss: 1.3032 - val_acc: 0.7373\n",
      "Epoch 75/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6325 - acc: 0.8164Epoch 00074: val_acc did not improve\n",
      "267475/267475 [==============================] - 343s - loss: 0.6325 - acc: 0.8164 - val_loss: 1.3458 - val_acc: 0.7248\n",
      "Epoch 76/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6290 - acc: 0.8170Epoch 00075: val_acc improved from 0.73730 to 0.73958, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 342s - loss: 0.6291 - acc: 0.8170 - val_loss: 1.3013 - val_acc: 0.7396\n",
      "Epoch 77/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6123 - acc: 0.8221Epoch 00076: val_acc did not improve\n",
      "267475/267475 [==============================] - 342s - loss: 0.6124 - acc: 0.8221 - val_loss: 1.3265 - val_acc: 0.7313\n",
      "Epoch 78/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6309 - acc: 0.8173Epoch 00077: val_acc did not improve\n",
      "267475/267475 [==============================] - 342s - loss: 0.6309 - acc: 0.8173 - val_loss: 1.3355 - val_acc: 0.7342\n",
      "Epoch 79/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6143 - acc: 0.8211Epoch 00078: val_acc did not improve\n",
      "267475/267475 [==============================] - 343s - loss: 0.6144 - acc: 0.8211 - val_loss: 1.3418 - val_acc: 0.7310\n",
      "Epoch 80/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6041 - acc: 0.8241Epoch 00079: val_acc improved from 0.73958 to 0.74308, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 342s - loss: 0.6041 - acc: 0.8241 - val_loss: 1.3111 - val_acc: 0.7431\n",
      "Epoch 81/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.8253Epoch 00080: val_acc did not improve\n",
      "267475/267475 [==============================] - 343s - loss: 0.6025 - acc: 0.8253 - val_loss: 1.3450 - val_acc: 0.7287\n",
      "Epoch 82/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5897 - acc: 0.8276Epoch 00081: val_acc did not improve\n",
      "267475/267475 [==============================] - 343s - loss: 0.5897 - acc: 0.8276 - val_loss: 1.3497 - val_acc: 0.7341\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6398 - acc: 0.8148Epoch 00082: val_acc did not improve\n",
      "267475/267475 [==============================] - 343s - loss: 0.6397 - acc: 0.8149 - val_loss: 1.3344 - val_acc: 0.7374\n",
      "Epoch 84/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5828 - acc: 0.8302Epoch 00083: val_acc did not improve\n",
      "267475/267475 [==============================] - 343s - loss: 0.5829 - acc: 0.8302 - val_loss: 1.3474 - val_acc: 0.7356\n",
      "Epoch 85/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.8243Epoch 00084: val_acc did not improve\n",
      "267475/267475 [==============================] - 344s - loss: 0.6025 - acc: 0.8243 - val_loss: 1.3649 - val_acc: 0.7305\n",
      "Epoch 86/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5768 - acc: 0.8315Epoch 00085: val_acc improved from 0.74308 to 0.74376, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 344s - loss: 0.5770 - acc: 0.8314 - val_loss: 1.3259 - val_acc: 0.7438\n",
      "Epoch 87/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5555 - acc: 0.8379Epoch 00086: val_acc did not improve\n",
      "267475/267475 [==============================] - 344s - loss: 0.5556 - acc: 0.8379 - val_loss: 1.3423 - val_acc: 0.7435\n",
      "Epoch 88/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5584 - acc: 0.8367Epoch 00087: val_acc did not improve\n",
      "267475/267475 [==============================] - 344s - loss: 0.5584 - acc: 0.8367 - val_loss: 1.3425 - val_acc: 0.7433\n",
      "Epoch 89/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5662 - acc: 0.8341Epoch 00088: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.5663 - acc: 0.8341 - val_loss: 1.3490 - val_acc: 0.7416\n",
      "Epoch 90/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5712 - acc: 0.8329Epoch 00089: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.5712 - acc: 0.8329 - val_loss: 1.3608 - val_acc: 0.7366\n",
      "Epoch 91/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5571 - acc: 0.8367Epoch 00090: val_acc improved from 0.74376 to 0.74424, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 345s - loss: 0.5570 - acc: 0.8367 - val_loss: 1.3465 - val_acc: 0.7442\n",
      "Epoch 92/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5710 - acc: 0.8330Epoch 00091: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.5710 - acc: 0.8330 - val_loss: 1.3523 - val_acc: 0.7428\n",
      "Epoch 93/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5426 - acc: 0.8407Epoch 00092: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.5428 - acc: 0.8407 - val_loss: 1.3526 - val_acc: 0.7426\n",
      "Epoch 94/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5791 - acc: 0.8303Epoch 00093: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.5790 - acc: 0.8303 - val_loss: 1.3621 - val_acc: 0.7383\n",
      "Epoch 95/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5371 - acc: 0.8421Epoch 00094: val_acc improved from 0.74424 to 0.74508, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 345s - loss: 0.5372 - acc: 0.8420 - val_loss: 1.3477 - val_acc: 0.7451\n",
      "Epoch 96/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5326 - acc: 0.8439Epoch 00095: val_acc did not improve\n",
      "267475/267475 [==============================] - 344s - loss: 0.5326 - acc: 0.8439 - val_loss: 1.3938 - val_acc: 0.7320\n",
      "Epoch 97/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5428 - acc: 0.8401Epoch 00096: val_acc improved from 0.74508 to 0.74523, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 344s - loss: 0.5428 - acc: 0.8401 - val_loss: 1.3607 - val_acc: 0.7452\n",
      "Epoch 98/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5063 - acc: 0.8516Epoch 00097: val_acc improved from 0.74523 to 0.74936, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 344s - loss: 0.5064 - acc: 0.8516 - val_loss: 1.3560 - val_acc: 0.7494\n",
      "Epoch 99/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5313 - acc: 0.8432Epoch 00098: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.5313 - acc: 0.8432 - val_loss: 1.3794 - val_acc: 0.7419\n",
      "Epoch 100/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5123 - acc: 0.8497Epoch 00099: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.5123 - acc: 0.8497 - val_loss: 1.3711 - val_acc: 0.7439\n",
      "Epoch 101/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5036 - acc: 0.8513Epoch 00100: val_acc improved from 0.74936 to 0.74981, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 344s - loss: 0.5037 - acc: 0.8512 - val_loss: 1.3629 - val_acc: 0.7498\n",
      "Epoch 102/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4971 - acc: 0.8540Epoch 00101: val_acc did not improve\n",
      "267475/267475 [==============================] - 344s - loss: 0.4972 - acc: 0.8540 - val_loss: 1.3804 - val_acc: 0.7450\n",
      "Epoch 103/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4862 - acc: 0.8573Epoch 00102: val_acc improved from 0.74981 to 0.75001, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 345s - loss: 0.4863 - acc: 0.8573 - val_loss: 1.3780 - val_acc: 0.7500\n",
      "Epoch 104/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.4963 - acc: 0.8535Epoch 00103: val_acc improved from 0.75001 to 0.75325, saving model to models/embeddings16-Mel2-Cho2-FC2_150ep.h5\n",
      "267475/267475 [==============================] - 345s - loss: 0.4962 - acc: 0.8536 - val_loss: 1.3850 - val_acc: 0.7532\n",
      "Epoch 105/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5004 - acc: 0.8523Epoch 00104: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.5005 - acc: 0.8523 - val_loss: 1.4033 - val_acc: 0.7413\n",
      "Epoch 106/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5301 - acc: 0.8435Epoch 00105: val_acc did not improve\n",
      "267475/267475 [==============================] - 344s - loss: 0.5302 - acc: 0.8434 - val_loss: 1.3833 - val_acc: 0.7439\n",
      "Epoch 107/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5491 - acc: 0.8406Epoch 00106: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.5492 - acc: 0.8406 - val_loss: 1.5112 - val_acc: 0.7040\n",
      "Epoch 108/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0180 - acc: 0.7317Epoch 00107: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 1.0179 - acc: 0.7317 - val_loss: 1.5786 - val_acc: 0.6798\n",
      "Epoch 109/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8899 - acc: 0.7560Epoch 00108: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.8898 - acc: 0.7560 - val_loss: 1.4718 - val_acc: 0.7037\n",
      "Epoch 110/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8294 - acc: 0.7683Epoch 00109: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.8294 - acc: 0.7683 - val_loss: 1.4530 - val_acc: 0.7034\n",
      "Epoch 111/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8056 - acc: 0.7732Epoch 00110: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.8056 - acc: 0.7732 - val_loss: 1.4333 - val_acc: 0.7063\n",
      "Epoch 112/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8190 - acc: 0.7701Epoch 00111: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.8191 - acc: 0.7700 - val_loss: 1.4487 - val_acc: 0.6996\n",
      "Epoch 113/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7958 - acc: 0.7748Epoch 00112: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.7958 - acc: 0.7748 - val_loss: 1.4019 - val_acc: 0.7115\n",
      "Epoch 114/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7598 - acc: 0.7835Epoch 00113: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.7597 - acc: 0.7835 - val_loss: 1.3680 - val_acc: 0.7197\n",
      "Epoch 115/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7327 - acc: 0.7905Epoch 00114: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.7326 - acc: 0.7905 - val_loss: 1.3641 - val_acc: 0.7194\n",
      "Epoch 116/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7167 - acc: 0.7940Epoch 00115: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.7166 - acc: 0.7941 - val_loss: 1.3442 - val_acc: 0.7245\n",
      "Epoch 117/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7099 - acc: 0.7961Epoch 00116: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.7100 - acc: 0.7961 - val_loss: 1.3592 - val_acc: 0.7216\n",
      "Epoch 118/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7107 - acc: 0.7952Epoch 00117: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.7107 - acc: 0.7952 - val_loss: 1.3499 - val_acc: 0.7258\n",
      "Epoch 119/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6957 - acc: 0.7997Epoch 00118: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6959 - acc: 0.7997 - val_loss: 1.3380 - val_acc: 0.7278\n",
      "Epoch 120/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6637 - acc: 0.8077Epoch 00119: val_acc did not improve\n",
      "267475/267475 [==============================] - 345s - loss: 0.6637 - acc: 0.8077 - val_loss: 1.3310 - val_acc: 0.7282\n",
      "Epoch 121/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6456 - acc: 0.8127Epoch 00120: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6455 - acc: 0.8127 - val_loss: 1.3439 - val_acc: 0.7316\n",
      "Epoch 122/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6482 - acc: 0.8117Epoch 00121: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6482 - acc: 0.8117 - val_loss: 1.3363 - val_acc: 0.7351\n",
      "Epoch 123/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6197 - acc: 0.8194Epoch 00122: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6196 - acc: 0.8194 - val_loss: 1.3362 - val_acc: 0.7353\n",
      "Epoch 124/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6054 - acc: 0.8231Epoch 00123: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6053 - acc: 0.8231 - val_loss: 1.3351 - val_acc: 0.7392\n",
      "Epoch 125/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5920 - acc: 0.8269Epoch 00124: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.5922 - acc: 0.8269 - val_loss: 1.3297 - val_acc: 0.7393\n",
      "Epoch 126/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5844 - acc: 0.8300Epoch 00125: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.5846 - acc: 0.8300 - val_loss: 1.3534 - val_acc: 0.7362\n",
      "Epoch 127/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7187 - acc: 0.7941Epoch 00126: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.7189 - acc: 0.7941 - val_loss: 1.4265 - val_acc: 0.7087\n",
      "Epoch 128/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.7050 - acc: 0.7963Epoch 00127: val_acc did not improve\n",
      "267475/267475 [==============================] - 347s - loss: 0.7049 - acc: 0.7963 - val_loss: 1.3578 - val_acc: 0.7287\n",
      "Epoch 129/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6672 - acc: 0.8053Epoch 00128: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6673 - acc: 0.8053 - val_loss: 1.3621 - val_acc: 0.7266\n",
      "Epoch 130/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6430 - acc: 0.8122Epoch 00129: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6428 - acc: 0.8123 - val_loss: 1.3556 - val_acc: 0.7284\n",
      "Epoch 131/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6266 - acc: 0.8169Epoch 00130: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6265 - acc: 0.8169 - val_loss: 1.3392 - val_acc: 0.7362\n",
      "Epoch 132/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6140 - acc: 0.8204Epoch 00131: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6140 - acc: 0.8204 - val_loss: 1.3441 - val_acc: 0.7365\n",
      "Epoch 133/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5927 - acc: 0.8264Epoch 00132: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.5927 - acc: 0.8264 - val_loss: 1.3402 - val_acc: 0.7392\n",
      "Epoch 134/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6318 - acc: 0.8159Epoch 00133: val_acc did not improve\n",
      "267475/267475 [==============================] - 347s - loss: 0.6319 - acc: 0.8159 - val_loss: 1.3600 - val_acc: 0.7263\n",
      "Epoch 135/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6867 - acc: 0.8013Epoch 00134: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6866 - acc: 0.8013 - val_loss: 1.3590 - val_acc: 0.7293\n",
      "Epoch 136/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6515 - acc: 0.8103Epoch 00135: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6516 - acc: 0.8102 - val_loss: 1.3683 - val_acc: 0.7293\n",
      "Epoch 137/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.8121Epoch 00136: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6461 - acc: 0.8121 - val_loss: 1.3397 - val_acc: 0.7347\n",
      "Epoch 138/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6237 - acc: 0.8187Epoch 00137: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.6239 - acc: 0.8186 - val_loss: 1.3333 - val_acc: 0.7370\n",
      "Epoch 139/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6106 - acc: 0.8223Epoch 00138: val_acc did not improve\n",
      "267475/267475 [==============================] - 347s - loss: 0.6104 - acc: 0.8223 - val_loss: 1.3550 - val_acc: 0.7347\n",
      "Epoch 140/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.6274 - acc: 0.8172Epoch 00139: val_acc did not improve\n",
      "267475/267475 [==============================] - 347s - loss: 0.6273 - acc: 0.8172 - val_loss: 1.3507 - val_acc: 0.7351\n",
      "Epoch 141/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5852 - acc: 0.8288Epoch 00140: val_acc did not improve\n",
      "267475/267475 [==============================] - 347s - loss: 0.5853 - acc: 0.8288 - val_loss: 1.3412 - val_acc: 0.7412\n",
      "Epoch 142/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5683 - acc: 0.8337Epoch 00141: val_acc did not improve\n",
      "267475/267475 [==============================] - 347s - loss: 0.5684 - acc: 0.8336 - val_loss: 1.3572 - val_acc: 0.7388\n",
      "Epoch 143/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5784 - acc: 0.8305Epoch 00142: val_acc did not improve\n",
      "267475/267475 [==============================] - 347s - loss: 0.5785 - acc: 0.8304 - val_loss: 1.3416 - val_acc: 0.7430\n",
      "Epoch 144/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5521 - acc: 0.8386Epoch 00143: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 347s - loss: 0.5522 - acc: 0.8386 - val_loss: 1.3487 - val_acc: 0.7441\n",
      "Epoch 145/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5421 - acc: 0.8405Epoch 00144: val_acc did not improve\n",
      "267475/267475 [==============================] - 347s - loss: 0.5420 - acc: 0.8405 - val_loss: 1.3669 - val_acc: 0.7382\n",
      "Epoch 146/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5396 - acc: 0.8414Epoch 00145: val_acc did not improve\n",
      "267475/267475 [==============================] - 346s - loss: 0.5396 - acc: 0.8415 - val_loss: 1.3461 - val_acc: 0.7487\n",
      "Epoch 147/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5337 - acc: 0.8436Epoch 00146: val_acc did not improve\n",
      "267475/267475 [==============================] - 347s - loss: 0.5337 - acc: 0.8435 - val_loss: 1.3683 - val_acc: 0.7415\n",
      "Epoch 148/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5396 - acc: 0.8412Epoch 00147: val_acc did not improve\n",
      "267475/267475 [==============================] - 348s - loss: 0.5396 - acc: 0.8411 - val_loss: 1.3932 - val_acc: 0.7365\n",
      "Epoch 149/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5604 - acc: 0.8342Epoch 00148: val_acc did not improve\n",
      "267475/267475 [==============================] - 348s - loss: 0.5602 - acc: 0.8342 - val_loss: 1.3727 - val_acc: 0.7385\n",
      "Epoch 150/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.5652 - acc: 0.8332Epoch 00149: val_acc did not improve\n",
      "267475/267475 [==============================] - 347s - loss: 0.5653 - acc: 0.8332 - val_loss: 1.3680 - val_acc: 0.7427\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 256\n",
    "epochs = 150\n",
    "\n",
    "history = model.fit([X_melody_train, X_chords_train], Y_chord_train, epochs=epochs, validation_data=([X_melody_valid, X_chords_valid], Y_chord_valid), batch_size=batch_size, callbacks=[bp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe2402c160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFkCAYAAADWs8tQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe2402c908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize model learning\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Training history of root model\", fontsize=16)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load best performance model\n",
    "best_model = load_model(\"models/embeddings16-Mel2-Cho2-FC2_150ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33435, 135, 14)\n",
      "(33435, 7, 16)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody_test.shape)\n",
    "print(X_chords_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord prediction: 0.7437\n",
      "Kappa score of combined chord prediction: 0.7373\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of labels\n",
    "\n",
    "# Predict chords from each test sample melody\n",
    "Y_chord_pred = model.predict([X_melody_test, X_chords_test])\n",
    "\n",
    "# Compute accuracy and kappa score \n",
    "print(\"Categorical accuracy of combined chord prediction: {0:.4f}\".format(harmoutil.compute_accuracy_score(Y_chord_test, Y_chord_pred)))\n",
    "print(\"Kappa score of combined chord prediction: {0:.4f}\".format(harmoutil.compute_kappa_score(Y_chord_test, Y_chord_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord pitch prediction: 0.9113\n",
      "TP: 112797 TN: 252822 FP: 17945 FN: 17656\n",
      "Kappa score of combined chord pitch prediction: 0.7979\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of pitches\n",
    "\n",
    "def label_to_pitch_tensors(predictions):\n",
    "    predicted_chords = [int_to_chord[np.argmax(ch)] for ch in predictions]\n",
    "    pitch_chords = [harmoutil.chord_to_notes(label) for label in predicted_chords]\n",
    "    \n",
    "    Y_pitches = np.zeros((predictions.shape[0], 12), dtype='float32')\n",
    "    for i, chord_pitches in enumerate(pitch_chords):\n",
    "        for j, pitch_presence in enumerate(chord_pitches):\n",
    "            Y_pitches[i, j] = pitch_presence\n",
    "\n",
    "    return Y_pitches\n",
    "\n",
    "Y_pitch_pred = label_to_pitch_tensors(Y_chord_pred)\n",
    "Y_pitch_test = label_to_pitch_tensors(Y_chord_test)\n",
    "\n",
    "print(\"Categorical accuracy of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_accuracy_score(Y_pitch_test, Y_pitch_pred)))\n",
    "print(\"Kappa score of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_kappa_score(Y_pitch_test, Y_pitch_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
