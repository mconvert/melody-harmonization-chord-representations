{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/.local/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, GRU, concatenate\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# Custom library for the project\n",
    "import sys\n",
    "sys.path.insert(0, '../../src')\n",
    "import harmoutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'harmoutil' from '../../src/harmoutil.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Remove when done with kernel\n",
    "import importlib\n",
    "importlib.reload(harmoutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = harmoutil.load_pickled_data(\"../../data/refined_data.pkl\") # lists of (chord label, melody seqs) by sections\n",
    "augmented_data = harmoutil.transpose_and_augment_data(raw_data)\n",
    "data = [harmoutil.to_sevenths(section) for section in augmented_data]\n",
    "data = [harmoutil.melody_to_octave_range(section) for section in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chords: 334344 | Sample chord: E6\n",
      "Number of melody notes in the data: 2209944 | Sample melody note: 4\n",
      "Unique notes: [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Unique notes: ['A', 'A+', 'A+7', 'A+j7', 'A-', 'A-6', 'A-7', 'A-j7', 'A6', 'A7', 'Ab', 'Ab+', 'Ab+7', 'Ab+j7', 'Ab-', 'Ab-6', 'Ab-7', 'Ab-j7', 'Ab6', 'Ab7', 'Abj7', 'Abm7b5', 'Abo', 'Abo7', 'Absus', 'Absus7', 'Aj7', 'Am7b5', 'Ao', 'Ao7', 'Asus', 'Asus7', 'B', 'B+', 'B+7', 'B+j7', 'B-', 'B-6', 'B-7', 'B-j7', 'B6', 'B7', 'Bb', 'Bb+', 'Bb+7', 'Bb+j7', 'Bb-', 'Bb-6', 'Bb-7', 'Bb-j7', 'Bb6', 'Bb7', 'Bbj7', 'Bbm7b5', 'Bbo', 'Bbo7', 'Bbsus', 'Bbsus7', 'Bj7', 'Bm7b5', 'Bo', 'Bo7', 'Bsus', 'Bsus7', 'C', 'C+', 'C+7', 'C+j7', 'C-', 'C-6', 'C-7', 'C-j7', 'C6', 'C7', 'Cj7', 'Cm7b5', 'Co', 'Co7', 'Csus', 'Csus7', 'D', 'D+', 'D+7', 'D+j7', 'D-', 'D-6', 'D-7', 'D-j7', 'D6', 'D7', 'Db', 'Db+', 'Db+7', 'Db+j7', 'Db-', 'Db-6', 'Db-7', 'Db-j7', 'Db6', 'Db7', 'Dbj7', 'Dbm7b5', 'Dbo', 'Dbo7', 'Dbsus', 'Dbsus7', 'Dj7', 'Dm7b5', 'Do', 'Do7', 'Dsus', 'Dsus7', 'E', 'E+', 'E+7', 'E+j7', 'E-', 'E-6', 'E-7', 'E-j7', 'E6', 'E7', 'Eb', 'Eb+', 'Eb+7', 'Eb+j7', 'Eb-', 'Eb-6', 'Eb-7', 'Eb-j7', 'Eb6', 'Eb7', 'Ebj7', 'Ebm7b5', 'Ebo', 'Ebo7', 'Ebsus', 'Ebsus7', 'Ej7', 'Em7b5', 'Eo', 'Eo7', 'Esus', 'Esus7', 'F', 'F+', 'F+7', 'F+j7', 'F-', 'F-6', 'F-7', 'F-j7', 'F6', 'F7', 'Fj7', 'Fm7b5', 'Fo', 'Fo7', 'Fsus', 'Fsus7', 'G', 'G+', 'G+7', 'G+j7', 'G-', 'G-6', 'G-7', 'G-j7', 'G6', 'G7', 'Gb', 'Gb+', 'Gb+7', 'Gb+j7', 'Gb-', 'Gb-6', 'Gb-7', 'Gb-j7', 'Gb6', 'Gb7', 'Gbj7', 'Gbm7b5', 'Gbo', 'Gbo7', 'Gbsus', 'Gbsus7', 'Gj7', 'Gm7b5', 'Go', 'Go7', 'Gsus', 'Gsus7', 'NC']\n"
     ]
    }
   ],
   "source": [
    "# Isolate relevant data\n",
    "def get_notes_by_chord(beats):\n",
    "    return [note for beat in beats for note in beat]\n",
    "\n",
    "def get_chords_by_section(section):\n",
    "    return [chord_info[0] for chord_info in section]\n",
    "\n",
    "# def check_if_augmented_major(section):\n",
    "#     section_chords = get_chords_by_section(section)\n",
    "#     for ch in section_chords:\n",
    "#         if \"+j7\" in ch:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "# data = [section for section in data if not check_if_augmented_major(section)]\n",
    "# print(\"---Remove sections with augmented major chord---\")\n",
    "# print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections_bf_augmaj7 = [get_chords_by_section(section) for section in data]\n",
    "chords = [chord_info[0] for section in data for chord_info in section]\n",
    "unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords_bf_augmaj7 = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "notes = [note for chord_notes in notes_by_chords_bf_augmaj7 for note in chord_notes]\n",
    "unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "# print(sum([len(section) for section in chords_by_sections]))\n",
    "# print(\"Number of sections: {} | Sample section chords: {}\".format(len(chords_by_sections), chords_by_sections[0]))\n",
    "print(\"Number of chords: {} | Sample chord: {}\".format(len(chords), chords[0]))\n",
    "# print(\"Number of melodies {} | Sample melody: {}\".format(len(notes_by_chords), notes_by_chords[0]))\n",
    "print(\"Number of melody notes in the data: {} | Sample melody note: {}\".format(len(notes), notes[0]))\n",
    "print(\"Unique notes: {}\".format(unique_notes))\n",
    "print(\"Unique notes: {}\".format(unique_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melody note to integer mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, '<pad>': 13, -1: 12}\n",
      "\n",
      "Integer to melody note mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: -1, 13: '<pad>'}\n",
      "\n",
      "Chord label to integer mapping:\n",
      " {'A+7': 2, 'Absus7': 25, 'Db+': 91, 'B7': 41, 'Gb-6': 175, 'D+7': 82, 'Co7': 77, 'G7': 169, 'Abj7': 20, 'Dm7b5': 107, 'Ab-j7': 17, 'Db-7': 96, 'Gb-': 174, 'F+j7': 147, 'Db7': 99, 'Gbj7': 180, 'Gj7': 186, 'Eb+7': 124, 'D': 80, 'Gbsus': 184, 'D-6': 85, 'Fj7': 154, 'Bsus': 62, 'Ao7': 29, 'Go': 188, 'F': 144, 'Eb+': 123, 'Bm7b5': 59, 'G6': 168, 'Abm7b5': 21, 'Am7b5': 27, 'Co': 76, '<bos>': 193, 'Eb7': 131, 'Dsus7': 111, 'D-7': 86, 'Bj7': 58, 'Dbj7': 100, 'Db': 90, 'Gb+': 171, 'E': 112, 'Bo7': 61, 'G+': 161, 'Csus7': 79, 'A7': 9, 'G-7': 166, 'Do': 108, 'Dbo': 102, 'Dbm7b5': 101, 'D-j7': 87, 'Db+7': 92, 'Asus7': 31, 'Ab7': 19, 'Dsus': 110, 'Dbo7': 103, 'Gb': 170, 'Go7': 189, 'Fsus7': 159, 'Dj7': 106, 'E7': 121, 'Ab+j7': 13, 'Ebm7b5': 133, 'Dbsus7': 105, 'C+7': 66, 'Bb-': 46, 'C-6': 69, 'Bsus7': 63, 'Aj7': 26, 'C+j7': 67, 'Gm7b5': 187, 'B+': 33, 'E+': 113, 'Ebsus7': 137, 'Bb': 42, 'Ebj7': 132, 'D+j7': 83, 'Eb6': 130, 'F-j7': 151, 'G': 160, 'Ab': 10, 'G-6': 165, 'C+': 65, 'F-': 148, 'Gb7': 179, 'B': 32, 'Ab6': 18, 'A-j7': 7, 'E+j7': 115, 'E-': 116, 'Ebo': 134, 'Eb-j7': 129, 'B-7': 38, 'Bbm7b5': 53, 'G-j7': 167, 'F+': 145, 'Eo': 140, 'Gbsus7': 185, 'NC': 192, 'Bbsus7': 57, 'Ab+7': 12, 'Fsus': 158, 'Ebo7': 135, 'Esus': 142, 'Bb6': 50, 'Bbo7': 55, 'Eb': 122, 'C': 64, 'Csus': 78, 'Bb+': 43, 'Bb+7': 44, 'Ab-': 14, 'D-': 84, 'Gsus7': 191, 'Gb+7': 172, 'G+j7': 163, 'E-j7': 119, 'B6': 40, 'D7': 89, 'Dbsus': 104, 'Eb-': 126, 'Bb-7': 48, 'Gsus': 190, 'A': 0, 'F6': 152, 'C-': 68, 'Do7': 109, 'A+': 1, 'B-6': 37, 'Cj7': 74, 'Bo': 60, 'C-j7': 71, 'E-6': 117, 'Db+j7': 93, 'Bbo': 54, 'A-7': 6, 'Bb7': 51, 'D+': 81, 'Esus7': 143, 'D6': 88, 'Eb-6': 127, 'B+7': 34, 'A-6': 5, 'Db-': 94, 'Ao': 28, 'Db-6': 95, 'Bbsus': 56, 'B-': 36, 'Fo7': 157, 'Cm7b5': 75, 'E+7': 114, 'Eo7': 141, 'Gb6': 178, 'G+7': 162, 'F+7': 146, 'Gbm7b5': 181, 'Ab+': 11, 'Bbj7': 52, 'A6': 8, 'Gb-j7': 177, 'Fm7b5': 155, '<eos>': 194, 'Ebsus': 136, 'F7': 153, 'E-7': 118, 'Gb-7': 176, 'C6': 72, 'A-': 4, 'Gbo7': 183, 'Abo7': 23, 'Fo': 156, 'Db-j7': 97, 'Eb-7': 128, 'Ej7': 138, 'G-': 164, 'B-j7': 39, 'Ab-6': 15, 'Absus': 24, 'F-6': 149, 'Abo': 22, 'Bb+j7': 45, 'F-7': 150, 'Gbo': 182, 'Em7b5': 139, 'Ab-7': 16, 'C7': 73, 'B+j7': 35, 'A+j7': 3, 'Asus': 30, 'Db6': 98, 'Bb-j7': 49, 'E6': 120, 'Gb+j7': 173, 'C-7': 70, 'Bb-6': 47, 'Eb+j7': 125}\n",
      "\n",
      "Integer to chord label mapping:\n",
      " {0: 'A', 1: 'A+', 2: 'A+7', 3: 'A+j7', 4: 'A-', 5: 'A-6', 6: 'A-7', 7: 'A-j7', 8: 'A6', 9: 'A7', 10: 'Ab', 11: 'Ab+', 12: 'Ab+7', 13: 'Ab+j7', 14: 'Ab-', 15: 'Ab-6', 16: 'Ab-7', 17: 'Ab-j7', 18: 'Ab6', 19: 'Ab7', 20: 'Abj7', 21: 'Abm7b5', 22: 'Abo', 23: 'Abo7', 24: 'Absus', 25: 'Absus7', 26: 'Aj7', 27: 'Am7b5', 28: 'Ao', 29: 'Ao7', 30: 'Asus', 31: 'Asus7', 32: 'B', 33: 'B+', 34: 'B+7', 35: 'B+j7', 36: 'B-', 37: 'B-6', 38: 'B-7', 39: 'B-j7', 40: 'B6', 41: 'B7', 42: 'Bb', 43: 'Bb+', 44: 'Bb+7', 45: 'Bb+j7', 46: 'Bb-', 47: 'Bb-6', 48: 'Bb-7', 49: 'Bb-j7', 50: 'Bb6', 51: 'Bb7', 52: 'Bbj7', 53: 'Bbm7b5', 54: 'Bbo', 55: 'Bbo7', 56: 'Bbsus', 57: 'Bbsus7', 58: 'Bj7', 59: 'Bm7b5', 60: 'Bo', 61: 'Bo7', 62: 'Bsus', 63: 'Bsus7', 64: 'C', 65: 'C+', 66: 'C+7', 67: 'C+j7', 68: 'C-', 69: 'C-6', 70: 'C-7', 71: 'C-j7', 72: 'C6', 73: 'C7', 74: 'Cj7', 75: 'Cm7b5', 76: 'Co', 77: 'Co7', 78: 'Csus', 79: 'Csus7', 80: 'D', 81: 'D+', 82: 'D+7', 83: 'D+j7', 84: 'D-', 85: 'D-6', 86: 'D-7', 87: 'D-j7', 88: 'D6', 89: 'D7', 90: 'Db', 91: 'Db+', 92: 'Db+7', 93: 'Db+j7', 94: 'Db-', 95: 'Db-6', 96: 'Db-7', 97: 'Db-j7', 98: 'Db6', 99: 'Db7', 100: 'Dbj7', 101: 'Dbm7b5', 102: 'Dbo', 103: 'Dbo7', 104: 'Dbsus', 105: 'Dbsus7', 106: 'Dj7', 107: 'Dm7b5', 108: 'Do', 109: 'Do7', 110: 'Dsus', 111: 'Dsus7', 112: 'E', 113: 'E+', 114: 'E+7', 115: 'E+j7', 116: 'E-', 117: 'E-6', 118: 'E-7', 119: 'E-j7', 120: 'E6', 121: 'E7', 122: 'Eb', 123: 'Eb+', 124: 'Eb+7', 125: 'Eb+j7', 126: 'Eb-', 127: 'Eb-6', 128: 'Eb-7', 129: 'Eb-j7', 130: 'Eb6', 131: 'Eb7', 132: 'Ebj7', 133: 'Ebm7b5', 134: 'Ebo', 135: 'Ebo7', 136: 'Ebsus', 137: 'Ebsus7', 138: 'Ej7', 139: 'Em7b5', 140: 'Eo', 141: 'Eo7', 142: 'Esus', 143: 'Esus7', 144: 'F', 145: 'F+', 146: 'F+7', 147: 'F+j7', 148: 'F-', 149: 'F-6', 150: 'F-7', 151: 'F-j7', 152: 'F6', 153: 'F7', 154: 'Fj7', 155: 'Fm7b5', 156: 'Fo', 157: 'Fo7', 158: 'Fsus', 159: 'Fsus7', 160: 'G', 161: 'G+', 162: 'G+7', 163: 'G+j7', 164: 'G-', 165: 'G-6', 166: 'G-7', 167: 'G-j7', 168: 'G6', 169: 'G7', 170: 'Gb', 171: 'Gb+', 172: 'Gb+7', 173: 'Gb+j7', 174: 'Gb-', 175: 'Gb-6', 176: 'Gb-7', 177: 'Gb-j7', 178: 'Gb6', 179: 'Gb7', 180: 'Gbj7', 181: 'Gbm7b5', 182: 'Gbo', 183: 'Gbo7', 184: 'Gbsus', 185: 'Gbsus7', 186: 'Gj7', 187: 'Gm7b5', 188: 'Go', 189: 'Go7', 190: 'Gsus', 191: 'Gsus7', 192: 'NC', 193: '<bos>', 194: '<eos>'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create categorical data mappings\n",
    "note_to_int = dict([(c, i) for i, c in enumerate(unique_notes[1:])])\n",
    "note_to_int[-1] = len(note_to_int)\n",
    "note_to_int['<pad>'] = len(note_to_int)\n",
    "\n",
    "int_to_note = dict([(k, v) for v, k in note_to_int.items()])\n",
    "\n",
    "chord_to_int = dict([(c, i) for i, c in enumerate(unique_chords)])\n",
    "chord_to_int['<bos>'] = len(chord_to_int)\n",
    "chord_to_int['<eos>'] = len(chord_to_int)\n",
    "\n",
    "int_to_chord = dict([(k, v) for v, k in chord_to_int.items()])\n",
    "\n",
    "print(\"Melody note to integer mapping:\\n {}\\n\".format(note_to_int))\n",
    "print(\"Integer to melody note mapping:\\n {}\\n\".format(int_to_note))\n",
    "print(\"Chord label to integer mapping:\\n {}\\n\".format(chord_to_int))\n",
    "print(\"Integer to chord label mapping:\\n {}\\n\".format(int_to_chord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 334344\n",
      "Number of distinct melody notes: 14\n",
      "Number of distinct chord labels: 195\n",
      "Maximum length of melody sequences for one chord: 135\n",
      "Number of past chords given as input: 7\n"
     ]
    }
   ],
   "source": [
    "# Define numerical variables\n",
    "\n",
    "n_samples = len(chords)\n",
    "n_chords = len(chord_to_int)\n",
    "n_notes = len(note_to_int)\n",
    "max_mel_len = max([len(mel) for mel in notes_by_chords_bf_augmaj7])\n",
    "chord_context_len = 7\n",
    "\n",
    "# print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Number of distinct melody notes: {}\".format(n_notes))\n",
    "print(\"Number of distinct chord labels: {}\".format(n_chords))\n",
    "print(\"Maximum length of melody sequences for one chord: {}\".format(max_mel_len))\n",
    "print(\"Number of past chords given as input: {}\".format(chord_context_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [4]]\n"
     ]
    }
   ],
   "source": [
    "mel_by_sections = [mel for section in data for ch, mel in section]\n",
    "print(mel_by_sections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Remove sections with augmented major chord---\n",
      "Number of sections: 28836\n",
      "\n",
      "Sample input melody sequence: [8, 3, 6, '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "\n",
      "Sample input chord sequence: ['<bos>', '<bos>', 'E6', 'Db7', 'Gb-7', 'B7', 'E']\n",
      "\n",
      "Sample target chord: Db-7\n",
      "\n",
      "Input melody: 333480, Input chords: 333480, Target chords: 333480\n"
     ]
    }
   ],
   "source": [
    "# Prepare tensor data\n",
    "\n",
    "\n",
    "def check_if_augmented_major(section):\n",
    "    section_chords = get_chords_by_section(section)\n",
    "    for ch in section_chords:\n",
    "        if \"+j7\" in ch:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "data = [section for section in data if not check_if_augmented_major(section)]\n",
    "print(\"---Remove sections with augmented major chord---\")\n",
    "print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections = [get_chords_by_section(section) for section in data]\n",
    "# chords = [chord_info[0] for section in data for chord_info in section]\n",
    "# unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "# notes = [note for chord_notes in notes_by_chords for note in chord_notes]\n",
    "# unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "\n",
    "\n",
    "def pad_melody(melody, max_len):\n",
    "    return melody + (max_len-len(melody))*['<pad>']\n",
    "\n",
    "def build_input_chord_sequences(chord_seq, context_len):\n",
    "    padded_sequence = context_len*['<bos>'] + chord_seq\n",
    "    formatted_sequences = [padded_sequence[i:i+context_len+1] for i in range(len(chord_seq))]\n",
    "    return formatted_sequences\n",
    "\n",
    "# Melody\n",
    "input_melody_data = [pad_melody(melody, max_mel_len) for melody in notes_by_chords]\n",
    "print(\"Sample input melody sequence: {}\\n\".format(input_melody_data[5]))\n",
    "\n",
    "# Chords\n",
    "formatted_chords_data = []\n",
    "for section_chords in chords_by_sections:\n",
    "    formatted_chords_data += build_input_chord_sequences(section_chords, chord_context_len)\n",
    "    \n",
    "input_chords_data = [ch[:-1] for ch in formatted_chords_data]\n",
    "target_chords_data = [ch[-1] for ch in formatted_chords_data]\n",
    "print(\"Sample input chord sequence: {}\\n\".format(input_chords_data[5]))\n",
    "print(\"Sample target chord: {}\\n\".format(target_chords_data[5]))\n",
    "\n",
    "print(\"Input melody: {}, Input chords: {}, Target chords: {}\".format(len(input_melody_data), len(input_chords_data), len(target_chords_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 16)\n"
     ]
    }
   ],
   "source": [
    "# Load embedding vectors\n",
    "\n",
    "num_dim = 16\n",
    "num_ch = 192\n",
    "num_notes = 12\n",
    "\n",
    "# Define embedding training model and load weights\n",
    "input_layer = Input(shape=(num_ch,)) \n",
    "embeddings_layer = Dense(num_dim, activation='linear', name=\"embeddings\")(input_layer)\n",
    "root_output_layer = Dense(num_notes, activation='softmax')(embeddings_layer)\n",
    "interval_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "pitch_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "melody_output_layer = Dense(num_notes, activation='relu')(embeddings_layer)\n",
    "embeddings_model = Model(input_layer, [root_output_layer, interval_output_layer, pitch_output_layer, melody_output_layer])\n",
    "\n",
    "embeddings_model.load_weights(\"../Skipgram & WJD/weights/combined_weights_dim16.h5\")\n",
    "\n",
    "X_chords_embeddings = embeddings_model.layers[1].get_weights()[0]\n",
    "print(X_chords_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embedding vector for each chord: 16\n"
     ]
    }
   ],
   "source": [
    "# Build tensors\n",
    "\n",
    "n_dimensions = X_chords_embeddings.shape[1]\n",
    "print(\"Size of embedding vector for each chord: {}\".format(n_dimensions))\n",
    "\n",
    "X_melody = np.zeros((n_samples, max_mel_len, n_notes), dtype='float32')\n",
    "X_chords = np.zeros((n_samples, chord_context_len, n_dimensions), dtype='float32')\n",
    "Y_chord = np.zeros((n_samples, n_chords), dtype='float32')\n",
    "\n",
    "for i, (input_mel, input_ch, target_ch) in enumerate(zip(input_melody_data, input_chords_data, target_chords_data)):\n",
    "    Y_chord[i, chord_to_int[target_ch]] = 1\n",
    "    for j, chord in enumerate(input_ch):\n",
    "#         X_chords[i, j, chord_to_int[chord]] = 1\n",
    "        chord_index = chord_to_int[chord]\n",
    "        if (chord_index < num_ch):\n",
    "            X_chords[i, j, :] = X_chords_embeddings[chord_index, :]\n",
    "    \n",
    "    for j, note in enumerate(input_mel):\n",
    "        X_melody[i, j, note_to_int[note]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334344, 135, 14)\n",
      "(334344, 7, 16)\n",
      "(334344, 195)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody.shape)\n",
    "print(X_chords.shape)\n",
    "print(Y_chord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset into 80%-10%-10% train-valid-test sets\n",
    "seed = 0\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "\n",
    "for train_index, aux_index in sss.split(X_chords, Y_chord):\n",
    "    X_melody_train, X_melody_aux = X_melody[train_index], X_melody[aux_index]\n",
    "    X_chords_train, X_chords_aux = X_chords[train_index], X_chords[aux_index]\n",
    "    Y_chord_train, Y_chord_aux = Y_chord[train_index], Y_chord[aux_index]\n",
    "    \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)\n",
    "\n",
    "for valid_index, test_index in sss.split(X_chords_aux, Y_chord_aux):\n",
    "    X_melody_valid, X_melody_test = X_melody[valid_index], X_melody[test_index]\n",
    "    X_chords_valid, X_chords_test = X_chords[valid_index], X_chords[test_index]\n",
    "    Y_chord_valid, Y_chord_test = Y_chord[valid_index], Y_chord[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 135, 14)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 7, 16)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_3 (GRU)                      (None, 128)           54912       input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      (None, 128)           55680       input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 256)           0           gru_3[0][0]                      \n",
      "                                                                   gru_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 195)           50115       concatenate_2[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 160,707\n",
      "Trainable params: 160,707\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"264pt\" viewBox=\"0.00 0.00 276.00 264.00\" width=\"276pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-260 272,-260 272,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139685442047392 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139685442047392</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 125,-255.5 125,-219.5 0,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-233.8\">input_4: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139685442047448 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139685442047448</title>\n",
       "<polygon fill=\"none\" points=\"30.5,-146.5 30.5,-182.5 114.5,-182.5 114.5,-146.5 30.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"72.5\" y=\"-160.8\">gru_3: GRU</text>\n",
       "</g>\n",
       "<!-- 139685442047392&#45;&gt;139685442047448 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139685442047392-&gt;139685442047448</title>\n",
       "<path d=\"M64.9207,-219.313C66.0508,-211.289 67.4229,-201.547 68.6874,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"72.1726,-192.919 70.1016,-182.529 65.241,-191.943 72.1726,-192.919\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139685442047560 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139685442047560</title>\n",
       "<polygon fill=\"none\" points=\"143,-219.5 143,-255.5 268,-255.5 268,-219.5 143,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-233.8\">input_5: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139685437432552 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139685437432552</title>\n",
       "<polygon fill=\"none\" points=\"152.5,-146.5 152.5,-182.5 236.5,-182.5 236.5,-146.5 152.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-160.8\">gru_4: GRU</text>\n",
       "</g>\n",
       "<!-- 139685442047560&#45;&gt;139685437432552 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139685442047560-&gt;139685437432552</title>\n",
       "<path d=\"M202.837,-219.313C201.594,-211.289 200.085,-201.547 198.694,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"202.128,-191.875 197.138,-182.529 195.211,-192.947 202.128,-191.875\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139685437435464 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139685437435464</title>\n",
       "<polygon fill=\"none\" points=\"49.5,-73.5 49.5,-109.5 217.5,-109.5 217.5,-73.5 49.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.5\" y=\"-87.8\">concatenate_2: Concatenate</text>\n",
       "</g>\n",
       "<!-- 139685442047448&#45;&gt;139685437435464 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139685442047448-&gt;139685437435464</title>\n",
       "<path d=\"M87.2664,-146.313C94.7591,-137.592 103.996,-126.84 112.239,-117.246\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"115.008,-119.395 118.87,-109.529 109.698,-114.833 115.008,-119.395\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139685437432552&#45;&gt;139685437435464 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139685437432552-&gt;139685437435464</title>\n",
       "<path d=\"M179.734,-146.313C172.241,-137.592 163.004,-126.84 154.761,-117.246\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"157.302,-114.833 148.13,-109.529 151.992,-119.395 157.302,-114.833\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139685426183976 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139685426183976</title>\n",
       "<polygon fill=\"none\" points=\"82.5,-0.5 82.5,-36.5 184.5,-36.5 184.5,-0.5 82.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.5\" y=\"-14.8\">dense_6: Dense</text>\n",
       "</g>\n",
       "<!-- 139685437435464&#45;&gt;139685426183976 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139685437435464-&gt;139685426183976</title>\n",
       "<path d=\"M133.5,-73.3129C133.5,-65.2895 133.5,-55.5475 133.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"137,-46.5288 133.5,-36.5288 130,-46.5289 137,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define neual net architecture\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "melody_input = Input(shape=(max_mel_len, n_notes))\n",
    "melody_gru = GRU(latent_dim)(melody_input)\n",
    "\n",
    "chords_input = Input(shape=(chord_context_len, n_dimensions))\n",
    "chords_gru = GRU(latent_dim)(chords_input)\n",
    "\n",
    "concat = concatenate([melody_gru, chords_gru])\n",
    "\n",
    "chord_dense = Dense(n_chords, activation='softmax')(concat)\n",
    "\n",
    "model = Model([melody_input, chords_input], chord_dense)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Introduce Best-Performance callbacks\n",
    "# es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "filepath = \"models/embeddings16-Mel1-Cho1-FC1_150ep.h5\"\n",
    "bp = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267475 samples, validate on 33434 samples\n",
      "Epoch 1/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.9542 - acc: 0.3420Epoch 00000: val_acc improved from -inf to 0.41129, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 430s - loss: 2.9539 - acc: 0.3420 - val_loss: 2.6111 - val_acc: 0.4113\n",
      "Epoch 2/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.3965 - acc: 0.4422Epoch 00001: val_acc improved from 0.41129 to 0.47509, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 2.3963 - acc: 0.4422 - val_loss: 2.2398 - val_acc: 0.4751\n",
      "Epoch 3/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 2.0743 - acc: 0.4998Epoch 00002: val_acc improved from 0.47509 to 0.52043, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 2.0742 - acc: 0.4998 - val_loss: 2.0386 - val_acc: 0.5204\n",
      "Epoch 4/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.8969 - acc: 0.5373Epoch 00003: val_acc improved from 0.52043 to 0.54815, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 1.8967 - acc: 0.5373 - val_loss: 1.9247 - val_acc: 0.5482\n",
      "Epoch 5/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.7707 - acc: 0.5664Epoch 00004: val_acc improved from 0.54815 to 0.56556, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 1.7706 - acc: 0.5664 - val_loss: 1.8529 - val_acc: 0.5656\n",
      "Epoch 6/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.6696 - acc: 0.5904Epoch 00005: val_acc improved from 0.56556 to 0.58043, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 1.6697 - acc: 0.5904 - val_loss: 1.7785 - val_acc: 0.5804\n",
      "Epoch 7/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.5920 - acc: 0.6091Epoch 00006: val_acc improved from 0.58043 to 0.59149, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 1.5919 - acc: 0.6092 - val_loss: 1.7290 - val_acc: 0.5915\n",
      "Epoch 8/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.5243 - acc: 0.6251Epoch 00007: val_acc improved from 0.59149 to 0.59900, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 1.5243 - acc: 0.6251 - val_loss: 1.6934 - val_acc: 0.5990\n",
      "Epoch 9/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.4698 - acc: 0.6383Epoch 00008: val_acc improved from 0.59900 to 0.60591, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 1.4698 - acc: 0.6383 - val_loss: 1.6626 - val_acc: 0.6059\n",
      "Epoch 10/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.4243 - acc: 0.6487Epoch 00009: val_acc improved from 0.60591 to 0.61608, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 1.4244 - acc: 0.6487 - val_loss: 1.6297 - val_acc: 0.6161\n",
      "Epoch 11/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.3824 - acc: 0.6582Epoch 00010: val_acc improved from 0.61608 to 0.62119, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 1.3823 - acc: 0.6583 - val_loss: 1.6067 - val_acc: 0.6212\n",
      "Epoch 12/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.3453 - acc: 0.6669Epoch 00011: val_acc improved from 0.62119 to 0.62619, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 1.3454 - acc: 0.6669 - val_loss: 1.5964 - val_acc: 0.6262\n",
      "Epoch 13/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.3151 - acc: 0.6736Epoch 00012: val_acc improved from 0.62619 to 0.63059, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 435s - loss: 1.3150 - acc: 0.6736 - val_loss: 1.5808 - val_acc: 0.6306\n",
      "Epoch 14/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2836 - acc: 0.6816Epoch 00013: val_acc improved from 0.63059 to 0.63202, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 1.2833 - acc: 0.6816 - val_loss: 1.5669 - val_acc: 0.6320\n",
      "Epoch 15/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2573 - acc: 0.6870Epoch 00014: val_acc improved from 0.63202 to 0.63669, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 1.2573 - acc: 0.6870 - val_loss: 1.5537 - val_acc: 0.6367\n",
      "Epoch 16/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2342 - acc: 0.6924Epoch 00015: val_acc improved from 0.63669 to 0.64120, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 1.2342 - acc: 0.6924 - val_loss: 1.5495 - val_acc: 0.6412\n",
      "Epoch 17/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.2124 - acc: 0.6974Epoch 00016: val_acc improved from 0.64120 to 0.64467, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 435s - loss: 1.2125 - acc: 0.6974 - val_loss: 1.5295 - val_acc: 0.6447\n",
      "Epoch 18/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1898 - acc: 0.7022Epoch 00017: val_acc improved from 0.64467 to 0.64778, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 435s - loss: 1.1898 - acc: 0.7021 - val_loss: 1.5200 - val_acc: 0.6478\n",
      "Epoch 19/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1710 - acc: 0.7076Epoch 00018: val_acc improved from 0.64778 to 0.64805, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 1.1711 - acc: 0.7076 - val_loss: 1.5121 - val_acc: 0.6481\n",
      "Epoch 20/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1566 - acc: 0.7093Epoch 00019: val_acc improved from 0.64805 to 0.64904, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 1.1566 - acc: 0.7093 - val_loss: 1.5070 - val_acc: 0.6490\n",
      "Epoch 21/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1363 - acc: 0.7144Epoch 00020: val_acc improved from 0.64904 to 0.65257, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 1.1363 - acc: 0.7144 - val_loss: 1.4998 - val_acc: 0.6526\n",
      "Epoch 22/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1226 - acc: 0.7170Epoch 00021: val_acc improved from 0.65257 to 0.65762, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 1.1226 - acc: 0.7170 - val_loss: 1.4954 - val_acc: 0.6576\n",
      "Epoch 23/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.1097 - acc: 0.7197Epoch 00022: val_acc did not improve\n",
      "267475/267475 [==============================] - 435s - loss: 1.1097 - acc: 0.7197 - val_loss: 1.5061 - val_acc: 0.6527\n",
      "Epoch 24/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0988 - acc: 0.7221Epoch 00023: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 1.0987 - acc: 0.7222 - val_loss: 1.4993 - val_acc: 0.6546\n",
      "Epoch 25/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0872 - acc: 0.7245Epoch 00024: val_acc improved from 0.65762 to 0.65963, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 1.0871 - acc: 0.7245 - val_loss: 1.4884 - val_acc: 0.6596\n",
      "Epoch 26/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0709 - acc: 0.7285Epoch 00025: val_acc improved from 0.65963 to 0.66011, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 1.0709 - acc: 0.7285 - val_loss: 1.4888 - val_acc: 0.6601\n",
      "Epoch 27/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0595 - acc: 0.7307Epoch 00026: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 1.0596 - acc: 0.7306 - val_loss: 1.4801 - val_acc: 0.6599\n",
      "Epoch 28/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0553 - acc: 0.7310Epoch 00027: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 1.0553 - acc: 0.7310 - val_loss: 1.4963 - val_acc: 0.6565\n",
      "Epoch 29/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0580 - acc: 0.7302Epoch 00028: val_acc improved from 0.66011 to 0.66199, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 1.0579 - acc: 0.7302 - val_loss: 1.4686 - val_acc: 0.6620\n",
      "Epoch 30/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0386 - acc: 0.7354Epoch 00029: val_acc improved from 0.66199 to 0.66627, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 1.0386 - acc: 0.7354 - val_loss: 1.4710 - val_acc: 0.6663\n",
      "Epoch 31/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0404 - acc: 0.7348Epoch 00030: val_acc improved from 0.66627 to 0.66651, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 1.0405 - acc: 0.7348 - val_loss: 1.4782 - val_acc: 0.6665\n",
      "Epoch 32/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0227 - acc: 0.7379Epoch 00031: val_acc improved from 0.66651 to 0.66818, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 432s - loss: 1.0226 - acc: 0.7380 - val_loss: 1.4649 - val_acc: 0.6682\n",
      "Epoch 33/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0128 - acc: 0.7403Epoch 00032: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 1.0128 - acc: 0.7403 - val_loss: 1.4725 - val_acc: 0.6667\n",
      "Epoch 34/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0149 - acc: 0.7394Epoch 00033: val_acc did not improve\n",
      "267475/267475 [==============================] - 435s - loss: 1.0150 - acc: 0.7394 - val_loss: 1.4931 - val_acc: 0.6599\n",
      "Epoch 35/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 1.0136 - acc: 0.7392Epoch 00034: val_acc improved from 0.66818 to 0.67078, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 435s - loss: 1.0137 - acc: 0.7392 - val_loss: 1.4601 - val_acc: 0.6708\n",
      "Epoch 36/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9985 - acc: 0.7431Epoch 00035: val_acc improved from 0.67078 to 0.67473, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 0.9982 - acc: 0.7431 - val_loss: 1.4609 - val_acc: 0.6747\n",
      "Epoch 37/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9852 - acc: 0.7468Epoch 00036: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.9850 - acc: 0.7469 - val_loss: 1.4535 - val_acc: 0.6732\n",
      "Epoch 38/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9767 - acc: 0.7485Epoch 00037: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.9767 - acc: 0.7485 - val_loss: 1.4597 - val_acc: 0.6734\n",
      "Epoch 39/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9782 - acc: 0.7475Epoch 00038: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.9784 - acc: 0.7475 - val_loss: 1.4557 - val_acc: 0.6742\n",
      "Epoch 40/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9706 - acc: 0.7489Epoch 00039: val_acc improved from 0.67473 to 0.67476, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 0.9706 - acc: 0.7489 - val_loss: 1.4571 - val_acc: 0.6748\n",
      "Epoch 41/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9651 - acc: 0.7506Epoch 00040: val_acc improved from 0.67476 to 0.67521, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 432s - loss: 0.9650 - acc: 0.7506 - val_loss: 1.4626 - val_acc: 0.6752\n",
      "Epoch 42/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9641 - acc: 0.7505Epoch 00041: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.9641 - acc: 0.7504 - val_loss: 1.4621 - val_acc: 0.6724\n",
      "Epoch 43/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9713 - acc: 0.7476Epoch 00042: val_acc did not improve\n",
      "267475/267475 [==============================] - 435s - loss: 0.9713 - acc: 0.7476 - val_loss: 1.4921 - val_acc: 0.6641\n",
      "Epoch 44/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9580 - acc: 0.7509Epoch 00043: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.9583 - acc: 0.7509 - val_loss: 1.4541 - val_acc: 0.6728\n",
      "Epoch 45/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9530 - acc: 0.7527Epoch 00044: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.9530 - acc: 0.7527 - val_loss: 1.4636 - val_acc: 0.6715\n",
      "Epoch 46/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9626 - acc: 0.7501Epoch 00045: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.9627 - acc: 0.7500 - val_loss: 1.4654 - val_acc: 0.6714\n",
      "Epoch 47/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9416 - acc: 0.7549Epoch 00046: val_acc improved from 0.67521 to 0.67608, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 432s - loss: 0.9416 - acc: 0.7549 - val_loss: 1.4600 - val_acc: 0.6761\n",
      "Epoch 48/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9459 - acc: 0.7533Epoch 00047: val_acc improved from 0.67608 to 0.67814, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 432s - loss: 0.9460 - acc: 0.7533 - val_loss: 1.4482 - val_acc: 0.6781\n",
      "Epoch 49/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9364 - acc: 0.7558Epoch 00048: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.9365 - acc: 0.7558 - val_loss: 1.4453 - val_acc: 0.6770\n",
      "Epoch 50/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9349 - acc: 0.7563Epoch 00049: val_acc improved from 0.67814 to 0.68039, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 432s - loss: 0.9349 - acc: 0.7563 - val_loss: 1.4498 - val_acc: 0.6804\n",
      "Epoch 51/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9442 - acc: 0.7528Epoch 00050: val_acc did not improve\n",
      "267475/267475 [==============================] - 435s - loss: 0.9442 - acc: 0.7528 - val_loss: 1.4524 - val_acc: 0.6774\n",
      "Epoch 52/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9225 - acc: 0.7594Epoch 00051: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.9226 - acc: 0.7593 - val_loss: 1.4521 - val_acc: 0.6790\n",
      "Epoch 53/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9212 - acc: 0.7587Epoch 00052: val_acc improved from 0.68039 to 0.68176, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 434s - loss: 0.9212 - acc: 0.7587 - val_loss: 1.4392 - val_acc: 0.6818\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9195 - acc: 0.7594Epoch 00053: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.9195 - acc: 0.7594 - val_loss: 1.4576 - val_acc: 0.6776\n",
      "Epoch 55/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9115 - acc: 0.7609Epoch 00054: val_acc improved from 0.68176 to 0.68191, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 0.9114 - acc: 0.7609 - val_loss: 1.4398 - val_acc: 0.6819\n",
      "Epoch 56/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9184 - acc: 0.7584Epoch 00055: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.9186 - acc: 0.7584 - val_loss: 1.4616 - val_acc: 0.6751\n",
      "Epoch 57/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9137 - acc: 0.7600Epoch 00056: val_acc improved from 0.68191 to 0.68394, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 0.9137 - acc: 0.7600 - val_loss: 1.4400 - val_acc: 0.6839\n",
      "Epoch 58/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9074 - acc: 0.7609Epoch 00057: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.9074 - acc: 0.7609 - val_loss: 1.4431 - val_acc: 0.6796\n",
      "Epoch 59/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8971 - acc: 0.7639Epoch 00058: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8972 - acc: 0.7639 - val_loss: 1.4515 - val_acc: 0.6810\n",
      "Epoch 60/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9018 - acc: 0.7630Epoch 00059: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.9019 - acc: 0.7630 - val_loss: 1.4553 - val_acc: 0.6800\n",
      "Epoch 61/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8888 - acc: 0.7662Epoch 00060: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8887 - acc: 0.7663 - val_loss: 1.4525 - val_acc: 0.6780\n",
      "Epoch 62/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8901 - acc: 0.7656Epoch 00061: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8901 - acc: 0.7656 - val_loss: 1.4555 - val_acc: 0.6817\n",
      "Epoch 63/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.9093 - acc: 0.7599Epoch 00062: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.9092 - acc: 0.7599 - val_loss: 1.4547 - val_acc: 0.6816\n",
      "Epoch 64/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8961 - acc: 0.7633Epoch 00063: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8960 - acc: 0.7634 - val_loss: 1.4513 - val_acc: 0.6821\n",
      "Epoch 65/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8868 - acc: 0.7660Epoch 00064: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8868 - acc: 0.7660 - val_loss: 1.4494 - val_acc: 0.6832\n",
      "Epoch 66/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8903 - acc: 0.7647Epoch 00065: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8904 - acc: 0.7647 - val_loss: 1.4445 - val_acc: 0.6835\n",
      "Epoch 67/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8804 - acc: 0.7668Epoch 00066: val_acc did not improve\n",
      "267475/267475 [==============================] - 428s - loss: 0.8806 - acc: 0.7667 - val_loss: 1.4590 - val_acc: 0.6817\n",
      "Epoch 68/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8757 - acc: 0.7685Epoch 00067: val_acc improved from 0.68394 to 0.68562, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 430s - loss: 0.8756 - acc: 0.7686 - val_loss: 1.4391 - val_acc: 0.6856\n",
      "Epoch 69/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8652 - acc: 0.7711Epoch 00068: val_acc improved from 0.68562 to 0.68768, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 430s - loss: 0.8652 - acc: 0.7711 - val_loss: 1.4418 - val_acc: 0.6877\n",
      "Epoch 70/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8737 - acc: 0.7685Epoch 00069: val_acc did not improve\n",
      "267475/267475 [==============================] - 431s - loss: 0.8737 - acc: 0.7686 - val_loss: 1.4474 - val_acc: 0.6864\n",
      "Epoch 71/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8866 - acc: 0.7648Epoch 00070: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8866 - acc: 0.7648 - val_loss: 1.4545 - val_acc: 0.6830\n",
      "Epoch 72/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8883 - acc: 0.7641Epoch 00071: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8882 - acc: 0.7641 - val_loss: 1.4881 - val_acc: 0.6742\n",
      "Epoch 73/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8908 - acc: 0.7631Epoch 00072: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8909 - acc: 0.7631 - val_loss: 1.4502 - val_acc: 0.6843\n",
      "Epoch 74/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8695 - acc: 0.7694Epoch 00073: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8697 - acc: 0.7694 - val_loss: 1.4530 - val_acc: 0.6833\n",
      "Epoch 75/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8714 - acc: 0.7686Epoch 00074: val_acc improved from 0.68768 to 0.68792, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 433s - loss: 0.8713 - acc: 0.7686 - val_loss: 1.4398 - val_acc: 0.6879\n",
      "Epoch 76/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8730 - acc: 0.7676Epoch 00075: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8729 - acc: 0.7676 - val_loss: 1.4437 - val_acc: 0.6868\n",
      "Epoch 77/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8627 - acc: 0.7708Epoch 00076: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8627 - acc: 0.7708 - val_loss: 1.4575 - val_acc: 0.6817\n",
      "Epoch 78/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8569 - acc: 0.7717Epoch 00077: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8567 - acc: 0.7717 - val_loss: 1.4481 - val_acc: 0.6865\n",
      "Epoch 79/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8547 - acc: 0.7720Epoch 00078: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8546 - acc: 0.7720 - val_loss: 1.4442 - val_acc: 0.6849\n",
      "Epoch 80/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8686 - acc: 0.7686Epoch 00079: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8686 - acc: 0.7686 - val_loss: 1.4525 - val_acc: 0.6859\n",
      "Epoch 81/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8713 - acc: 0.7678Epoch 00080: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8713 - acc: 0.7678 - val_loss: 1.4632 - val_acc: 0.6821\n",
      "Epoch 82/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8721 - acc: 0.7669Epoch 00081: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8721 - acc: 0.7669 - val_loss: 1.4490 - val_acc: 0.6870\n",
      "Epoch 83/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8681 - acc: 0.7690Epoch 00082: val_acc did not improve\n",
      "267475/267475 [==============================] - 430s - loss: 0.8683 - acc: 0.7689 - val_loss: 1.4499 - val_acc: 0.6852\n",
      "Epoch 84/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8670 - acc: 0.7686Epoch 00083: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 429s - loss: 0.8671 - acc: 0.7686 - val_loss: 1.4679 - val_acc: 0.6804\n",
      "Epoch 85/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8842 - acc: 0.7641Epoch 00084: val_acc did not improve\n",
      "267475/267475 [==============================] - 430s - loss: 0.8841 - acc: 0.7641 - val_loss: 1.4669 - val_acc: 0.6799\n",
      "Epoch 86/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8946 - acc: 0.7610Epoch 00085: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8947 - acc: 0.7610 - val_loss: 1.4641 - val_acc: 0.6817\n",
      "Epoch 87/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8777 - acc: 0.7665Epoch 00086: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8777 - acc: 0.7664 - val_loss: 1.4465 - val_acc: 0.6867\n",
      "Epoch 88/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8643 - acc: 0.7686Epoch 00087: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8644 - acc: 0.7686 - val_loss: 1.4596 - val_acc: 0.6843\n",
      "Epoch 89/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8589 - acc: 0.7697Epoch 00088: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8589 - acc: 0.7697 - val_loss: 1.4524 - val_acc: 0.6855\n",
      "Epoch 90/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8611 - acc: 0.7695Epoch 00089: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8613 - acc: 0.7695 - val_loss: 1.4565 - val_acc: 0.6844\n",
      "Epoch 91/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8603 - acc: 0.7702Epoch 00090: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8603 - acc: 0.7702 - val_loss: 1.4700 - val_acc: 0.6800\n",
      "Epoch 92/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8679 - acc: 0.7670Epoch 00091: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8678 - acc: 0.7670 - val_loss: 1.4672 - val_acc: 0.6849\n",
      "Epoch 93/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8653 - acc: 0.7678Epoch 00092: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8652 - acc: 0.7678 - val_loss: 1.4513 - val_acc: 0.6831\n",
      "Epoch 94/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8624 - acc: 0.7689Epoch 00093: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8625 - acc: 0.7689 - val_loss: 1.4528 - val_acc: 0.6853\n",
      "Epoch 95/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8534 - acc: 0.7705Epoch 00094: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8533 - acc: 0.7705 - val_loss: 1.4548 - val_acc: 0.6876\n",
      "Epoch 96/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8444 - acc: 0.7732Epoch 00095: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8443 - acc: 0.7732 - val_loss: 1.4562 - val_acc: 0.6842\n",
      "Epoch 97/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8490 - acc: 0.7717Epoch 00096: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8489 - acc: 0.7717 - val_loss: 1.4575 - val_acc: 0.6857\n",
      "Epoch 98/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8428 - acc: 0.7737Epoch 00097: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8428 - acc: 0.7737 - val_loss: 1.4620 - val_acc: 0.6832\n",
      "Epoch 99/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8802 - acc: 0.7640Epoch 00098: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8802 - acc: 0.7639 - val_loss: 1.4729 - val_acc: 0.6804\n",
      "Epoch 100/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8620 - acc: 0.7687Epoch 00099: val_acc did not improve\n",
      "267475/267475 [==============================] - 430s - loss: 0.8621 - acc: 0.7687 - val_loss: 1.4489 - val_acc: 0.6875\n",
      "Epoch 101/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8524 - acc: 0.7712Epoch 00100: val_acc did not improve\n",
      "267475/267475 [==============================] - 431s - loss: 0.8524 - acc: 0.7712 - val_loss: 1.4702 - val_acc: 0.6841\n",
      "Epoch 102/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8520 - acc: 0.7708Epoch 00101: val_acc improved from 0.68792 to 0.68912, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 432s - loss: 0.8521 - acc: 0.7707 - val_loss: 1.4551 - val_acc: 0.6891\n",
      "Epoch 103/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8357 - acc: 0.7748Epoch 00102: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8357 - acc: 0.7748 - val_loss: 1.4510 - val_acc: 0.6882\n",
      "Epoch 104/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8461 - acc: 0.7720Epoch 00103: val_acc did not improve\n",
      "267475/267475 [==============================] - 431s - loss: 0.8462 - acc: 0.7720 - val_loss: 1.4674 - val_acc: 0.6846\n",
      "Epoch 105/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8561 - acc: 0.7699Epoch 00104: val_acc did not improve\n",
      "267475/267475 [==============================] - 431s - loss: 0.8563 - acc: 0.7699 - val_loss: 1.4834 - val_acc: 0.6784\n",
      "Epoch 106/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8499 - acc: 0.7712Epoch 00105: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8499 - acc: 0.7712 - val_loss: 1.4618 - val_acc: 0.6855\n",
      "Epoch 107/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8502 - acc: 0.7710Epoch 00106: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8502 - acc: 0.7710 - val_loss: 1.4694 - val_acc: 0.6832\n",
      "Epoch 108/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8423 - acc: 0.7730Epoch 00107: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8424 - acc: 0.7729 - val_loss: 1.4751 - val_acc: 0.6813\n",
      "Epoch 109/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8532 - acc: 0.7697Epoch 00108: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8532 - acc: 0.7697 - val_loss: 1.4624 - val_acc: 0.6868\n",
      "Epoch 110/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8475 - acc: 0.7718Epoch 00109: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8476 - acc: 0.7718 - val_loss: 1.4913 - val_acc: 0.6780\n",
      "Epoch 111/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8583 - acc: 0.7677Epoch 00110: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8584 - acc: 0.7676 - val_loss: 1.4658 - val_acc: 0.6875\n",
      "Epoch 112/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8455 - acc: 0.7712Epoch 00111: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8457 - acc: 0.7711 - val_loss: 1.4639 - val_acc: 0.6830\n",
      "Epoch 113/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8414 - acc: 0.7732Epoch 00112: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8415 - acc: 0.7732 - val_loss: 1.4532 - val_acc: 0.6891\n",
      "Epoch 114/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8455 - acc: 0.7711Epoch 00113: val_acc did not improve\n",
      "267475/267475 [==============================] - 435s - loss: 0.8455 - acc: 0.7711 - val_loss: 1.4743 - val_acc: 0.6827\n",
      "Epoch 115/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8392 - acc: 0.7738Epoch 00114: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8391 - acc: 0.7737 - val_loss: 1.4520 - val_acc: 0.6891\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8392 - acc: 0.7733Epoch 00115: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8393 - acc: 0.7733 - val_loss: 1.4788 - val_acc: 0.6821\n",
      "Epoch 117/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8459 - acc: 0.7711Epoch 00116: val_acc did not improve\n",
      "267475/267475 [==============================] - 429s - loss: 0.8460 - acc: 0.7711 - val_loss: 1.4507 - val_acc: 0.6890\n",
      "Epoch 118/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8273 - acc: 0.7762Epoch 00117: val_acc did not improve\n",
      "267475/267475 [==============================] - 430s - loss: 0.8274 - acc: 0.7762 - val_loss: 1.4788 - val_acc: 0.6832\n",
      "Epoch 119/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8355 - acc: 0.7740Epoch 00118: val_acc did not improve\n",
      "267475/267475 [==============================] - 430s - loss: 0.8354 - acc: 0.7740 - val_loss: 1.4567 - val_acc: 0.6869\n",
      "Epoch 120/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8533 - acc: 0.7688Epoch 00119: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8535 - acc: 0.7688 - val_loss: 1.4792 - val_acc: 0.6829\n",
      "Epoch 121/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8360 - acc: 0.7734Epoch 00120: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8360 - acc: 0.7734 - val_loss: 1.4590 - val_acc: 0.6854\n",
      "Epoch 122/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8338 - acc: 0.7743Epoch 00121: val_acc improved from 0.68912 to 0.68954, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 432s - loss: 0.8337 - acc: 0.7743 - val_loss: 1.4507 - val_acc: 0.6895\n",
      "Epoch 123/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8297 - acc: 0.7759Epoch 00122: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8296 - acc: 0.7759 - val_loss: 1.4561 - val_acc: 0.6872\n",
      "Epoch 124/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8219 - acc: 0.7772Epoch 00123: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8219 - acc: 0.7772 - val_loss: 1.4529 - val_acc: 0.6891\n",
      "Epoch 125/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8292 - acc: 0.7741Epoch 00124: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8291 - acc: 0.7741 - val_loss: 1.4717 - val_acc: 0.6840\n",
      "Epoch 126/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8380 - acc: 0.7732Epoch 00125: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8380 - acc: 0.7732 - val_loss: 1.4726 - val_acc: 0.6837\n",
      "Epoch 127/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8267 - acc: 0.7755Epoch 00126: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8269 - acc: 0.7754 - val_loss: 1.4648 - val_acc: 0.6845\n",
      "Epoch 128/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8329 - acc: 0.7744Epoch 00127: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8332 - acc: 0.7743 - val_loss: 1.4794 - val_acc: 0.6839\n",
      "Epoch 129/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8394 - acc: 0.7726Epoch 00128: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8394 - acc: 0.7727 - val_loss: 1.4699 - val_acc: 0.6863\n",
      "Epoch 130/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8326 - acc: 0.7745Epoch 00129: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8327 - acc: 0.7745 - val_loss: 1.5424 - val_acc: 0.6681\n",
      "Epoch 131/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8665 - acc: 0.7661Epoch 00130: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8665 - acc: 0.7661 - val_loss: 1.4819 - val_acc: 0.6836\n",
      "Epoch 132/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8500 - acc: 0.7701Epoch 00131: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8502 - acc: 0.7700 - val_loss: 1.4722 - val_acc: 0.6843\n",
      "Epoch 133/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8309 - acc: 0.7759Epoch 00132: val_acc did not improve\n",
      "267475/267475 [==============================] - 431s - loss: 0.8309 - acc: 0.7759 - val_loss: 1.4684 - val_acc: 0.6849\n",
      "Epoch 134/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8363 - acc: 0.7728Epoch 00133: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8364 - acc: 0.7728 - val_loss: 1.5012 - val_acc: 0.6767\n",
      "Epoch 135/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8489 - acc: 0.7702Epoch 00134: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8488 - acc: 0.7702 - val_loss: 1.4880 - val_acc: 0.6833\n",
      "Epoch 136/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8313 - acc: 0.7745Epoch 00135: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8312 - acc: 0.7744 - val_loss: 1.4567 - val_acc: 0.6884\n",
      "Epoch 137/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8227 - acc: 0.7764Epoch 00136: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8228 - acc: 0.7764 - val_loss: 1.4681 - val_acc: 0.6860\n",
      "Epoch 138/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8266 - acc: 0.7751Epoch 00137: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8268 - acc: 0.7750 - val_loss: 1.4787 - val_acc: 0.6850\n",
      "Epoch 139/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8351 - acc: 0.7726Epoch 00138: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8352 - acc: 0.7726 - val_loss: 1.4728 - val_acc: 0.6846\n",
      "Epoch 140/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8883 - acc: 0.7592Epoch 00139: val_acc did not improve\n",
      "267475/267475 [==============================] - 431s - loss: 0.8883 - acc: 0.7592 - val_loss: 1.4901 - val_acc: 0.6795\n",
      "Epoch 141/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8622 - acc: 0.7659Epoch 00140: val_acc did not improve\n",
      "267475/267475 [==============================] - 431s - loss: 0.8622 - acc: 0.7659 - val_loss: 1.4798 - val_acc: 0.6833\n",
      "Epoch 142/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8484 - acc: 0.7701Epoch 00141: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8482 - acc: 0.7702 - val_loss: 1.4674 - val_acc: 0.6857\n",
      "Epoch 143/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8400 - acc: 0.7723Epoch 00142: val_acc did not improve\n",
      "267475/267475 [==============================] - 434s - loss: 0.8399 - acc: 0.7723 - val_loss: 1.4628 - val_acc: 0.6851\n",
      "Epoch 144/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8340 - acc: 0.7737Epoch 00143: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8341 - acc: 0.7737 - val_loss: 1.4673 - val_acc: 0.6835\n",
      "Epoch 145/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8325 - acc: 0.7738Epoch 00144: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8324 - acc: 0.7737 - val_loss: 1.4676 - val_acc: 0.6891\n",
      "Epoch 146/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8315 - acc: 0.7741Epoch 00145: val_acc did not improve\n",
      "267475/267475 [==============================] - 433s - loss: 0.8316 - acc: 0.7741 - val_loss: 1.4715 - val_acc: 0.6850\n",
      "Epoch 147/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8335 - acc: 0.7738Epoch 00146: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267475/267475 [==============================] - 432s - loss: 0.8335 - acc: 0.7738 - val_loss: 1.4655 - val_acc: 0.6892\n",
      "Epoch 148/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8247 - acc: 0.7759Epoch 00147: val_acc improved from 0.68954 to 0.69023, saving model to models/embeddings16-Mel1-Cho1-FC1_150ep.h5\n",
      "267475/267475 [==============================] - 432s - loss: 0.8247 - acc: 0.7759 - val_loss: 1.4602 - val_acc: 0.6902\n",
      "Epoch 149/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8406 - acc: 0.7720Epoch 00148: val_acc did not improve\n",
      "267475/267475 [==============================] - 432s - loss: 0.8407 - acc: 0.7719 - val_loss: 1.4716 - val_acc: 0.6866\n",
      "Epoch 150/150\n",
      "267264/267475 [============================>.] - ETA: 0s - loss: 0.8298 - acc: 0.7740Epoch 00149: val_acc did not improve\n",
      "267475/267475 [==============================] - 435s - loss: 0.8297 - acc: 0.7740 - val_loss: 1.4687 - val_acc: 0.6861\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 256\n",
    "epochs = 150\n",
    "\n",
    "history = model.fit([X_melody_train, X_chords_train], Y_chord_train, epochs=epochs, validation_data=([X_melody_valid, X_chords_valid], Y_chord_valid), batch_size=batch_size, callbacks=[bp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b05e72e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFkCAYAAADWs8tQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREREBjw1MERERERERERkwPv/JB6Ja4+GoOcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b05e6b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize model learning\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Training history of root model\", fontsize=16)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load best performance model\n",
    "best_model = load_model(\"models/embeddings16-Mel1-Cho1-FC1_150ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33435, 135, 14)\n",
      "(33434, 7, 16)\n"
     ]
    }
   ],
   "source": [
    "print(X_melody_test.shape)\n",
    "print(X_chords_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord prediction: 0.6837\n",
      "Kappa score of combined chord prediction: 0.6758\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of labels\n",
    "\n",
    "# Predict chords from each test sample melody\n",
    "Y_chord_pred = model.predict([X_melody_test, X_chords_test])\n",
    "\n",
    "# Compute accuracy and kappa score \n",
    "print(\"Categorical accuracy of combined chord prediction: {0:.4f}\".format(harmoutil.compute_accuracy_score(Y_chord_test, Y_chord_pred)))\n",
    "print(\"Kappa score of combined chord prediction: {0:.4f}\".format(harmoutil.compute_kappa_score(Y_chord_test, Y_chord_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord pitch prediction: 0.8885\n",
      "TP: 108290 TN: 248211 FP: 22556 FN: 22163\n",
      "Kappa score of combined chord pitch prediction: 0.7462\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of pitches\n",
    "\n",
    "def label_to_pitch_tensors(predictions):\n",
    "    predicted_chords = [int_to_chord[np.argmax(ch)] for ch in predictions]\n",
    "    pitch_chords = [harmoutil.chord_to_notes(label) for label in predicted_chords]\n",
    "    \n",
    "    Y_pitches = np.zeros((predictions.shape[0], 12), dtype='float32')\n",
    "    for i, chord_pitches in enumerate(pitch_chords):\n",
    "        for j, pitch_presence in enumerate(chord_pitches):\n",
    "            Y_pitches[i, j] = pitch_presence\n",
    "\n",
    "    return Y_pitches\n",
    "\n",
    "Y_pitch_pred = label_to_pitch_tensors(Y_chord_pred)\n",
    "Y_pitch_test = label_to_pitch_tensors(Y_chord_test)\n",
    "\n",
    "print(\"Categorical accuracy of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_accuracy_score(Y_pitch_test, Y_pitch_pred)))\n",
    "print(\"Kappa score of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_kappa_score(Y_pitch_test, Y_pitch_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
