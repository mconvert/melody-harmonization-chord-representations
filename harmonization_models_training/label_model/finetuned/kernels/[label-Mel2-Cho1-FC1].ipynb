{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/.local/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import harmoutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU, concatenate\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Raw data---\n",
      "Number of sections: 2408\n",
      "Sample section: [('Bb6', [[58.0], [58.0]]), ('G7', [[-1.0], [-1.0]]), ('C-7', [[-1.0], [-1.0]]), ('F7', [[-1.0], [-1.0]]), ('Bb', [[-1.0], [-1.0]]), ('G-7', [[50.0], [57.0, 60.0]]), ('C-7', [[58.0, 55.0], [58.0]]), ('F7', [[61.0], [60.0, 58.0]]), ('F-7', [[60.0], [58.0]]), ('Bb7', [[56.0, 60.0], [59.0, 57.0]]), ('Eb7', [[58.0, 54.0], [55.0, 58.0]]), ('Ab7', [[61.0, 56.0], [61.0, 62.0]]), ('D-7', [[58.0, 60.0], [55.0, 58.0]]), ('G7', [[58.0], [-1.0]]), ('C-7', [[-1.0], [-1.0]]), ('F7', [[-1.0], [-1.0]])]\n",
      "\n",
      "---Transpose and augment data---\n",
      "Number of sections after data augmentation: 28884\n",
      "Sample section: [('E6', [[52.0], [52.0]]), ('Db7', [[-1.0], [-1.0]]), ('Gb-7', [[-1.0], [-1.0]]), ('B7', [[-1.0], [-1.0]]), ('E', [[-1.0], [-1.0]]), ('Db-7', [[44.0], [51.0, 54.0]]), ('Gb-7', [[52.0, 49.0], [52.0]]), ('B7', [[55.0], [54.0, 52.0]]), ('B-7', [[54.0], [52.0]]), ('E7', [[50.0, 54.0], [53.0, 51.0]]), ('A7', [[52.0, 48.0], [49.0, 52.0]]), ('D7', [[55.0, 50.0], [55.0, 56.0]]), ('Ab-7', [[52.0, 54.0], [49.0, 52.0]]), ('Db7', [[52.0], [-1.0]]), ('Gb-7', [[-1.0], [-1.0]]), ('B7', [[-1.0], [-1.0]])]\n",
      "\n",
      "---Truncate chords to sevenths---\n",
      "Number of sections: 28884\n",
      "Sample section: [('E6', [[52.0], [52.0]]), ('Db7', [[-1.0], [-1.0]]), ('Gb-7', [[-1.0], [-1.0]]), ('B7', [[-1.0], [-1.0]]), ('E', [[-1.0], [-1.0]]), ('Db-7', [[44.0], [51.0, 54.0]]), ('Gb-7', [[52.0, 49.0], [52.0]]), ('B7', [[55.0], [54.0, 52.0]]), ('B-7', [[54.0], [52.0]]), ('E7', [[50.0, 54.0], [53.0, 51.0]]), ('A7', [[52.0, 48.0], [49.0, 52.0]]), ('D7', [[55.0, 50.0], [55.0, 56.0]]), ('Ab-7', [[52.0, 54.0], [49.0, 52.0]]), ('Db7', [[52.0], [-1.0]]), ('Gb-7', [[-1.0], [-1.0]]), ('B7', [[-1.0], [-1.0]])]\n",
      "\n",
      "---Convert melody to integers---\n",
      "Number of sections: 28884\n",
      "Sample section: [('E6', [[4], [4]]), ('Db7', [[-1], [-1]]), ('Gb-7', [[-1], [-1]]), ('B7', [[-1], [-1]]), ('E', [[-1], [-1]]), ('Db-7', [[8], [3, 6]]), ('Gb-7', [[4, 1], [4]]), ('B7', [[7], [6, 4]]), ('B-7', [[6], [4]]), ('E7', [[2, 6], [5, 3]]), ('A7', [[4, 0], [1, 4]]), ('D7', [[7, 2], [7, 8]]), ('Ab-7', [[4, 6], [1, 4]]), ('Db7', [[4], [-1]]), ('Gb-7', [[-1], [-1]]), ('B7', [[-1], [-1]])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "raw_data = harmoutil.load_pickled_data(\"../data/refined_data.pkl\") # lists of (chord label, melody seqs) by sections\n",
    "print(\"---Raw data---\")\n",
    "print(\"Number of sections: {}\".format(len(raw_data)))\n",
    "print(\"Sample section: {}\\n\".format(raw_data[0]))\n",
    "augmented_data = harmoutil.transpose_and_augment_data(raw_data)\n",
    "print(\"---Transpose and augment data---\")\n",
    "print(\"Number of sections after data augmentation: {}\".format(len(augmented_data)))\n",
    "print(\"Sample section: {}\\n\".format(augmented_data[0]))\n",
    "data = [harmoutil.to_sevenths(section) for section in augmented_data]\n",
    "print(\"---Truncate chords to sevenths---\")\n",
    "print(\"Number of sections: {}\".format(len(data)))\n",
    "print(\"Sample section: {}\\n\".format(data[0]))\n",
    "data = [harmoutil.melody_to_octave_range(section) for section in data]\n",
    "print(\"---Convert melody to integers---\")\n",
    "print(\"Number of sections: {}\".format(len(data)))\n",
    "print(\"Sample section: {}\\n\".format(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Remove sections with augmented major chord---\n",
      "Number of sections: 28836\n",
      "\n",
      "Number of sections: 28836 | Sample section chords: ['E6', 'Db7', 'Gb-7', 'B7', 'E', 'Db-7', 'Gb-7', 'B7', 'B-7', 'E7', 'A7', 'D7', 'Ab-7', 'Db7', 'Gb-7', 'B7']\n",
      "Number of chords: 333480 | Sample chord: E6\n",
      "Number of melodies 333480 | Sample melody: [4, 4]\n",
      "Number of melody notes in the data: 2195328 | Sample melody note: 4\n"
     ]
    }
   ],
   "source": [
    "# Create individual chord and melody element lists \n",
    "def get_notes_by_chord(beats):\n",
    "    return [note for beat in beats for note in beat]\n",
    "\n",
    "def get_chords_by_section(section):\n",
    "    return [chord_info[0] for chord_info in section]\n",
    "\n",
    "def check_if_augmented_major(section):\n",
    "    section_chords = get_chords_by_section(section)\n",
    "    for ch in section_chords:\n",
    "        if \"+j7\" in ch:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "data = [section for section in data if not check_if_augmented_major(section)]\n",
    "print(\"---Remove sections with augmented major chord---\")\n",
    "print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections = [get_chords_by_section(section) for section in data]\n",
    "chords = [chord_info[0] for section in data for chord_info in section]\n",
    "notes_by_chords = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "notes = [note for chord_notes in notes_by_chords for note in chord_notes]\n",
    "# print(sum([len(section) for section in chords_by_sections]))\n",
    "print(\"Number of sections: {} | Sample section chords: {}\".format(len(chords_by_sections), chords_by_sections[0]))\n",
    "print(\"Number of chords: {} | Sample chord: {}\".format(len(chords), chords[0]))\n",
    "print(\"Number of melodies {} | Sample melody: {}\".format(len(notes_by_chords), notes_by_chords[0]))\n",
    "print(\"Number of melody notes in the data: {} | Sample melody note: {}\".format(len(notes), notes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melody note to integer mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, '<pad>': 13, -1: 12}\n",
      "\n",
      "Integer to melody note mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: -1, 13: '<pad>'}\n",
      "\n",
      "Chord label to integer mapping:\n",
      " {'A-j7': 6, 'Bb6': 46, 'C-7': 65, 'A+': 1, 'B+': 31, 'Do7': 102, 'Bo': 56, 'Asus': 28, 'Bb': 39, 'Eb-7': 119, 'Gb-7': 164, 'F6': 142, 'D-j7': 81, 'Bbm7b5': 49, 'Fj7': 144, 'Gsus7': 179, 'Bj7': 54, 'Cm7b5': 70, 'Ebo': 125, 'C7': 68, 'Ao7': 27, 'C6': 67, 'Bbj7': 48, 'D7': 83, '<bos>': 181, 'Abj7': 18, 'E6': 112, 'Fsus': 148, 'Eb-j7': 120, 'Eb': 114, 'Ab-7': 14, 'Ab': 9, 'D-': 78, 'Gb7': 167, 'Ab-': 12, 'Co7': 72, 'Db6': 91, 'F+': 136, 'Gb-6': 163, 'D+': 76, 'C+7': 62, 'Db-j7': 90, 'Bb7': 47, 'A+7': 2, 'Gj7': 174, 'Go': 176, 'Asus7': 29, 'B6': 37, 'B-': 33, 'Gb-j7': 165, 'Gbo7': 171, 'A-6': 4, 'G-6': 154, 'Esus7': 134, 'G': 150, 'E+': 106, 'Gm7b5': 175, 'Bbsus7': 53, 'Ebsus': 127, 'A-7': 5, 'D-7': 80, 'E+7': 107, 'Bsus': 58, 'Dbm7b5': 94, 'Csus7': 74, 'F-j7': 141, 'Bbo': 50, 'G-7': 155, 'Gsus': 178, 'Ao': 26, 'E-7': 110, 'Gbsus': 172, 'Ebo7': 126, 'Dm7b5': 100, 'F7': 143, 'A-': 3, 'Db+7': 86, 'B7': 38, 'F-7': 140, 'F+7': 137, 'Eb7': 122, 'B+7': 32, 'Bb+7': 41, 'Ej7': 129, 'Dsus': 103, 'E7': 113, 'Absus': 22, 'Csus': 73, 'Eb6': 121, 'Bbo7': 51, 'A6': 7, 'Abo': 20, 'F-6': 139, 'Abm7b5': 19, 'Db-': 87, 'Aj7': 24, 'Em7b5': 130, 'E': 105, 'Bm7b5': 55, 'G+': 151, 'C-j7': 66, 'Ab7': 17, 'C': 60, 'Bb+': 40, 'D+7': 77, 'Dj7': 99, 'Bb-j7': 45, 'Ebj7': 123, 'Fo': 146, 'D-6': 79, 'Eb+': 115, 'A7': 8, 'B-6': 34, 'C-6': 64, 'B-j7': 36, 'Dbsus7': 98, 'D': 75, 'Cj7': 69, 'B': 30, 'Fo7': 147, 'Abo7': 21, 'Db+': 85, 'E-6': 109, 'E-': 108, 'Eb-6': 118, 'Gb': 159, 'Gbo': 170, 'Dbsus': 97, 'Db': 84, 'Am7b5': 25, 'D6': 82, 'NC': 180, 'Gbm7b5': 169, 'Db7': 92, 'G7': 158, 'G6': 157, 'Gbsus7': 173, 'Absus7': 23, 'Ab6': 16, 'Db-7': 89, 'Gb+7': 161, 'Ab-6': 13, 'Bb-6': 43, 'Ab+': 10, 'Eb-': 117, 'F-': 138, 'Go7': 177, 'C+': 61, 'Eo': 131, 'G-': 153, 'Gb+': 160, 'Co': 71, 'Do': 101, 'A': 0, 'Ebm7b5': 124, 'Fsus7': 149, 'Gb-': 162, 'Dbo7': 96, 'Esus': 133, 'C-': 63, 'G+7': 152, 'Fm7b5': 145, 'E-j7': 111, 'Bb-7': 44, 'Dbo': 95, 'Ab+7': 11, 'Dbj7': 93, 'Dsus7': 104, 'Eb+7': 116, 'Ab-j7': 15, 'Gbj7': 168, 'B-7': 35, 'Ebsus7': 128, 'G-j7': 156, 'Bsus7': 59, 'F': 135, 'Eo7': 132, 'Bb-': 42, 'Bbsus': 52, 'Bo7': 57, 'Db-6': 88, 'Gb6': 166}\n",
      "\n",
      "Integer to chord label mapping:\n",
      " {0: 'A', 1: 'A+', 2: 'A+7', 3: 'A-', 4: 'A-6', 5: 'A-7', 6: 'A-j7', 7: 'A6', 8: 'A7', 9: 'Ab', 10: 'Ab+', 11: 'Ab+7', 12: 'Ab-', 13: 'Ab-6', 14: 'Ab-7', 15: 'Ab-j7', 16: 'Ab6', 17: 'Ab7', 18: 'Abj7', 19: 'Abm7b5', 20: 'Abo', 21: 'Abo7', 22: 'Absus', 23: 'Absus7', 24: 'Aj7', 25: 'Am7b5', 26: 'Ao', 27: 'Ao7', 28: 'Asus', 29: 'Asus7', 30: 'B', 31: 'B+', 32: 'B+7', 33: 'B-', 34: 'B-6', 35: 'B-7', 36: 'B-j7', 37: 'B6', 38: 'B7', 39: 'Bb', 40: 'Bb+', 41: 'Bb+7', 42: 'Bb-', 43: 'Bb-6', 44: 'Bb-7', 45: 'Bb-j7', 46: 'Bb6', 47: 'Bb7', 48: 'Bbj7', 49: 'Bbm7b5', 50: 'Bbo', 51: 'Bbo7', 52: 'Bbsus', 53: 'Bbsus7', 54: 'Bj7', 55: 'Bm7b5', 56: 'Bo', 57: 'Bo7', 58: 'Bsus', 59: 'Bsus7', 60: 'C', 61: 'C+', 62: 'C+7', 63: 'C-', 64: 'C-6', 65: 'C-7', 66: 'C-j7', 67: 'C6', 68: 'C7', 69: 'Cj7', 70: 'Cm7b5', 71: 'Co', 72: 'Co7', 73: 'Csus', 74: 'Csus7', 75: 'D', 76: 'D+', 77: 'D+7', 78: 'D-', 79: 'D-6', 80: 'D-7', 81: 'D-j7', 82: 'D6', 83: 'D7', 84: 'Db', 85: 'Db+', 86: 'Db+7', 87: 'Db-', 88: 'Db-6', 89: 'Db-7', 90: 'Db-j7', 91: 'Db6', 92: 'Db7', 93: 'Dbj7', 94: 'Dbm7b5', 95: 'Dbo', 96: 'Dbo7', 97: 'Dbsus', 98: 'Dbsus7', 99: 'Dj7', 100: 'Dm7b5', 101: 'Do', 102: 'Do7', 103: 'Dsus', 104: 'Dsus7', 105: 'E', 106: 'E+', 107: 'E+7', 108: 'E-', 109: 'E-6', 110: 'E-7', 111: 'E-j7', 112: 'E6', 113: 'E7', 114: 'Eb', 115: 'Eb+', 116: 'Eb+7', 117: 'Eb-', 118: 'Eb-6', 119: 'Eb-7', 120: 'Eb-j7', 121: 'Eb6', 122: 'Eb7', 123: 'Ebj7', 124: 'Ebm7b5', 125: 'Ebo', 126: 'Ebo7', 127: 'Ebsus', 128: 'Ebsus7', 129: 'Ej7', 130: 'Em7b5', 131: 'Eo', 132: 'Eo7', 133: 'Esus', 134: 'Esus7', 135: 'F', 136: 'F+', 137: 'F+7', 138: 'F-', 139: 'F-6', 140: 'F-7', 141: 'F-j7', 142: 'F6', 143: 'F7', 144: 'Fj7', 145: 'Fm7b5', 146: 'Fo', 147: 'Fo7', 148: 'Fsus', 149: 'Fsus7', 150: 'G', 151: 'G+', 152: 'G+7', 153: 'G-', 154: 'G-6', 155: 'G-7', 156: 'G-j7', 157: 'G6', 158: 'G7', 159: 'Gb', 160: 'Gb+', 161: 'Gb+7', 162: 'Gb-', 163: 'Gb-6', 164: 'Gb-7', 165: 'Gb-j7', 166: 'Gb6', 167: 'Gb7', 168: 'Gbj7', 169: 'Gbm7b5', 170: 'Gbo', 171: 'Gbo7', 172: 'Gbsus', 173: 'Gbsus7', 174: 'Gj7', 175: 'Gm7b5', 176: 'Go', 177: 'Go7', 178: 'Gsus', 179: 'Gsus7', 180: 'NC', 181: '<bos>'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create categorical data mappings\n",
    "\n",
    "# Note to integer index\n",
    "note_to_int = dict([(c, i) for i, c in enumerate(sorted(list(set(notes)))[1:])])\n",
    "note_to_int[-1] = len(note_to_int)\n",
    "note_to_int['<pad>'] = len(note_to_int)\n",
    "print(\"Melody note to integer mapping:\\n {}\\n\".format(note_to_int))\n",
    "\n",
    "# Integer to note\n",
    "int_to_note = dict([(k, v) for v, k in note_to_int.items()])\n",
    "print(\"Integer to melody note mapping:\\n {}\\n\".format(int_to_note))\n",
    "\n",
    "# Chord to integer index\n",
    "chord_to_int = dict([(c, i) for i, c in enumerate(sorted(list(set(chords))))])\n",
    "chord_to_int['<bos>'] = len(chord_to_int)\n",
    "print(\"Chord label to integer mapping:\\n {}\\n\".format(chord_to_int))\n",
    "\n",
    "\n",
    "# Integer to chord index\n",
    "int_to_chord = dict([(k, v) for v, k in chord_to_int.items()])\n",
    "print(\"Integer to chord label mapping:\\n {}\\n\".format(int_to_chord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 333480\n",
      "Number of distinct melody notes: 14\n",
      "Number of distinct chord labels: 182\n",
      "Maximum melody sequence length: 135\n",
      "Fixed context chord sequence length: 7\n"
     ]
    }
   ],
   "source": [
    "# Define numerical variables\n",
    "\n",
    "n_samples = len(chords)\n",
    "n_notes = len(note_to_int)\n",
    "n_chords = len(chord_to_int)\n",
    "max_melody_len = max([len(mel_seq) for mel_seq in notes_by_chords])\n",
    "chord_context_len = 7\n",
    "\n",
    "print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Number of distinct melody notes: {}\".format(n_notes))\n",
    "print(\"Number of distinct chord labels: {}\".format(n_chords))\n",
    "print(\"Maximum melody sequence length: {}\".format(max_melody_len))\n",
    "print(\"Fixed context chord sequence length: {}\".format(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input melody sequence: [8, 3, 6, '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "\n",
      "Sample input chord sequence: ['<bos>', '<bos>', 'E6', 'Db7', 'Gb-7', 'B7', 'E']\n",
      "\n",
      "Sample target chord: Db-7\n",
      "\n",
      "Input melody: 333480, Input chords: 333480, Target chords: 333480\n"
     ]
    }
   ],
   "source": [
    "# Prepare tensor data\n",
    "\n",
    "def pad_melody(melody, max_len):\n",
    "    return melody + (max_len-len(melody))*['<pad>']\n",
    "\n",
    "def build_input_chord_sequences(chord_seq, context_len):\n",
    "    padded_sequence = context_len*['<bos>'] + chord_seq\n",
    "    formatted_sequences = [padded_sequence[i:i+context_len+1] for i in range(len(chord_seq))]\n",
    "    return formatted_sequences\n",
    "\n",
    "# Melody\n",
    "input_melody_data = [pad_melody(melody, max_melody_len) for melody in notes_by_chords]\n",
    "print(\"Sample input melody sequence: {}\\n\".format(input_melody_data[5]))\n",
    "\n",
    "\n",
    "# Chords\n",
    "formatted_chords_data = []\n",
    "for section_chords in chords_by_sections:\n",
    "    formatted_chords_data += build_input_chord_sequences(section_chords, chord_context_len)\n",
    "\n",
    "input_chords_data = [ch[:-1] for ch in formatted_chords_data]\n",
    "target_chords_data = [ch[-1] for ch in formatted_chords_data]\n",
    "print(\"Sample input chord sequence: {}\\n\".format(input_chords_data[5]))\n",
    "print(\"Sample target chord: {}\\n\".format(target_chords_data[5]))\n",
    "\n",
    "print(\"Input melody: {}, Input chords: {}, Target chords: {}\".format(len(input_melody_data), len(input_chords_data), len(target_chords_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build tensors\n",
    "\n",
    "X_melody = np.zeros((n_samples, max_melody_len, n_notes), dtype='float32')\n",
    "X_chords = np.zeros((n_samples, chord_context_len, n_chords), dtype='float32')\n",
    "Y = np.zeros((n_samples, n_chords), dtype='float32')\n",
    "\n",
    "for i, (input_mel, input_ch, target_ch) in enumerate(zip(input_melody_data, input_chords_data, target_chords_data)):\n",
    "    Y[i, chord_to_int[target_ch]] = 1\n",
    "    for j, chord in enumerate(input_ch):\n",
    "        X_chords[i, j, chord_to_int[chord]] = 1\n",
    "        \n",
    "    for j, note in enumerate(input_mel):\n",
    "        X_melody[i, j, note_to_int[note]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333480, 135, 14) = (n_samples, max_melody_len, n_notes)\n",
      "(True, 45019800, 45019800.0, 44982130.0, 45019800)\n"
     ]
    }
   ],
   "source": [
    "# Test melody tensor\n",
    "\n",
    "def test_samples_axis(melody_tensor):\n",
    "    count = 0\n",
    "    sample_axis_sums = melody_tensor.sum(axis=2)\n",
    "    for entry in sample_axis_sums.ravel():\n",
    "        count += 1\n",
    "        if not (entry == 1):\n",
    "            return (False, count)\n",
    "    return (True, count, np.sum(sample_axis_sums), np.sum(melody_tensor), np.sum(melody_tensor, dtype=np.int32))\n",
    "\n",
    "# Test n_samples axis i.e. axis 1. If there are any \"holes\" (non-1) entry, it's a problem\n",
    "print(\"{} = (n_samples, max_melody_len, n_notes)\".format(X_melody.shape))\n",
    "print(test_samples_axis(X_melody))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset into 80%-10%-10% train-valid-test\n",
    "\n",
    "seed = 0\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "\n",
    "for train_index, aux_index in sss.split(X_chords, Y):\n",
    "    X_melody_train, X_melody_aux = X_melody[train_index], X_melody[aux_index]\n",
    "    X_chords_train, X_chords_aux = X_chords[train_index], X_chords[aux_index]\n",
    "    Y_train, Y_aux = Y[train_index], Y[aux_index]\n",
    "    \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)\n",
    "\n",
    "for valid_index, test_index in sss.split(X_chords_aux, Y_aux):\n",
    "    X_melody_valid, X_melody_test = X_melody[valid_index], X_melody[test_index]\n",
    "    X_chords_valid, X_chords_test = X_chords[valid_index], X_chords[test_index]\n",
    "    Y_valid, Y_test = Y[valid_index], Y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maxime/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 135, 14)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_7 (GRU)                      (None, 135, 128)      54912       input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 7, 182)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_8 (GRU)                      (None, 128)           98688       gru_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru_9 (GRU)                      (None, 128)           119424      input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 256)           0           gru_8[0][0]                      \n",
      "                                                                   gru_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 182)           46774       concatenate_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 319,798\n",
      "Trainable params: 319,798\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 255.00 337.00\" width=\"255pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-333 251,-333 251,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139757774745672 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139757774745672</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 125,-328.5 125,-292.5 0,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-306.8\">input_5: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139757774583288 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139757774583288</title>\n",
       "<polygon fill=\"none\" points=\"20.5,-219.5 20.5,-255.5 104.5,-255.5 104.5,-219.5 20.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-233.8\">gru_7: GRU</text>\n",
       "</g>\n",
       "<!-- 139757774745672&#45;&gt;139757774583288 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139757774745672-&gt;139757774583288</title>\n",
       "<path d=\"M62.5,-292.313C62.5,-284.289 62.5,-274.547 62.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-265.529 62.5,-255.529 59.0001,-265.529 66.0001,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139757779500112 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139757779500112</title>\n",
       "<polygon fill=\"none\" points=\"25.5,-146.5 25.5,-182.5 109.5,-182.5 109.5,-146.5 25.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67.5\" y=\"-160.8\">gru_8: GRU</text>\n",
       "</g>\n",
       "<!-- 139757774583288&#45;&gt;139757779500112 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139757774583288-&gt;139757779500112</title>\n",
       "<path d=\"M63.7104,-219.313C64.2754,-211.289 64.9614,-201.547 65.5937,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"69.0896,-192.75 66.3008,-182.529 62.1069,-192.258 69.0896,-192.75\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139757774746512 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139757774746512</title>\n",
       "<polygon fill=\"none\" points=\"122,-219.5 122,-255.5 247,-255.5 247,-219.5 122,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-233.8\">input_6: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139757773894264 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139757773894264</title>\n",
       "<polygon fill=\"none\" points=\"137.5,-146.5 137.5,-182.5 221.5,-182.5 221.5,-146.5 137.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"179.5\" y=\"-160.8\">gru_9: GRU</text>\n",
       "</g>\n",
       "<!-- 139757774746512&#45;&gt;139757773894264 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139757774746512-&gt;139757773894264</title>\n",
       "<path d=\"M183.29,-219.313C182.725,-211.289 182.039,-201.547 181.406,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"184.893,-192.258 180.699,-182.529 177.91,-192.75 184.893,-192.258\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139757773018504 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139757773018504</title>\n",
       "<polygon fill=\"none\" points=\"39.5,-73.5 39.5,-109.5 207.5,-109.5 207.5,-73.5 39.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-87.8\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 139757779500112&#45;&gt;139757773018504 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139757779500112-&gt;139757773018504</title>\n",
       "<path d=\"M81.056,-146.313C87.8658,-137.679 96.2453,-127.055 103.755,-117.534\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"106.624,-119.548 110.069,-109.529 101.128,-115.213 106.624,-119.548\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139757773894264&#45;&gt;139757773018504 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139757773894264-&gt;139757773018504</title>\n",
       "<path d=\"M165.944,-146.313C159.134,-137.679 150.755,-127.055 143.245,-117.534\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"145.872,-115.213 136.931,-109.529 140.376,-119.548 145.872,-115.213\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139756902038832 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139756902038832</title>\n",
       "<polygon fill=\"none\" points=\"72.5,-0.5 72.5,-36.5 174.5,-36.5 174.5,-0.5 72.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-14.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 139757773018504&#45;&gt;139756902038832 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139757773018504-&gt;139756902038832</title>\n",
       "<path d=\"M123.5,-73.3129C123.5,-65.2895 123.5,-55.5475 123.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"127,-46.5288 123.5,-36.5288 120,-46.5289 127,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define neural net architecture\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "melody_input = Input(shape=(max_melody_len, n_notes))\n",
    "melody_gru1 = GRU(latent_dim, return_sequences=True)(melody_input)\n",
    "melody_gru2 = GRU(latent_dim)(melody_gru1)\n",
    "\n",
    "chords_input = Input(shape=(chord_context_len, n_chords))\n",
    "chords_gru = GRU(latent_dim)(chords_input)\n",
    "\n",
    "concat = concatenate([melody_gru2, chords_gru])\n",
    "\n",
    "chord_dense = Dense(n_chords, activation='softmax')(concat)\n",
    "\n",
    "model = Model([melody_input, chords_input], chord_dense)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Introduce Early-Stopping and Save-Best-Performance callbacks\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "filepath = \"../models/label-Mel2-Cho1-FC1_150ep.h5\"\n",
    "bp = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 266784 samples, validate on 33348 samples\n",
      "Epoch 1/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 2.9865 - acc: 0.3356Epoch 00000: val_acc improved from -inf to 0.42521, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 909s - loss: 2.9864 - acc: 0.3356 - val_loss: 2.5387 - val_acc: 0.4252\n",
      "Epoch 2/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 2.4298 - acc: 0.4341Epoch 00001: val_acc improved from 0.42521 to 0.45988, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 910s - loss: 2.4298 - acc: 0.4341 - val_loss: 2.3265 - val_acc: 0.4599\n",
      "Epoch 3/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 2.2454 - acc: 0.4678Epoch 00002: val_acc improved from 0.45988 to 0.49109, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 911s - loss: 2.2454 - acc: 0.4678 - val_loss: 2.2048 - val_acc: 0.4911\n",
      "Epoch 4/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 2.0366 - acc: 0.5095Epoch 00003: val_acc improved from 0.49109 to 0.54606, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 912s - loss: 2.0366 - acc: 0.5095 - val_loss: 1.9332 - val_acc: 0.5461\n",
      "Epoch 5/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.8141 - acc: 0.5548Epoch 00004: val_acc improved from 0.54606 to 0.57203, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 913s - loss: 1.8141 - acc: 0.5548 - val_loss: 1.8029 - val_acc: 0.5720\n",
      "Epoch 6/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.6905 - acc: 0.5822Epoch 00005: val_acc improved from 0.57203 to 0.59065, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 913s - loss: 1.6904 - acc: 0.5822 - val_loss: 1.7253 - val_acc: 0.5907\n",
      "Epoch 7/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.5959 - acc: 0.6041Epoch 00006: val_acc improved from 0.59065 to 0.60267, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 912s - loss: 1.5958 - acc: 0.6041 - val_loss: 1.6700 - val_acc: 0.6027\n",
      "Epoch 8/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.5163 - acc: 0.6221Epoch 00007: val_acc improved from 0.60267 to 0.61389, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 914s - loss: 1.5163 - acc: 0.6221 - val_loss: 1.6272 - val_acc: 0.6139\n",
      "Epoch 9/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.4441 - acc: 0.6398Epoch 00008: val_acc improved from 0.61389 to 0.62654, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 914s - loss: 1.4441 - acc: 0.6398 - val_loss: 1.5809 - val_acc: 0.6265\n",
      "Epoch 10/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.3809 - acc: 0.6549Epoch 00009: val_acc improved from 0.62654 to 0.63191, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 913s - loss: 1.3810 - acc: 0.6549 - val_loss: 1.5439 - val_acc: 0.6319\n",
      "Epoch 11/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.3231 - acc: 0.6690Epoch 00010: val_acc improved from 0.63191 to 0.64025, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 912s - loss: 1.3230 - acc: 0.6690 - val_loss: 1.5137 - val_acc: 0.6402\n",
      "Epoch 12/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.2698 - acc: 0.6810Epoch 00011: val_acc improved from 0.64025 to 0.64622, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 914s - loss: 1.2699 - acc: 0.6810 - val_loss: 1.4938 - val_acc: 0.6462\n",
      "Epoch 13/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.2215 - acc: 0.6925Epoch 00012: val_acc improved from 0.64622 to 0.65461, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 913s - loss: 1.2215 - acc: 0.6925 - val_loss: 1.4742 - val_acc: 0.6546\n",
      "Epoch 14/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.1796 - acc: 0.7027Epoch 00013: val_acc improved from 0.65461 to 0.65929, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 913s - loss: 1.1796 - acc: 0.7027 - val_loss: 1.4508 - val_acc: 0.6593\n",
      "Epoch 15/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.1404 - acc: 0.7123Epoch 00014: val_acc improved from 0.65929 to 0.66307, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 912s - loss: 1.1404 - acc: 0.7123 - val_loss: 1.4339 - val_acc: 0.6631\n",
      "Epoch 16/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.0989 - acc: 0.7217Epoch 00015: val_acc improved from 0.66307 to 0.66838, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 913s - loss: 1.0989 - acc: 0.7217 - val_loss: 1.4178 - val_acc: 0.6684\n",
      "Epoch 17/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.0682 - acc: 0.7285Epoch 00016: val_acc improved from 0.66838 to 0.67131, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 915s - loss: 1.0683 - acc: 0.7285 - val_loss: 1.4014 - val_acc: 0.6713\n",
      "Epoch 18/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.0300 - acc: 0.7383Epoch 00017: val_acc improved from 0.67131 to 0.67776, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 914s - loss: 1.0300 - acc: 0.7383 - val_loss: 1.3869 - val_acc: 0.6778\n",
      "Epoch 19/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.9975 - acc: 0.7457Epoch 00018: val_acc improved from 0.67776 to 0.68109, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 912s - loss: 0.9975 - acc: 0.7457 - val_loss: 1.3832 - val_acc: 0.6811\n",
      "Epoch 20/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.9804 - acc: 0.7497Epoch 00019: val_acc improved from 0.68109 to 0.68490, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 912s - loss: 0.9804 - acc: 0.7497 - val_loss: 1.3680 - val_acc: 0.6849\n",
      "Epoch 21/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.9399 - acc: 0.7599Epoch 00020: val_acc improved from 0.68490 to 0.68835, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 913s - loss: 0.9398 - acc: 0.7599 - val_loss: 1.3555 - val_acc: 0.6883\n",
      "Epoch 22/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.9177 - acc: 0.7655Epoch 00021: val_acc improved from 0.68835 to 0.69204, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 913s - loss: 0.9177 - acc: 0.7655 - val_loss: 1.3414 - val_acc: 0.6920\n",
      "Epoch 23/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8965 - acc: 0.7695Epoch 00022: val_acc improved from 0.69204 to 0.69575, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 912s - loss: 0.8965 - acc: 0.7695 - val_loss: 1.3345 - val_acc: 0.6958\n",
      "Epoch 24/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8776 - acc: 0.7750Epoch 00023: val_acc improved from 0.69575 to 0.69953, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 915s - loss: 0.8776 - acc: 0.7750 - val_loss: 1.3326 - val_acc: 0.6995\n",
      "Epoch 25/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8472 - acc: 0.7823Epoch 00024: val_acc improved from 0.69953 to 0.70061, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266784/266784 [==============================] - 914s - loss: 0.8471 - acc: 0.7823 - val_loss: 1.3238 - val_acc: 0.7006\n",
      "Epoch 26/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8272 - acc: 0.7864Epoch 00025: val_acc improved from 0.70061 to 0.70319, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 912s - loss: 0.8272 - acc: 0.7865 - val_loss: 1.3185 - val_acc: 0.7032\n",
      "Epoch 27/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8165 - acc: 0.7891Epoch 00026: val_acc improved from 0.70319 to 0.70808, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 911s - loss: 0.8164 - acc: 0.7891 - val_loss: 1.3101 - val_acc: 0.7081\n",
      "Epoch 28/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8045 - acc: 0.7913Epoch 00027: val_acc improved from 0.70808 to 0.71090, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 910s - loss: 0.8046 - acc: 0.7913 - val_loss: 1.3096 - val_acc: 0.7109\n",
      "Epoch 29/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7956 - acc: 0.7931Epoch 00028: val_acc improved from 0.71090 to 0.71225, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 910s - loss: 0.7956 - acc: 0.7931 - val_loss: 1.3016 - val_acc: 0.7122\n",
      "Epoch 30/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7604 - acc: 0.8026Epoch 00029: val_acc improved from 0.71225 to 0.71459, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 910s - loss: 0.7604 - acc: 0.8026 - val_loss: 1.2974 - val_acc: 0.7146\n",
      "Epoch 31/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7428 - acc: 0.8070Epoch 00030: val_acc improved from 0.71459 to 0.71737, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 912s - loss: 0.7429 - acc: 0.8070 - val_loss: 1.2924 - val_acc: 0.7174\n",
      "Epoch 32/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7277 - acc: 0.8110Epoch 00031: val_acc improved from 0.71737 to 0.71866, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 914s - loss: 0.7277 - acc: 0.8110 - val_loss: 1.2937 - val_acc: 0.7187\n",
      "Epoch 33/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7212 - acc: 0.8113Epoch 00032: val_acc improved from 0.71866 to 0.71884, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 914s - loss: 0.7212 - acc: 0.8113 - val_loss: 1.2962 - val_acc: 0.7188\n",
      "Epoch 34/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6993 - acc: 0.8169Epoch 00033: val_acc did not improve\n",
      "266784/266784 [==============================] - 913s - loss: 0.6993 - acc: 0.8169 - val_loss: 1.2984 - val_acc: 0.7182\n",
      "Epoch 35/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6896 - acc: 0.8196Epoch 00034: val_acc did not improve\n",
      "266784/266784 [==============================] - 912s - loss: 0.6895 - acc: 0.8196 - val_loss: 1.2976 - val_acc: 0.7185\n",
      "Epoch 36/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6871 - acc: 0.8192Epoch 00035: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.6871 - acc: 0.8192 - val_loss: 1.3278 - val_acc: 0.7140\n",
      "Epoch 37/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6864 - acc: 0.8179Epoch 00036: val_acc improved from 0.71884 to 0.72706, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 914s - loss: 0.6864 - acc: 0.8179 - val_loss: 1.2916 - val_acc: 0.7271\n",
      "Epoch 38/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6608 - acc: 0.8258Epoch 00037: val_acc improved from 0.72706 to 0.72769, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 913s - loss: 0.6608 - acc: 0.8258 - val_loss: 1.2876 - val_acc: 0.7277\n",
      "Epoch 39/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6449 - acc: 0.8292Epoch 00038: val_acc improved from 0.72769 to 0.73183, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 914s - loss: 0.6449 - acc: 0.8292 - val_loss: 1.2778 - val_acc: 0.7318\n",
      "Epoch 40/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6507 - acc: 0.8279Epoch 00039: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.6507 - acc: 0.8279 - val_loss: 1.2835 - val_acc: 0.7297\n",
      "Epoch 41/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6282 - acc: 0.8335Epoch 00040: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.6283 - acc: 0.8335 - val_loss: 1.2893 - val_acc: 0.7306\n",
      "Epoch 42/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6206 - acc: 0.8348Epoch 00041: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.6206 - acc: 0.8348 - val_loss: 1.3048 - val_acc: 0.7248\n",
      "Epoch 43/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6123 - acc: 0.8375Epoch 00042: val_acc improved from 0.73183 to 0.73864, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 910s - loss: 0.6123 - acc: 0.8375 - val_loss: 1.2781 - val_acc: 0.7386\n",
      "Epoch 44/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5892 - acc: 0.8444Epoch 00043: val_acc did not improve\n",
      "266784/266784 [==============================] - 909s - loss: 0.5892 - acc: 0.8444 - val_loss: 1.2915 - val_acc: 0.7335\n",
      "Epoch 45/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5901 - acc: 0.8422Epoch 00044: val_acc did not improve\n",
      "266784/266784 [==============================] - 910s - loss: 0.5901 - acc: 0.8422 - val_loss: 1.2849 - val_acc: 0.7385\n",
      "Epoch 46/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5929 - acc: 0.8405Epoch 00045: val_acc did not improve\n",
      "266784/266784 [==============================] - 910s - loss: 0.5930 - acc: 0.8405 - val_loss: 1.3367 - val_acc: 0.7243\n",
      "Epoch 47/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5970 - acc: 0.8392Epoch 00046: val_acc improved from 0.73864 to 0.73917, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 917s - loss: 0.5969 - acc: 0.8392 - val_loss: 1.2864 - val_acc: 0.7392\n",
      "Epoch 48/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5751 - acc: 0.8453Epoch 00047: val_acc improved from 0.73917 to 0.74013, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 918s - loss: 0.5751 - acc: 0.8453 - val_loss: 1.2856 - val_acc: 0.7401\n",
      "Epoch 49/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5778 - acc: 0.8439Epoch 00048: val_acc did not improve\n",
      "266784/266784 [==============================] - 916s - loss: 0.5778 - acc: 0.8439 - val_loss: 1.2931 - val_acc: 0.7377\n",
      "Epoch 50/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5551 - acc: 0.8510Epoch 00049: val_acc improved from 0.74013 to 0.74568, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 915s - loss: 0.5551 - acc: 0.8510 - val_loss: 1.2859 - val_acc: 0.7457\n",
      "Epoch 51/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5552 - acc: 0.8503Epoch 00050: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.5552 - acc: 0.8503 - val_loss: 1.3012 - val_acc: 0.7379\n",
      "Epoch 52/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5460 - acc: 0.8528Epoch 00051: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.5461 - acc: 0.8528 - val_loss: 1.3053 - val_acc: 0.7398\n",
      "Epoch 53/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5398 - acc: 0.8543Epoch 00052: val_acc did not improve\n",
      "266784/266784 [==============================] - 913s - loss: 0.5398 - acc: 0.8543 - val_loss: 1.2936 - val_acc: 0.7426\n",
      "Epoch 54/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5250 - acc: 0.8584Epoch 00053: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.5251 - acc: 0.8584 - val_loss: 1.2954 - val_acc: 0.7446\n",
      "Epoch 55/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5385 - acc: 0.8531Epoch 00054: val_acc did not improve\n",
      "266784/266784 [==============================] - 912s - loss: 0.5385 - acc: 0.8531 - val_loss: 1.3344 - val_acc: 0.7355\n",
      "Epoch 56/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5399 - acc: 0.8526Epoch 00055: val_acc did not improve\n",
      "266784/266784 [==============================] - 911s - loss: 0.5398 - acc: 0.8526 - val_loss: 1.3104 - val_acc: 0.7435\n",
      "Epoch 57/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5149 - acc: 0.8612Epoch 00056: val_acc improved from 0.74568 to 0.74631, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 915s - loss: 0.5149 - acc: 0.8612 - val_loss: 1.3053 - val_acc: 0.7463\n",
      "Epoch 58/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.8571Epoch 00057: val_acc improved from 0.74631 to 0.74724, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 918s - loss: 0.5258 - acc: 0.8571 - val_loss: 1.2979 - val_acc: 0.7472\n",
      "Epoch 59/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5033 - acc: 0.8636Epoch 00058: val_acc improved from 0.74724 to 0.74754, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 917s - loss: 0.5033 - acc: 0.8636 - val_loss: 1.2997 - val_acc: 0.7475\n",
      "Epoch 60/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5604 - acc: 0.8459Epoch 00059: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.5603 - acc: 0.8459 - val_loss: 1.3142 - val_acc: 0.7410\n",
      "Epoch 61/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5083 - acc: 0.8609Epoch 00060: val_acc improved from 0.74754 to 0.74763, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 915s - loss: 0.5082 - acc: 0.8610 - val_loss: 1.3009 - val_acc: 0.7476\n",
      "Epoch 62/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4847 - acc: 0.8691Epoch 00061: val_acc improved from 0.74763 to 0.75177, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 915s - loss: 0.4847 - acc: 0.8691 - val_loss: 1.3012 - val_acc: 0.7518\n",
      "Epoch 63/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5182 - acc: 0.8572Epoch 00062: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.5182 - acc: 0.8572 - val_loss: 1.3545 - val_acc: 0.7328\n",
      "Epoch 64/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5095 - acc: 0.8600Epoch 00063: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.5095 - acc: 0.8600 - val_loss: 1.3220 - val_acc: 0.7444\n",
      "Epoch 65/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5041 - acc: 0.8614Epoch 00064: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.5041 - acc: 0.8614 - val_loss: 1.3094 - val_acc: 0.7467\n",
      "Epoch 66/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5232 - acc: 0.8548Epoch 00065: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.5231 - acc: 0.8548 - val_loss: 1.3192 - val_acc: 0.7449\n",
      "Epoch 67/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4866 - acc: 0.8665Epoch 00066: val_acc improved from 0.75177 to 0.75444, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 914s - loss: 0.4866 - acc: 0.8665 - val_loss: 1.2998 - val_acc: 0.7544\n",
      "Epoch 68/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4749 - acc: 0.8700Epoch 00067: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.4750 - acc: 0.8700 - val_loss: 1.3193 - val_acc: 0.7499\n",
      "Epoch 69/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8717Epoch 00068: val_acc improved from 0.75444 to 0.75552, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 916s - loss: 0.4674 - acc: 0.8718 - val_loss: 1.3063 - val_acc: 0.7555\n",
      "Epoch 70/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4887 - acc: 0.8646Epoch 00069: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.4886 - acc: 0.8646 - val_loss: 1.3547 - val_acc: 0.7389\n",
      "Epoch 71/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5001 - acc: 0.8612Epoch 00070: val_acc did not improve\n",
      "266784/266784 [==============================] - 910s - loss: 0.5001 - acc: 0.8612 - val_loss: 1.3364 - val_acc: 0.7469\n",
      "Epoch 72/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.8721Epoch 00071: val_acc improved from 0.75552 to 0.75612, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 910s - loss: 0.4637 - acc: 0.8721 - val_loss: 1.3082 - val_acc: 0.7561\n",
      "Epoch 73/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4852 - acc: 0.8672Epoch 00072: val_acc did not improve\n",
      "266784/266784 [==============================] - 911s - loss: 0.4852 - acc: 0.8672 - val_loss: 1.4069 - val_acc: 0.7255\n",
      "Epoch 74/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.5051 - acc: 0.8581Epoch 00073: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.5051 - acc: 0.8581 - val_loss: 1.3250 - val_acc: 0.7537\n",
      "Epoch 75/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4504 - acc: 0.8761Epoch 00074: val_acc did not improve\n",
      "266784/266784 [==============================] - 918s - loss: 0.4504 - acc: 0.8761 - val_loss: 1.3278 - val_acc: 0.7539\n",
      "Epoch 76/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4377 - acc: 0.8798Epoch 00075: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.4376 - acc: 0.8798 - val_loss: 1.3530 - val_acc: 0.7466\n",
      "Epoch 77/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4485 - acc: 0.8755Epoch 00076: val_acc did not improve\n",
      "266784/266784 [==============================] - 913s - loss: 0.4485 - acc: 0.8755 - val_loss: 1.3764 - val_acc: 0.7433\n",
      "Epoch 78/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4816 - acc: 0.8647Epoch 00077: val_acc did not improve\n",
      "266784/266784 [==============================] - 912s - loss: 0.4816 - acc: 0.8647 - val_loss: 1.3324 - val_acc: 0.7515\n",
      "Epoch 79/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4362 - acc: 0.8793Epoch 00078: val_acc did not improve\n",
      "266784/266784 [==============================] - 912s - loss: 0.4362 - acc: 0.8793 - val_loss: 1.3263 - val_acc: 0.7553\n",
      "Epoch 80/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4414 - acc: 0.8778Epoch 00079: val_acc did not improve\n",
      "266784/266784 [==============================] - 911s - loss: 0.4414 - acc: 0.8778 - val_loss: 1.3539 - val_acc: 0.7462\n",
      "Epoch 81/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8699Epoch 00080: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.4647 - acc: 0.8699 - val_loss: 1.3373 - val_acc: 0.7519\n",
      "Epoch 82/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4371 - acc: 0.8783Epoch 00081: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266784/266784 [==============================] - 915s - loss: 0.4371 - acc: 0.8783 - val_loss: 1.3372 - val_acc: 0.7559\n",
      "Epoch 83/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4220 - acc: 0.8832Epoch 00082: val_acc improved from 0.75612 to 0.75735, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 915s - loss: 0.4220 - acc: 0.8832 - val_loss: 1.3328 - val_acc: 0.7573\n",
      "Epoch 84/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4286 - acc: 0.8809Epoch 00083: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.4286 - acc: 0.8809 - val_loss: 1.3447 - val_acc: 0.7565\n",
      "Epoch 85/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4244 - acc: 0.8816Epoch 00084: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.4243 - acc: 0.8816 - val_loss: 1.3565 - val_acc: 0.7522\n",
      "Epoch 86/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4324 - acc: 0.8791Epoch 00085: val_acc did not improve\n",
      "266784/266784 [==============================] - 920s - loss: 0.4324 - acc: 0.8791 - val_loss: 1.3539 - val_acc: 0.7555\n",
      "Epoch 87/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4559 - acc: 0.8715Epoch 00086: val_acc did not improve\n",
      "266784/266784 [==============================] - 921s - loss: 0.4559 - acc: 0.8715 - val_loss: 1.3563 - val_acc: 0.7523\n",
      "Epoch 88/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4188 - acc: 0.8826Epoch 00087: val_acc improved from 0.75735 to 0.75891, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 920s - loss: 0.4189 - acc: 0.8826 - val_loss: 1.3413 - val_acc: 0.7589\n",
      "Epoch 89/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4201 - acc: 0.8825Epoch 00088: val_acc improved from 0.75891 to 0.75933, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 919s - loss: 0.4200 - acc: 0.8825 - val_loss: 1.3423 - val_acc: 0.7593\n",
      "Epoch 90/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4488 - acc: 0.8734Epoch 00089: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.4488 - acc: 0.8734 - val_loss: 1.3586 - val_acc: 0.7574\n",
      "Epoch 91/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4187 - acc: 0.8828Epoch 00090: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.4187 - acc: 0.8828 - val_loss: 1.3624 - val_acc: 0.7580\n",
      "Epoch 92/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4128 - acc: 0.8842Epoch 00091: val_acc did not improve\n",
      "266784/266784 [==============================] - 916s - loss: 0.4129 - acc: 0.8842 - val_loss: 1.3632 - val_acc: 0.7589\n",
      "Epoch 93/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4781 - acc: 0.8661Epoch 00092: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.4780 - acc: 0.8661 - val_loss: 1.3793 - val_acc: 0.7496\n",
      "Epoch 94/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4345 - acc: 0.8777Epoch 00093: val_acc did not improve\n",
      "266784/266784 [==============================] - 919s - loss: 0.4345 - acc: 0.8777 - val_loss: 1.3539 - val_acc: 0.7581\n",
      "Epoch 95/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4084 - acc: 0.8864Epoch 00094: val_acc improved from 0.75933 to 0.76172, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 919s - loss: 0.4084 - acc: 0.8865 - val_loss: 1.3512 - val_acc: 0.7617\n",
      "Epoch 96/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4884 - acc: 0.8628Epoch 00095: val_acc did not improve\n",
      "266784/266784 [==============================] - 918s - loss: 0.4884 - acc: 0.8628 - val_loss: 1.3873 - val_acc: 0.7464\n",
      "Epoch 97/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4443 - acc: 0.8739Epoch 00096: val_acc did not improve\n",
      "266784/266784 [==============================] - 918s - loss: 0.4443 - acc: 0.8739 - val_loss: 1.3572 - val_acc: 0.7606\n",
      "Epoch 98/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3927 - acc: 0.8908Epoch 00097: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.3927 - acc: 0.8908 - val_loss: 1.3563 - val_acc: 0.7595\n",
      "Epoch 99/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4266 - acc: 0.8788Epoch 00098: val_acc did not improve\n",
      "266784/266784 [==============================] - 913s - loss: 0.4265 - acc: 0.8788 - val_loss: 1.3639 - val_acc: 0.7576\n",
      "Epoch 100/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4397 - acc: 0.8750Epoch 00099: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.4397 - acc: 0.8750 - val_loss: 1.3805 - val_acc: 0.7517\n",
      "Epoch 101/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4136 - acc: 0.8828Epoch 00100: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.4136 - acc: 0.8828 - val_loss: 1.3525 - val_acc: 0.7615\n",
      "Epoch 102/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3976 - acc: 0.8885Epoch 00101: val_acc did not improve\n",
      "266784/266784 [==============================] - 916s - loss: 0.3977 - acc: 0.8885 - val_loss: 1.3684 - val_acc: 0.7577\n",
      "Epoch 103/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3922 - acc: 0.8899Epoch 00102: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.3923 - acc: 0.8898 - val_loss: 1.3777 - val_acc: 0.7561\n",
      "Epoch 104/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3976 - acc: 0.8873Epoch 00103: val_acc improved from 0.76172 to 0.76334, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 916s - loss: 0.3975 - acc: 0.8873 - val_loss: 1.3631 - val_acc: 0.7633\n",
      "Epoch 105/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4133 - acc: 0.8825Epoch 00104: val_acc did not improve\n",
      "266784/266784 [==============================] - 920s - loss: 0.4133 - acc: 0.8825 - val_loss: 1.3789 - val_acc: 0.7562\n",
      "Epoch 106/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4018 - acc: 0.8861Epoch 00105: val_acc did not improve\n",
      "266784/266784 [==============================] - 918s - loss: 0.4018 - acc: 0.8861 - val_loss: 1.3731 - val_acc: 0.7609\n",
      "Epoch 107/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3793 - acc: 0.8934Epoch 00106: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.3794 - acc: 0.8934 - val_loss: 1.3768 - val_acc: 0.7580\n",
      "Epoch 108/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3769 - acc: 0.8935Epoch 00107: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.3770 - acc: 0.8935 - val_loss: 1.3879 - val_acc: 0.7598\n",
      "Epoch 109/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4201 - acc: 0.8800Epoch 00108: val_acc did not improve\n",
      "266784/266784 [==============================] - 916s - loss: 0.4201 - acc: 0.8800 - val_loss: 1.4371 - val_acc: 0.7422\n",
      "Epoch 110/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4186 - acc: 0.8800Epoch 00109: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.4187 - acc: 0.8800 - val_loss: 1.3736 - val_acc: 0.7624\n",
      "Epoch 111/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3831 - acc: 0.8917Epoch 00110: val_acc improved from 0.76334 to 0.76433, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 914s - loss: 0.3831 - acc: 0.8917 - val_loss: 1.3785 - val_acc: 0.7643\n",
      "Epoch 112/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.8880Epoch 00111: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266784/266784 [==============================] - 917s - loss: 0.3936 - acc: 0.8880 - val_loss: 1.4210 - val_acc: 0.7486\n",
      "Epoch 113/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3864 - acc: 0.8900Epoch 00112: val_acc did not improve\n",
      "266784/266784 [==============================] - 920s - loss: 0.3864 - acc: 0.8900 - val_loss: 1.4008 - val_acc: 0.7541\n",
      "Epoch 114/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3728 - acc: 0.8945Epoch 00113: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.3727 - acc: 0.8945 - val_loss: 1.3920 - val_acc: 0.7605\n",
      "Epoch 115/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4397 - acc: 0.8741Epoch 00114: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.4397 - acc: 0.8741 - val_loss: 1.4084 - val_acc: 0.7530\n",
      "Epoch 116/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4320 - acc: 0.8757Epoch 00115: val_acc did not improve\n",
      "266784/266784 [==============================] - 913s - loss: 0.4320 - acc: 0.8757 - val_loss: 1.4319 - val_acc: 0.7476\n",
      "Epoch 117/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3986 - acc: 0.8863Epoch 00116: val_acc did not improve\n",
      "266784/266784 [==============================] - 913s - loss: 0.3986 - acc: 0.8863 - val_loss: 1.4535 - val_acc: 0.7434\n",
      "Epoch 118/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3995 - acc: 0.8857Epoch 00117: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.3995 - acc: 0.8857 - val_loss: 1.3798 - val_acc: 0.7624\n",
      "Epoch 119/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8863Epoch 00118: val_acc did not improve\n",
      "266784/266784 [==============================] - 918s - loss: 0.3998 - acc: 0.8863 - val_loss: 1.4284 - val_acc: 0.7486\n",
      "Epoch 120/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4141 - acc: 0.8806Epoch 00119: val_acc did not improve\n",
      "266784/266784 [==============================] - 918s - loss: 0.4141 - acc: 0.8806 - val_loss: 1.3782 - val_acc: 0.7640\n",
      "Epoch 121/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3751 - acc: 0.8935Epoch 00120: val_acc improved from 0.76433 to 0.76502, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 916s - loss: 0.3751 - acc: 0.8934 - val_loss: 1.3757 - val_acc: 0.7650\n",
      "Epoch 122/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3671 - acc: 0.8955Epoch 00121: val_acc did not improve\n",
      "266784/266784 [==============================] - 911s - loss: 0.3671 - acc: 0.8955 - val_loss: 1.4053 - val_acc: 0.7618\n",
      "Epoch 123/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3817 - acc: 0.8908Epoch 00122: val_acc did not improve\n",
      "266784/266784 [==============================] - 910s - loss: 0.3817 - acc: 0.8908 - val_loss: 1.4030 - val_acc: 0.7610\n",
      "Epoch 124/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3834 - acc: 0.8899Epoch 00123: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.3834 - acc: 0.8899 - val_loss: 1.3928 - val_acc: 0.7623\n",
      "Epoch 125/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3720 - acc: 0.8934Epoch 00124: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.3720 - acc: 0.8934 - val_loss: 1.3972 - val_acc: 0.7616\n",
      "Epoch 126/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3570 - acc: 0.8990Epoch 00125: val_acc did not improve\n",
      "266784/266784 [==============================] - 919s - loss: 0.3570 - acc: 0.8990 - val_loss: 1.4117 - val_acc: 0.7607\n",
      "Epoch 127/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3806 - acc: 0.8909Epoch 00126: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.3806 - acc: 0.8909 - val_loss: 1.4339 - val_acc: 0.7478\n",
      "Epoch 128/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4016 - acc: 0.8843Epoch 00127: val_acc did not improve\n",
      "266784/266784 [==============================] - 916s - loss: 0.4016 - acc: 0.8842 - val_loss: 1.4138 - val_acc: 0.7566\n",
      "Epoch 129/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4560 - acc: 0.8696Epoch 00128: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.4560 - acc: 0.8696 - val_loss: 1.4090 - val_acc: 0.7554\n",
      "Epoch 130/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3809 - acc: 0.8912Epoch 00129: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.3808 - acc: 0.8912 - val_loss: 1.4026 - val_acc: 0.7628\n",
      "Epoch 131/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3692 - acc: 0.8941Epoch 00130: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.3692 - acc: 0.8941 - val_loss: 1.4029 - val_acc: 0.7630\n",
      "Epoch 132/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3841 - acc: 0.8895Epoch 00131: val_acc improved from 0.76502 to 0.76817, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 912s - loss: 0.3841 - acc: 0.8895 - val_loss: 1.3897 - val_acc: 0.7682\n",
      "Epoch 133/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4097 - acc: 0.8827Epoch 00132: val_acc did not improve\n",
      "266784/266784 [==============================] - 913s - loss: 0.4097 - acc: 0.8827 - val_loss: 1.4069 - val_acc: 0.7590\n",
      "Epoch 134/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3697 - acc: 0.8943Epoch 00133: val_acc did not improve\n",
      "266784/266784 [==============================] - 919s - loss: 0.3697 - acc: 0.8943 - val_loss: 1.3835 - val_acc: 0.7669\n",
      "Epoch 135/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3543 - acc: 0.8992Epoch 00134: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.3543 - acc: 0.8992 - val_loss: 1.3968 - val_acc: 0.7659\n",
      "Epoch 136/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3702 - acc: 0.8933Epoch 00135: val_acc did not improve\n",
      "266784/266784 [==============================] - 916s - loss: 0.3702 - acc: 0.8933 - val_loss: 1.4120 - val_acc: 0.7621\n",
      "Epoch 137/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3516 - acc: 0.8994Epoch 00136: val_acc did not improve\n",
      "266784/266784 [==============================] - 915s - loss: 0.3516 - acc: 0.8994 - val_loss: 1.3996 - val_acc: 0.7681\n",
      "Epoch 138/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3798 - acc: 0.8912Epoch 00137: val_acc did not improve\n",
      "266784/266784 [==============================] - 911s - loss: 0.3797 - acc: 0.8912 - val_loss: 1.4226 - val_acc: 0.7593\n",
      "Epoch 139/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3667 - acc: 0.8936Epoch 00138: val_acc did not improve\n",
      "266784/266784 [==============================] - 911s - loss: 0.3667 - acc: 0.8936 - val_loss: 1.4029 - val_acc: 0.7667\n",
      "Epoch 140/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3568 - acc: 0.8975Epoch 00139: val_acc did not improve\n",
      "266784/266784 [==============================] - 916s - loss: 0.3568 - acc: 0.8975 - val_loss: 1.3996 - val_acc: 0.7637\n",
      "Epoch 141/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3449 - acc: 0.9012Epoch 00140: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.3449 - acc: 0.9011 - val_loss: 1.4448 - val_acc: 0.7546\n",
      "Epoch 142/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4080 - acc: 0.8822Epoch 00141: val_acc did not improve\n",
      "266784/266784 [==============================] - 917s - loss: 0.4080 - acc: 0.8822 - val_loss: 1.4633 - val_acc: 0.7481\n",
      "Epoch 143/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3847 - acc: 0.8883Epoch 00142: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266784/266784 [==============================] - 915s - loss: 0.3848 - acc: 0.8883 - val_loss: 1.4058 - val_acc: 0.7634\n",
      "Epoch 144/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3536 - acc: 0.8982Epoch 00143: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.3535 - acc: 0.8982 - val_loss: 1.4096 - val_acc: 0.7624\n",
      "Epoch 145/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3582 - acc: 0.8971Epoch 00144: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.3583 - acc: 0.8971 - val_loss: 1.4575 - val_acc: 0.7525\n",
      "Epoch 146/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4767 - acc: 0.8615Epoch 00145: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.4767 - acc: 0.8615 - val_loss: 1.4152 - val_acc: 0.7587\n",
      "Epoch 147/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3648 - acc: 0.8950Epoch 00146: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.3648 - acc: 0.8950 - val_loss: 1.4086 - val_acc: 0.7630\n",
      "Epoch 148/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3708 - acc: 0.8933Epoch 00147: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.3708 - acc: 0.8933 - val_loss: 1.4006 - val_acc: 0.7643\n",
      "Epoch 149/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.4174 - acc: 0.8787Epoch 00148: val_acc did not improve\n",
      "266784/266784 [==============================] - 914s - loss: 0.4174 - acc: 0.8787 - val_loss: 1.4315 - val_acc: 0.7558\n",
      "Epoch 150/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.3610 - acc: 0.8961Epoch 00149: val_acc improved from 0.76817 to 0.76973, saving model to ../models/label-Mel2-Cho1-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 917s - loss: 0.3610 - acc: 0.8961 - val_loss: 1.3821 - val_acc: 0.7697\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 256\n",
    "epochs = 150\n",
    "\n",
    "history = model.fit([X_melody_train, X_chords_train], Y_train, epochs=epochs, validation_data=([X_melody_valid, X_chords_valid], Y_valid,), batch_size=batch_size, callbacks=[bp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1be4cc40f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFkCAYAAADWs8tQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZhsStQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1be4cc4898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize model learning\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Training history of root model\", fontsize=16)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best performance model\n",
    "model = load_model(\"../models/label-Mel2-Cho1-FC1_150ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord label prediction: 0.7703\n",
      "Kappa score of combined chord label prediction: 0.7646\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of labels\n",
    "\n",
    "# Predict chords from each test sample melody\n",
    "Y_pred = model.predict([X_melody_test, X_chords_test])\n",
    "\n",
    "# Compute accuracy and kappa score\n",
    "print(\"Categorical accuracy of combined chord label prediction: {0:.4f}\".format(harmoutil.compute_accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Kappa score of combined chord label prediction: {0:.4f}\".format(harmoutil.compute_kappa_score(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord pitch prediction: 0.9059\n",
      "TP: 111378 TN: 251126 FP: 18924 FN: 18748\n",
      "Kappa score of combined chord pitch prediction: 0.7856\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of pitches\n",
    "\n",
    "def label_to_pitch_tensors(predictions):\n",
    "    predicted_chords = [int_to_chord[np.argmax(ch)] for ch in predictions]\n",
    "    pitch_chords = [harmoutil.chord_to_notes(label) for label in predicted_chords]\n",
    "    \n",
    "    Y_pitches = np.zeros((predictions.shape[0], 12), dtype='float32')\n",
    "    for i, chord_pitches in enumerate(pitch_chords):\n",
    "        for j, pitch_presence in enumerate(chord_pitches):\n",
    "            Y_pitches[i, j] = pitch_presence\n",
    "\n",
    "    return Y_pitches\n",
    "    \n",
    "    \n",
    "Y_pred_pitch = label_to_pitch_tensors(Y_pred)\n",
    "Y_test_pitch = label_to_pitch_tensors(Y_test)\n",
    "\n",
    "print(\"Categorical accuracy of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_accuracy_score(Y_test_pitch, Y_pred_pitch)))\n",
    "print(\"Kappa score of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_kappa_score(Y_test_pitch, Y_pred_pitch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"F-score: {0:.4f}\".format(harmoutil.compute_binary_fscore(Y_test_pitch, Y_pred_pitch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
