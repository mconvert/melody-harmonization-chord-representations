{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/.local/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import harmoutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU, concatenate\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Raw data---\n",
      "Number of sections: 2408\n",
      "Sample section: [('Bb6', [[58.0], [58.0]]), ('G7', [[-1.0], [-1.0]]), ('C-7', [[-1.0], [-1.0]]), ('F7', [[-1.0], [-1.0]]), ('Bb', [[-1.0], [-1.0]]), ('G-7', [[50.0], [57.0, 60.0]]), ('C-7', [[58.0, 55.0], [58.0]]), ('F7', [[61.0], [60.0, 58.0]]), ('F-7', [[60.0], [58.0]]), ('Bb7', [[56.0, 60.0], [59.0, 57.0]]), ('Eb7', [[58.0, 54.0], [55.0, 58.0]]), ('Ab7', [[61.0, 56.0], [61.0, 62.0]]), ('D-7', [[58.0, 60.0], [55.0, 58.0]]), ('G7', [[58.0], [-1.0]]), ('C-7', [[-1.0], [-1.0]]), ('F7', [[-1.0], [-1.0]])]\n",
      "\n",
      "---Transpose and augment data---\n",
      "Number of sections after data augmentation: 28884\n",
      "Sample section: [('E6', [[52.0], [52.0]]), ('Db7', [[-1.0], [-1.0]]), ('Gb-7', [[-1.0], [-1.0]]), ('B7', [[-1.0], [-1.0]]), ('E', [[-1.0], [-1.0]]), ('Db-7', [[44.0], [51.0, 54.0]]), ('Gb-7', [[52.0, 49.0], [52.0]]), ('B7', [[55.0], [54.0, 52.0]]), ('B-7', [[54.0], [52.0]]), ('E7', [[50.0, 54.0], [53.0, 51.0]]), ('A7', [[52.0, 48.0], [49.0, 52.0]]), ('D7', [[55.0, 50.0], [55.0, 56.0]]), ('Ab-7', [[52.0, 54.0], [49.0, 52.0]]), ('Db7', [[52.0], [-1.0]]), ('Gb-7', [[-1.0], [-1.0]]), ('B7', [[-1.0], [-1.0]])]\n",
      "\n",
      "---Truncate chords to sevenths---\n",
      "Number of sections: 28884\n",
      "Sample section: [('E6', [[52.0], [52.0]]), ('Db7', [[-1.0], [-1.0]]), ('Gb-7', [[-1.0], [-1.0]]), ('B7', [[-1.0], [-1.0]]), ('E', [[-1.0], [-1.0]]), ('Db-7', [[44.0], [51.0, 54.0]]), ('Gb-7', [[52.0, 49.0], [52.0]]), ('B7', [[55.0], [54.0, 52.0]]), ('B-7', [[54.0], [52.0]]), ('E7', [[50.0, 54.0], [53.0, 51.0]]), ('A7', [[52.0, 48.0], [49.0, 52.0]]), ('D7', [[55.0, 50.0], [55.0, 56.0]]), ('Ab-7', [[52.0, 54.0], [49.0, 52.0]]), ('Db7', [[52.0], [-1.0]]), ('Gb-7', [[-1.0], [-1.0]]), ('B7', [[-1.0], [-1.0]])]\n",
      "\n",
      "---Convert melody to integers---\n",
      "Number of sections: 28884\n",
      "Sample section: [('E6', [[4], [4]]), ('Db7', [[-1], [-1]]), ('Gb-7', [[-1], [-1]]), ('B7', [[-1], [-1]]), ('E', [[-1], [-1]]), ('Db-7', [[8], [3, 6]]), ('Gb-7', [[4, 1], [4]]), ('B7', [[7], [6, 4]]), ('B-7', [[6], [4]]), ('E7', [[2, 6], [5, 3]]), ('A7', [[4, 0], [1, 4]]), ('D7', [[7, 2], [7, 8]]), ('Ab-7', [[4, 6], [1, 4]]), ('Db7', [[4], [-1]]), ('Gb-7', [[-1], [-1]]), ('B7', [[-1], [-1]])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "raw_data = harmoutil.load_pickled_data(\"../data/refined_data.pkl\") # lists of (chord label, melody seqs) by sections\n",
    "print(\"---Raw data---\")\n",
    "print(\"Number of sections: {}\".format(len(raw_data)))\n",
    "print(\"Sample section: {}\\n\".format(raw_data[0]))\n",
    "augmented_data = harmoutil.transpose_and_augment_data(raw_data)\n",
    "print(\"---Transpose and augment data---\")\n",
    "print(\"Number of sections after data augmentation: {}\".format(len(augmented_data)))\n",
    "print(\"Sample section: {}\\n\".format(augmented_data[0]))\n",
    "data = [harmoutil.to_sevenths(section) for section in augmented_data]\n",
    "print(\"---Truncate chords to sevenths---\")\n",
    "print(\"Number of sections: {}\".format(len(data)))\n",
    "print(\"Sample section: {}\\n\".format(data[0]))\n",
    "data = [harmoutil.melody_to_octave_range(section) for section in data]\n",
    "print(\"---Convert melody to integers---\")\n",
    "print(\"Number of sections: {}\".format(len(data)))\n",
    "print(\"Sample section: {}\\n\".format(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Remove sections with augmented major chord---\n",
      "Number of sections: 28836\n",
      "\n",
      "Number of sections: 28836 | Sample section chords: ['E6', 'Db7', 'Gb-7', 'B7', 'E', 'Db-7', 'Gb-7', 'B7', 'B-7', 'E7', 'A7', 'D7', 'Ab-7', 'Db7', 'Gb-7', 'B7']\n",
      "Number of chords: 333480 | Sample chord: E6\n",
      "Number of melodies 333480 | Sample melody: [4, 4]\n",
      "Number of melody notes in the data: 2195328 | Sample melody note: 4\n"
     ]
    }
   ],
   "source": [
    "# Create individual chord and melody element lists \n",
    "def get_notes_by_chord(beats):\n",
    "    return [note for beat in beats for note in beat]\n",
    "\n",
    "def get_chords_by_section(section):\n",
    "    return [chord_info[0] for chord_info in section]\n",
    "\n",
    "def check_if_augmented_major(section):\n",
    "    section_chords = get_chords_by_section(section)\n",
    "    for ch in section_chords:\n",
    "        if \"+j7\" in ch:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "data = [section for section in data if not check_if_augmented_major(section)]\n",
    "print(\"---Remove sections with augmented major chord---\")\n",
    "print(\"Number of sections: {}\\n\".format(len(data)))\n",
    "\n",
    "chords_by_sections = [get_chords_by_section(section) for section in data]\n",
    "chords = [chord_info[0] for section in data for chord_info in section]\n",
    "notes_by_chords = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "notes = [note for chord_notes in notes_by_chords for note in chord_notes]\n",
    "# print(sum([len(section) for section in chords_by_sections]))\n",
    "print(\"Number of sections: {} | Sample section chords: {}\".format(len(chords_by_sections), chords_by_sections[0]))\n",
    "print(\"Number of chords: {} | Sample chord: {}\".format(len(chords), chords[0]))\n",
    "print(\"Number of melodies {} | Sample melody: {}\".format(len(notes_by_chords), notes_by_chords[0]))\n",
    "print(\"Number of melody notes in the data: {} | Sample melody note: {}\".format(len(notes), notes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melody note to integer mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, '<pad>': 13, -1: 12}\n",
      "\n",
      "Integer to melody note mapping:\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: -1, 13: '<pad>'}\n",
      "\n",
      "Chord label to integer mapping:\n",
      " {'Ebj7': 123, 'Dsus': 103, 'Esus': 133, 'Bsus7': 59, 'Asus': 28, 'D-6': 79, 'E+7': 107, 'Go7': 177, 'Bb-6': 43, 'D+7': 77, 'Dsus7': 104, 'C-j7': 66, 'C-': 63, 'Bo': 56, 'Ab-j7': 15, 'Bj7': 54, 'C': 60, 'Gbo7': 171, 'Bbm7b5': 49, 'Eb6': 121, 'G-': 153, 'Bsus': 58, 'A-': 3, 'B+': 31, 'E': 105, 'Ab-': 12, 'F-j7': 141, 'Do7': 102, 'B6': 37, 'B-7': 35, 'Bo7': 57, 'Aj7': 24, 'Ab6': 16, 'E+': 106, 'G+7': 152, 'A-7': 5, 'Dbo': 95, 'Ab-7': 14, 'Dbm7b5': 94, 'B': 30, 'F6': 142, 'Gb': 159, 'G+': 151, 'F+': 136, 'D-': 78, 'Abj7': 18, 'Co7': 72, 'Bb-': 42, 'Absus': 22, 'Esus7': 134, 'Ebo7': 126, 'Ao7': 27, 'Dbsus7': 98, 'A': 0, 'Fj7': 144, 'Co': 71, 'Dbsus': 97, 'Gb-': 162, 'Db7': 92, 'D6': 82, 'B7': 38, 'Db-': 87, 'G-7': 155, 'Dm7b5': 100, 'C+': 61, 'D+': 76, 'Fsus7': 149, 'Gm7b5': 175, 'Gb-j7': 165, 'Gb7': 167, 'B+7': 32, '<bos>': 181, 'Gbsus7': 173, 'Gb-7': 164, 'Ebo': 125, 'Db6': 91, 'Abm7b5': 19, 'Gsus7': 179, 'F-7': 140, 'B-6': 34, 'Eb+': 115, 'Eb-': 117, 'F+7': 137, 'Eb-6': 118, 'Bb': 39, 'Ab-6': 13, 'Eb-7': 119, 'Db-6': 88, 'A7': 8, 'Dj7': 99, 'Cm7b5': 70, 'G7': 158, 'Em7b5': 130, 'Fo7': 147, 'E7': 113, 'A-6': 4, 'Ab': 9, 'Asus7': 29, 'F': 135, 'Db': 84, 'Absus7': 23, 'A6': 7, 'Eb': 114, 'Db+': 85, 'D-j7': 81, 'F-6': 139, 'Bb+': 40, 'E-j7': 111, 'Gbj7': 168, 'G-6': 154, 'E-': 108, 'E-7': 110, 'A-j7': 6, 'G': 150, 'D-7': 80, 'Eo': 131, 'Cj7': 69, 'C+7': 62, 'Ab7': 17, 'Ej7': 129, 'Bbsus': 52, 'A+7': 2, 'Dbj7': 93, 'G-j7': 156, 'Gbo': 170, 'Ebsus': 127, 'C-6': 64, 'Bb6': 46, 'Bb-j7': 45, 'Gsus': 178, 'Fo': 146, 'Bb-7': 44, 'Eo7': 132, 'NC': 180, 'Fsus': 148, 'Gb+7': 161, 'Ebsus7': 128, 'Eb7': 122, 'Eb+7': 116, 'Gbm7b5': 169, 'C6': 67, 'B-': 33, 'Gj7': 174, 'Abo7': 21, 'Db+7': 86, 'E6': 112, 'Gb-6': 163, 'Bm7b5': 55, 'Csus7': 74, 'Gbsus': 172, 'Ab+': 10, 'E-6': 109, 'Eb-j7': 120, 'Db-7': 89, 'Db-j7': 90, 'C-7': 65, 'Bbo7': 51, 'Ab+7': 11, 'Am7b5': 25, 'Dbo7': 96, 'Bb+7': 41, 'Gb6': 166, 'Ebm7b5': 124, 'Go': 176, 'Abo': 20, 'Do': 101, 'D7': 83, 'Bbo': 50, 'F-': 138, 'Csus': 73, 'A+': 1, 'Gb+': 160, 'Bbsus7': 53, 'D': 75, 'Fm7b5': 145, 'B-j7': 36, 'Bb7': 47, 'G6': 157, 'Ao': 26, 'Bbj7': 48, 'C7': 68, 'F7': 143}\n",
      "\n",
      "Integer to chord label mapping:\n",
      " {0: 'A', 1: 'A+', 2: 'A+7', 3: 'A-', 4: 'A-6', 5: 'A-7', 6: 'A-j7', 7: 'A6', 8: 'A7', 9: 'Ab', 10: 'Ab+', 11: 'Ab+7', 12: 'Ab-', 13: 'Ab-6', 14: 'Ab-7', 15: 'Ab-j7', 16: 'Ab6', 17: 'Ab7', 18: 'Abj7', 19: 'Abm7b5', 20: 'Abo', 21: 'Abo7', 22: 'Absus', 23: 'Absus7', 24: 'Aj7', 25: 'Am7b5', 26: 'Ao', 27: 'Ao7', 28: 'Asus', 29: 'Asus7', 30: 'B', 31: 'B+', 32: 'B+7', 33: 'B-', 34: 'B-6', 35: 'B-7', 36: 'B-j7', 37: 'B6', 38: 'B7', 39: 'Bb', 40: 'Bb+', 41: 'Bb+7', 42: 'Bb-', 43: 'Bb-6', 44: 'Bb-7', 45: 'Bb-j7', 46: 'Bb6', 47: 'Bb7', 48: 'Bbj7', 49: 'Bbm7b5', 50: 'Bbo', 51: 'Bbo7', 52: 'Bbsus', 53: 'Bbsus7', 54: 'Bj7', 55: 'Bm7b5', 56: 'Bo', 57: 'Bo7', 58: 'Bsus', 59: 'Bsus7', 60: 'C', 61: 'C+', 62: 'C+7', 63: 'C-', 64: 'C-6', 65: 'C-7', 66: 'C-j7', 67: 'C6', 68: 'C7', 69: 'Cj7', 70: 'Cm7b5', 71: 'Co', 72: 'Co7', 73: 'Csus', 74: 'Csus7', 75: 'D', 76: 'D+', 77: 'D+7', 78: 'D-', 79: 'D-6', 80: 'D-7', 81: 'D-j7', 82: 'D6', 83: 'D7', 84: 'Db', 85: 'Db+', 86: 'Db+7', 87: 'Db-', 88: 'Db-6', 89: 'Db-7', 90: 'Db-j7', 91: 'Db6', 92: 'Db7', 93: 'Dbj7', 94: 'Dbm7b5', 95: 'Dbo', 96: 'Dbo7', 97: 'Dbsus', 98: 'Dbsus7', 99: 'Dj7', 100: 'Dm7b5', 101: 'Do', 102: 'Do7', 103: 'Dsus', 104: 'Dsus7', 105: 'E', 106: 'E+', 107: 'E+7', 108: 'E-', 109: 'E-6', 110: 'E-7', 111: 'E-j7', 112: 'E6', 113: 'E7', 114: 'Eb', 115: 'Eb+', 116: 'Eb+7', 117: 'Eb-', 118: 'Eb-6', 119: 'Eb-7', 120: 'Eb-j7', 121: 'Eb6', 122: 'Eb7', 123: 'Ebj7', 124: 'Ebm7b5', 125: 'Ebo', 126: 'Ebo7', 127: 'Ebsus', 128: 'Ebsus7', 129: 'Ej7', 130: 'Em7b5', 131: 'Eo', 132: 'Eo7', 133: 'Esus', 134: 'Esus7', 135: 'F', 136: 'F+', 137: 'F+7', 138: 'F-', 139: 'F-6', 140: 'F-7', 141: 'F-j7', 142: 'F6', 143: 'F7', 144: 'Fj7', 145: 'Fm7b5', 146: 'Fo', 147: 'Fo7', 148: 'Fsus', 149: 'Fsus7', 150: 'G', 151: 'G+', 152: 'G+7', 153: 'G-', 154: 'G-6', 155: 'G-7', 156: 'G-j7', 157: 'G6', 158: 'G7', 159: 'Gb', 160: 'Gb+', 161: 'Gb+7', 162: 'Gb-', 163: 'Gb-6', 164: 'Gb-7', 165: 'Gb-j7', 166: 'Gb6', 167: 'Gb7', 168: 'Gbj7', 169: 'Gbm7b5', 170: 'Gbo', 171: 'Gbo7', 172: 'Gbsus', 173: 'Gbsus7', 174: 'Gj7', 175: 'Gm7b5', 176: 'Go', 177: 'Go7', 178: 'Gsus', 179: 'Gsus7', 180: 'NC', 181: '<bos>'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create categorical data mappings\n",
    "\n",
    "# Note to integer index\n",
    "note_to_int = dict([(c, i) for i, c in enumerate(sorted(list(set(notes)))[1:])])\n",
    "note_to_int[-1] = len(note_to_int)\n",
    "note_to_int['<pad>'] = len(note_to_int)\n",
    "print(\"Melody note to integer mapping:\\n {}\\n\".format(note_to_int))\n",
    "\n",
    "# Integer to note\n",
    "int_to_note = dict([(k, v) for v, k in note_to_int.items()])\n",
    "print(\"Integer to melody note mapping:\\n {}\\n\".format(int_to_note))\n",
    "\n",
    "# Chord to integer index\n",
    "chord_to_int = dict([(c, i) for i, c in enumerate(sorted(list(set(chords))))])\n",
    "chord_to_int['<bos>'] = len(chord_to_int)\n",
    "print(\"Chord label to integer mapping:\\n {}\\n\".format(chord_to_int))\n",
    "\n",
    "\n",
    "# Integer to chord index\n",
    "int_to_chord = dict([(k, v) for v, k in chord_to_int.items()])\n",
    "print(\"Integer to chord label mapping:\\n {}\\n\".format(int_to_chord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 333480\n",
      "Number of distinct melody notes: 14\n",
      "Number of distinct chord labels: 182\n",
      "Maximum melody sequence length: 135\n",
      "Fixed context chord sequence length: 7\n"
     ]
    }
   ],
   "source": [
    "# Define numerical variables\n",
    "\n",
    "n_samples = len(chords)\n",
    "n_notes = len(note_to_int)\n",
    "n_chords = len(chord_to_int)\n",
    "max_melody_len = max([len(mel_seq) for mel_seq in notes_by_chords])\n",
    "chord_context_len = 7\n",
    "\n",
    "print(\"Total number of samples: {}\".format(n_samples))\n",
    "print(\"Number of distinct melody notes: {}\".format(n_notes))\n",
    "print(\"Number of distinct chord labels: {}\".format(n_chords))\n",
    "print(\"Maximum melody sequence length: {}\".format(max_melody_len))\n",
    "print(\"Fixed context chord sequence length: {}\".format(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input melody sequence: [8, 3, 6, '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "\n",
      "Sample input chord sequence: ['<bos>', '<bos>', 'E6', 'Db7', 'Gb-7', 'B7', 'E']\n",
      "\n",
      "Sample target chord: Db-7\n",
      "\n",
      "Input melody: 333480, Input chords: 333480, Target chords: 333480\n"
     ]
    }
   ],
   "source": [
    "# Prepare tensor data\n",
    "\n",
    "def pad_melody(melody, max_len):\n",
    "    return melody + (max_len-len(melody))*['<pad>']\n",
    "\n",
    "def build_input_chord_sequences(chord_seq, context_len):\n",
    "    padded_sequence = context_len*['<bos>'] + chord_seq\n",
    "    formatted_sequences = [padded_sequence[i:i+context_len+1] for i in range(len(chord_seq))]\n",
    "    return formatted_sequences\n",
    "\n",
    "# Melody\n",
    "input_melody_data = [pad_melody(melody, max_melody_len) for melody in notes_by_chords]\n",
    "print(\"Sample input melody sequence: {}\\n\".format(input_melody_data[5]))\n",
    "\n",
    "\n",
    "# Chords\n",
    "formatted_chords_data = []\n",
    "for section_chords in chords_by_sections:\n",
    "    formatted_chords_data += build_input_chord_sequences(section_chords, chord_context_len)\n",
    "\n",
    "input_chords_data = [ch[:-1] for ch in formatted_chords_data]\n",
    "target_chords_data = [ch[-1] for ch in formatted_chords_data]\n",
    "print(\"Sample input chord sequence: {}\\n\".format(input_chords_data[5]))\n",
    "print(\"Sample target chord: {}\\n\".format(target_chords_data[5]))\n",
    "\n",
    "print(\"Input melody: {}, Input chords: {}, Target chords: {}\".format(len(input_melody_data), len(input_chords_data), len(target_chords_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build tensors\n",
    "\n",
    "X_melody = np.zeros((n_samples, max_melody_len, n_notes), dtype='float32')\n",
    "X_chords = np.zeros((n_samples, chord_context_len, n_chords), dtype='float32')\n",
    "Y = np.zeros((n_samples, n_chords), dtype='float32')\n",
    "\n",
    "for i, (input_mel, input_ch, target_ch) in enumerate(zip(input_melody_data, input_chords_data, target_chords_data)):\n",
    "    Y[i, chord_to_int[target_ch]] = 1\n",
    "    for j, chord in enumerate(input_ch):\n",
    "        X_chords[i, j, chord_to_int[chord]] = 1\n",
    "        \n",
    "    for j, note in enumerate(input_mel):\n",
    "        X_melody[i, j, note_to_int[note]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333480, 135, 14) = (n_samples, max_melody_len, n_notes)\n",
      "(True, 45019800, 45019800.0, 44982130.0, 45019800)\n"
     ]
    }
   ],
   "source": [
    "# Test melody tensor\n",
    "\n",
    "def test_samples_axis(melody_tensor):\n",
    "    count = 0\n",
    "    sample_axis_sums = melody_tensor.sum(axis=2)\n",
    "    for entry in sample_axis_sums.ravel():\n",
    "        count += 1\n",
    "        if not (entry == 1):\n",
    "            return (False, count)\n",
    "    return (True, count, np.sum(sample_axis_sums), np.sum(melody_tensor), np.sum(melody_tensor, dtype=np.int32))\n",
    "\n",
    "# Test n_samples axis i.e. axis 1. If there are any \"holes\" (non-1) entry, it's a problem\n",
    "print(\"{} = (n_samples, max_melody_len, n_notes)\".format(X_melody.shape))\n",
    "print(test_samples_axis(X_melody))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset into 80%-10%-10% train-valid-test\n",
    "\n",
    "seed = 0\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "\n",
    "for train_index, aux_index in sss.split(X_chords, Y):\n",
    "    X_melody_train, X_melody_aux = X_melody[train_index], X_melody[aux_index]\n",
    "    X_chords_train, X_chords_aux = X_chords[train_index], X_chords[aux_index]\n",
    "    Y_train, Y_aux = Y[train_index], Y[aux_index]\n",
    "    \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)\n",
    "\n",
    "for valid_index, test_index in sss.split(X_chords_aux, Y_aux):\n",
    "    X_melody_valid, X_melody_test = X_melody[valid_index], X_melody[test_index]\n",
    "    X_chords_valid, X_chords_test = X_chords[valid_index], X_chords[test_index]\n",
    "    Y_valid, Y_test = Y[valid_index], Y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maxime/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1192: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/maxime/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 7, 182)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_1 (InputLayer)             (None, 135, 14)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "gru_2 (GRU)                      (None, 7, 128)        119424      input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_1 (GRU)                      (None, 128)           54912       input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_3 (GRU)                      (None, 128)           98688       gru_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 256)           0           gru_1[0][0]                      \n",
      "                                                                   gru_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 182)           46774       concatenate_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 319,798\n",
      "Trainable params: 319,798\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 255.00 337.00\" width=\"255pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-333 251,-333 251,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140256241362872 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140256241362872</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 125,-328.5 125,-292.5 0,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-306.8\">input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140256450111696 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140256450111696</title>\n",
       "<polygon fill=\"none\" points=\"20.5,-219.5 20.5,-255.5 104.5,-255.5 104.5,-219.5 20.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-233.8\">gru_2: GRU</text>\n",
       "</g>\n",
       "<!-- 140256241362872&#45;&gt;140256450111696 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140256241362872-&gt;140256450111696</title>\n",
       "<path d=\"M62.5,-292.313C62.5,-284.289 62.5,-274.547 62.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-265.529 62.5,-255.529 59.0001,-265.529 66.0001,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140256091620464 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140256091620464</title>\n",
       "<polygon fill=\"none\" points=\"122,-219.5 122,-255.5 247,-255.5 247,-219.5 122,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-233.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140256450111920 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140256450111920</title>\n",
       "<polygon fill=\"none\" points=\"137.5,-146.5 137.5,-182.5 221.5,-182.5 221.5,-146.5 137.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"179.5\" y=\"-160.8\">gru_1: GRU</text>\n",
       "</g>\n",
       "<!-- 140256091620464&#45;&gt;140256450111920 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140256091620464-&gt;140256450111920</title>\n",
       "<path d=\"M183.29,-219.313C182.725,-211.289 182.039,-201.547 181.406,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"184.893,-192.258 180.699,-182.529 177.91,-192.75 184.893,-192.258\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140256450113096 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140256450113096</title>\n",
       "<polygon fill=\"none\" points=\"25.5,-146.5 25.5,-182.5 109.5,-182.5 109.5,-146.5 25.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67.5\" y=\"-160.8\">gru_3: GRU</text>\n",
       "</g>\n",
       "<!-- 140256450111696&#45;&gt;140256450113096 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140256450111696-&gt;140256450113096</title>\n",
       "<path d=\"M63.7104,-219.313C64.2754,-211.289 64.9614,-201.547 65.5937,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"69.0896,-192.75 66.3008,-182.529 62.1069,-192.258 69.0896,-192.75\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140251064969480 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140251064969480</title>\n",
       "<polygon fill=\"none\" points=\"39.5,-73.5 39.5,-109.5 207.5,-109.5 207.5,-73.5 39.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-87.8\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140256450111920&#45;&gt;140251064969480 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140256450111920-&gt;140251064969480</title>\n",
       "<path d=\"M165.944,-146.313C159.134,-137.679 150.755,-127.055 143.245,-117.534\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"145.872,-115.213 136.931,-109.529 140.376,-119.548 145.872,-115.213\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140256450113096&#45;&gt;140251064969480 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140256450113096-&gt;140251064969480</title>\n",
       "<path d=\"M81.056,-146.313C87.8658,-137.679 96.2453,-127.055 103.755,-117.534\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"106.624,-119.548 110.069,-109.529 101.128,-115.213 106.624,-119.548\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140251062611584 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140251062611584</title>\n",
       "<polygon fill=\"none\" points=\"72.5,-0.5 72.5,-36.5 174.5,-36.5 174.5,-0.5 72.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-14.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140251064969480&#45;&gt;140251062611584 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140251064969480-&gt;140251062611584</title>\n",
       "<path d=\"M123.5,-73.3129C123.5,-65.2895 123.5,-55.5475 123.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"127,-46.5288 123.5,-36.5288 120,-46.5289 127,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define neural net architecture\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "melody_input = Input(shape=(max_melody_len, n_notes))\n",
    "melody_gru = GRU(latent_dim)(melody_input)\n",
    "\n",
    "chords_input = Input(shape=(chord_context_len, n_chords))\n",
    "chords_gru1 = GRU(latent_dim, return_sequences=True)(chords_input)\n",
    "chords_gru2 = GRU(latent_dim)(chords_gru1)\n",
    "\n",
    "concat = concatenate([melody_gru, chords_gru2])\n",
    "\n",
    "chord_dense = Dense(n_chords, activation='softmax')(concat)\n",
    "\n",
    "model = Model([melody_input, chords_input], chord_dense)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Introduce Early-Stopping and Save-Best-Performance callbacks\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "filepath = \"../models/label-Mel1-Cho2-FC1_150ep.h5\"\n",
    "bp = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 266784 samples, validate on 33348 samples\n",
      "Epoch 1/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 2.9717 - acc: 0.3303Epoch 00000: val_acc improved from -inf to 0.42896, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 444s - loss: 2.9717 - acc: 0.3303 - val_loss: 2.4943 - val_acc: 0.4290\n",
      "Epoch 2/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 2.3192 - acc: 0.4513Epoch 00001: val_acc improved from 0.42896 to 0.48642, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 445s - loss: 2.3192 - acc: 0.4513 - val_loss: 2.2218 - val_acc: 0.4864\n",
      "Epoch 3/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 2.0668 - acc: 0.5053Epoch 00002: val_acc improved from 0.48642 to 0.53113, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 2.0667 - acc: 0.5053 - val_loss: 2.0194 - val_acc: 0.5311\n",
      "Epoch 4/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.8160 - acc: 0.5572Epoch 00003: val_acc improved from 0.53113 to 0.56762, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 1.8160 - acc: 0.5572 - val_loss: 1.8392 - val_acc: 0.5676\n",
      "Epoch 5/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.6510 - acc: 0.5948Epoch 00004: val_acc improved from 0.56762 to 0.59455, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 1.6511 - acc: 0.5947 - val_loss: 1.7237 - val_acc: 0.5945\n",
      "Epoch 6/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.5172 - acc: 0.6270Epoch 00005: val_acc improved from 0.59455 to 0.61758, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 1.5172 - acc: 0.6270 - val_loss: 1.6315 - val_acc: 0.6176\n",
      "Epoch 7/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.4024 - acc: 0.6532Epoch 00006: val_acc improved from 0.61758 to 0.63047, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 1.4024 - acc: 0.6532 - val_loss: 1.5580 - val_acc: 0.6305\n",
      "Epoch 8/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.3095 - acc: 0.6739Epoch 00007: val_acc improved from 0.63047 to 0.64577, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 447s - loss: 1.3095 - acc: 0.6739 - val_loss: 1.4907 - val_acc: 0.6458\n",
      "Epoch 9/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.2331 - acc: 0.6921Epoch 00008: val_acc improved from 0.64577 to 0.65269, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 1.2332 - acc: 0.6921 - val_loss: 1.4483 - val_acc: 0.6527\n",
      "Epoch 10/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.1720 - acc: 0.7057Epoch 00009: val_acc improved from 0.65269 to 0.66427, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 447s - loss: 1.1720 - acc: 0.7057 - val_loss: 1.4105 - val_acc: 0.6643\n",
      "Epoch 11/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.1188 - acc: 0.7176Epoch 00010: val_acc improved from 0.66427 to 0.67377, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 1.1189 - acc: 0.7176 - val_loss: 1.3813 - val_acc: 0.6738\n",
      "Epoch 12/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.0747 - acc: 0.7270Epoch 00011: val_acc improved from 0.67377 to 0.67560, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 1.0748 - acc: 0.7270 - val_loss: 1.3595 - val_acc: 0.6756\n",
      "Epoch 13/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.0335 - acc: 0.7357Epoch 00012: val_acc improved from 0.67560 to 0.68469, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 1.0335 - acc: 0.7357 - val_loss: 1.3233 - val_acc: 0.6847\n",
      "Epoch 14/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 1.0048 - acc: 0.7435Epoch 00013: val_acc improved from 0.68469 to 0.68676, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 447s - loss: 1.0048 - acc: 0.7435 - val_loss: 1.3155 - val_acc: 0.6868\n",
      "Epoch 15/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.9722 - acc: 0.7489Epoch 00014: val_acc improved from 0.68676 to 0.69599, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 447s - loss: 0.9722 - acc: 0.7489 - val_loss: 1.2912 - val_acc: 0.6960\n",
      "Epoch 16/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.9440 - acc: 0.7555Epoch 00015: val_acc improved from 0.69599 to 0.70172, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 447s - loss: 0.9441 - acc: 0.7554 - val_loss: 1.2770 - val_acc: 0.7017\n",
      "Epoch 17/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.9204 - acc: 0.7600Epoch 00016: val_acc improved from 0.70172 to 0.70325, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 0.9204 - acc: 0.7600 - val_loss: 1.2688 - val_acc: 0.7033\n",
      "Epoch 18/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8993 - acc: 0.7644Epoch 00017: val_acc improved from 0.70325 to 0.70568, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 0.8994 - acc: 0.7643 - val_loss: 1.2580 - val_acc: 0.7057\n",
      "Epoch 19/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8850 - acc: 0.7674Epoch 00018: val_acc did not improve\n",
      "266784/266784 [==============================] - 446s - loss: 0.8849 - acc: 0.7674 - val_loss: 1.2588 - val_acc: 0.7038\n",
      "Epoch 20/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8614 - acc: 0.7732Epoch 00019: val_acc improved from 0.70568 to 0.70835, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 0.8614 - acc: 0.7732 - val_loss: 1.2516 - val_acc: 0.7083\n",
      "Epoch 21/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8509 - acc: 0.7750Epoch 00020: val_acc improved from 0.70835 to 0.71012, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 447s - loss: 0.8509 - acc: 0.7750 - val_loss: 1.2429 - val_acc: 0.7101\n",
      "Epoch 22/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8336 - acc: 0.7782Epoch 00021: val_acc improved from 0.71012 to 0.71665, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 446s - loss: 0.8336 - acc: 0.7781 - val_loss: 1.2272 - val_acc: 0.7167\n",
      "Epoch 23/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8263 - acc: 0.7799Epoch 00022: val_acc improved from 0.71665 to 0.71689, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 445s - loss: 0.8263 - acc: 0.7799 - val_loss: 1.2234 - val_acc: 0.7169\n",
      "Epoch 24/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8107 - acc: 0.7828Epoch 00023: val_acc improved from 0.71689 to 0.72073, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 445s - loss: 0.8107 - acc: 0.7828 - val_loss: 1.2107 - val_acc: 0.7207\n",
      "Epoch 25/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7960 - acc: 0.7867Epoch 00024: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7960 - acc: 0.7867 - val_loss: 1.2320 - val_acc: 0.7156\n",
      "Epoch 26/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7915 - acc: 0.7873Epoch 00025: val_acc improved from 0.72073 to 0.72352, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 444s - loss: 0.7915 - acc: 0.7873 - val_loss: 1.2126 - val_acc: 0.7235\n",
      "Epoch 27/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7759 - acc: 0.7906Epoch 00026: val_acc improved from 0.72352 to 0.72628, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 444s - loss: 0.7759 - acc: 0.7906 - val_loss: 1.1975 - val_acc: 0.7263\n",
      "Epoch 28/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7693 - acc: 0.7923Epoch 00027: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7693 - acc: 0.7923 - val_loss: 1.2015 - val_acc: 0.7260\n",
      "Epoch 29/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7550 - acc: 0.7946Epoch 00028: val_acc improved from 0.72628 to 0.73036, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 444s - loss: 0.7550 - acc: 0.7946 - val_loss: 1.1918 - val_acc: 0.7304\n",
      "Epoch 30/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7569 - acc: 0.7941Epoch 00029: val_acc did not improve\n",
      "266784/266784 [==============================] - 443s - loss: 0.7569 - acc: 0.7941 - val_loss: 1.1960 - val_acc: 0.7286\n",
      "Epoch 31/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7485 - acc: 0.7961Epoch 00030: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7486 - acc: 0.7961 - val_loss: 1.2084 - val_acc: 0.7251\n",
      "Epoch 32/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7391 - acc: 0.7974Epoch 00031: val_acc improved from 0.73036 to 0.73228, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 445s - loss: 0.7391 - acc: 0.7974 - val_loss: 1.1822 - val_acc: 0.7323\n",
      "Epoch 33/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7308 - acc: 0.7997Epoch 00032: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7308 - acc: 0.7997 - val_loss: 1.1907 - val_acc: 0.7317\n",
      "Epoch 34/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7216 - acc: 0.8019Epoch 00033: val_acc improved from 0.73228 to 0.73447, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 443s - loss: 0.7216 - acc: 0.8019 - val_loss: 1.1853 - val_acc: 0.7345\n",
      "Epoch 35/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7132 - acc: 0.8037Epoch 00034: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7132 - acc: 0.8037 - val_loss: 1.1965 - val_acc: 0.7328\n",
      "Epoch 36/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7144 - acc: 0.8030Epoch 00035: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7144 - acc: 0.8030 - val_loss: 1.1937 - val_acc: 0.7304\n",
      "Epoch 37/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7103 - acc: 0.8038Epoch 00036: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7103 - acc: 0.8038 - val_loss: 1.1943 - val_acc: 0.7339\n",
      "Epoch 38/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7118 - acc: 0.8028Epoch 00037: val_acc did not improve\n",
      "266784/266784 [==============================] - 443s - loss: 0.7119 - acc: 0.8028 - val_loss: 1.1941 - val_acc: 0.7333\n",
      "Epoch 39/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7070 - acc: 0.8039Epoch 00038: val_acc improved from 0.73447 to 0.73537, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 445s - loss: 0.7070 - acc: 0.8039 - val_loss: 1.1901 - val_acc: 0.7354\n",
      "Epoch 40/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6890 - acc: 0.8094Epoch 00039: val_acc improved from 0.73537 to 0.73884, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 444s - loss: 0.6890 - acc: 0.8094 - val_loss: 1.1821 - val_acc: 0.7388\n",
      "Epoch 41/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6936 - acc: 0.8072Epoch 00040: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6936 - acc: 0.8072 - val_loss: 1.2393 - val_acc: 0.7268\n",
      "Epoch 42/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6970 - acc: 0.8059Epoch 00041: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.6970 - acc: 0.8059 - val_loss: 1.1903 - val_acc: 0.7371\n",
      "Epoch 43/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6766 - acc: 0.8114Epoch 00042: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6766 - acc: 0.8114 - val_loss: 1.1893 - val_acc: 0.7373\n",
      "Epoch 44/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6757 - acc: 0.8120Epoch 00043: val_acc improved from 0.73884 to 0.74025, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 444s - loss: 0.6757 - acc: 0.8121 - val_loss: 1.1800 - val_acc: 0.7403\n",
      "Epoch 45/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6719 - acc: 0.8124Epoch 00044: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6720 - acc: 0.8124 - val_loss: 1.1965 - val_acc: 0.7366\n",
      "Epoch 46/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6732 - acc: 0.8122Epoch 00045: val_acc did not improve\n",
      "266784/266784 [==============================] - 443s - loss: 0.6732 - acc: 0.8122 - val_loss: 1.1895 - val_acc: 0.7370\n",
      "Epoch 47/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6669 - acc: 0.8133Epoch 00046: val_acc did not improve\n",
      "266784/266784 [==============================] - 439s - loss: 0.6669 - acc: 0.8133 - val_loss: 1.1850 - val_acc: 0.7395\n",
      "Epoch 48/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6643 - acc: 0.8141Epoch 00047: val_acc did not improve\n",
      "266784/266784 [==============================] - 440s - loss: 0.6643 - acc: 0.8141 - val_loss: 1.1931 - val_acc: 0.7385\n",
      "Epoch 49/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6660 - acc: 0.8138Epoch 00048: val_acc did not improve\n",
      "266784/266784 [==============================] - 441s - loss: 0.6659 - acc: 0.8138 - val_loss: 1.2045 - val_acc: 0.7354\n",
      "Epoch 50/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6547 - acc: 0.8161Epoch 00049: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6547 - acc: 0.8161 - val_loss: 1.1851 - val_acc: 0.7400\n",
      "Epoch 51/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6548 - acc: 0.8165Epoch 00050: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.6548 - acc: 0.8165 - val_loss: 1.2099 - val_acc: 0.7333\n",
      "Epoch 52/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6627 - acc: 0.8134Epoch 00051: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6628 - acc: 0.8134 - val_loss: 1.1882 - val_acc: 0.7387\n",
      "Epoch 53/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6560 - acc: 0.8151Epoch 00052: val_acc improved from 0.74025 to 0.74346, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 444s - loss: 0.6560 - acc: 0.8151 - val_loss: 1.1827 - val_acc: 0.7435\n",
      "Epoch 54/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6438 - acc: 0.8187Epoch 00053: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6438 - acc: 0.8187 - val_loss: 1.1854 - val_acc: 0.7415\n",
      "Epoch 55/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6532 - acc: 0.8157Epoch 00054: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266784/266784 [==============================] - 445s - loss: 0.6532 - acc: 0.8157 - val_loss: 1.2009 - val_acc: 0.7390\n",
      "Epoch 56/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6339 - acc: 0.8212Epoch 00055: val_acc improved from 0.74346 to 0.74427, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 445s - loss: 0.6340 - acc: 0.8212 - val_loss: 1.1852 - val_acc: 0.7443\n",
      "Epoch 57/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6429 - acc: 0.8186Epoch 00056: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6429 - acc: 0.8186 - val_loss: 1.1992 - val_acc: 0.7393\n",
      "Epoch 58/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6399 - acc: 0.8194Epoch 00057: val_acc improved from 0.74427 to 0.74436, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 444s - loss: 0.6400 - acc: 0.8194 - val_loss: 1.1887 - val_acc: 0.7444\n",
      "Epoch 59/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7302 - acc: 0.7968Epoch 00058: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7302 - acc: 0.7968 - val_loss: 1.2384 - val_acc: 0.7261\n",
      "Epoch 60/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7036 - acc: 0.8017Epoch 00059: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7036 - acc: 0.8017 - val_loss: 1.1994 - val_acc: 0.7400\n",
      "Epoch 61/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6712 - acc: 0.8102Epoch 00060: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6712 - acc: 0.8102 - val_loss: 1.1946 - val_acc: 0.7425\n",
      "Epoch 62/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6530 - acc: 0.8151Epoch 00061: val_acc did not improve\n",
      "266784/266784 [==============================] - 443s - loss: 0.6530 - acc: 0.8151 - val_loss: 1.1958 - val_acc: 0.7383\n",
      "Epoch 63/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6381 - acc: 0.8194Epoch 00062: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6381 - acc: 0.8194 - val_loss: 1.1844 - val_acc: 0.7411\n",
      "Epoch 64/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6326 - acc: 0.8205Epoch 00063: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6326 - acc: 0.8205 - val_loss: 1.1939 - val_acc: 0.7413\n",
      "Epoch 65/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6469 - acc: 0.8170Epoch 00064: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6469 - acc: 0.8170 - val_loss: 1.2048 - val_acc: 0.7398\n",
      "Epoch 66/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6417 - acc: 0.8177Epoch 00065: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6417 - acc: 0.8177 - val_loss: 1.1939 - val_acc: 0.7431\n",
      "Epoch 67/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6403 - acc: 0.8180Epoch 00066: val_acc improved from 0.74436 to 0.74472, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 444s - loss: 0.6402 - acc: 0.8180 - val_loss: 1.1975 - val_acc: 0.7447\n",
      "Epoch 68/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6276 - acc: 0.8216Epoch 00067: val_acc improved from 0.74472 to 0.74580, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 444s - loss: 0.6276 - acc: 0.8216 - val_loss: 1.1922 - val_acc: 0.7458\n",
      "Epoch 69/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6281 - acc: 0.8208Epoch 00068: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6281 - acc: 0.8208 - val_loss: 1.1892 - val_acc: 0.7442\n",
      "Epoch 70/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6161 - acc: 0.8245Epoch 00069: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6161 - acc: 0.8245 - val_loss: 1.1857 - val_acc: 0.7444\n",
      "Epoch 71/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6219 - acc: 0.8231Epoch 00070: val_acc improved from 0.74580 to 0.74613, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 441s - loss: 0.6220 - acc: 0.8231 - val_loss: 1.1867 - val_acc: 0.7461\n",
      "Epoch 72/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6193 - acc: 0.8236Epoch 00071: val_acc improved from 0.74613 to 0.74640, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 441s - loss: 0.6193 - acc: 0.8236 - val_loss: 1.1870 - val_acc: 0.7464\n",
      "Epoch 73/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6202 - acc: 0.8228Epoch 00072: val_acc did not improve\n",
      "266784/266784 [==============================] - 441s - loss: 0.6202 - acc: 0.8228 - val_loss: 1.1847 - val_acc: 0.7462\n",
      "Epoch 74/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6069 - acc: 0.8268Epoch 00073: val_acc did not improve\n",
      "266784/266784 [==============================] - 442s - loss: 0.6069 - acc: 0.8268 - val_loss: 1.1914 - val_acc: 0.7448\n",
      "Epoch 75/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6140 - acc: 0.8247Epoch 00074: val_acc did not improve\n",
      "266784/266784 [==============================] - 442s - loss: 0.6140 - acc: 0.8247 - val_loss: 1.1922 - val_acc: 0.7463\n",
      "Epoch 76/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6259 - acc: 0.8213Epoch 00075: val_acc did not improve\n",
      "266784/266784 [==============================] - 442s - loss: 0.6259 - acc: 0.8212 - val_loss: 1.2087 - val_acc: 0.7431\n",
      "Epoch 77/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6076 - acc: 0.8266Epoch 00076: val_acc did not improve\n",
      "266784/266784 [==============================] - 442s - loss: 0.6076 - acc: 0.8266 - val_loss: 1.2005 - val_acc: 0.7438\n",
      "Epoch 78/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7149 - acc: 0.7992Epoch 00077: val_acc did not improve\n",
      "266784/266784 [==============================] - 443s - loss: 0.7148 - acc: 0.7992 - val_loss: 1.2680 - val_acc: 0.7264\n",
      "Epoch 79/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7085 - acc: 0.7999Epoch 00078: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7085 - acc: 0.7999 - val_loss: 1.2387 - val_acc: 0.7332\n",
      "Epoch 80/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6837 - acc: 0.8056Epoch 00079: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.6837 - acc: 0.8057 - val_loss: 1.2141 - val_acc: 0.7385\n",
      "Epoch 81/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6629 - acc: 0.8113Epoch 00080: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6629 - acc: 0.8113 - val_loss: 1.2038 - val_acc: 0.7418\n",
      "Epoch 82/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6457 - acc: 0.8153Epoch 00081: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6457 - acc: 0.8152 - val_loss: 1.1929 - val_acc: 0.7421\n",
      "Epoch 83/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6395 - acc: 0.8172Epoch 00082: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6395 - acc: 0.8172 - val_loss: 1.1906 - val_acc: 0.7425\n",
      "Epoch 84/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6448 - acc: 0.8157Epoch 00083: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6448 - acc: 0.8157 - val_loss: 1.2209 - val_acc: 0.7368\n",
      "Epoch 85/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6339 - acc: 0.8183Epoch 00084: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266784/266784 [==============================] - 444s - loss: 0.6339 - acc: 0.8183 - val_loss: 1.1978 - val_acc: 0.7445\n",
      "Epoch 86/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6278 - acc: 0.8205Epoch 00085: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.6278 - acc: 0.8205 - val_loss: 1.2003 - val_acc: 0.7445\n",
      "Epoch 87/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6227 - acc: 0.8218Epoch 00086: val_acc improved from 0.74640 to 0.74721, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 444s - loss: 0.6226 - acc: 0.8218 - val_loss: 1.1906 - val_acc: 0.7472\n",
      "Epoch 88/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6234 - acc: 0.8214Epoch 00087: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6234 - acc: 0.8214 - val_loss: 1.2071 - val_acc: 0.7418\n",
      "Epoch 89/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6219 - acc: 0.8211Epoch 00088: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6218 - acc: 0.8211 - val_loss: 1.1993 - val_acc: 0.7456\n",
      "Epoch 90/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6152 - acc: 0.8235Epoch 00089: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6152 - acc: 0.8235 - val_loss: 1.2135 - val_acc: 0.7418\n",
      "Epoch 91/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6169 - acc: 0.8233Epoch 00090: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6169 - acc: 0.8233 - val_loss: 1.2021 - val_acc: 0.7466\n",
      "Epoch 92/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6438 - acc: 0.8160Epoch 00091: val_acc did not improve\n",
      "266784/266784 [==============================] - 443s - loss: 0.6438 - acc: 0.8160 - val_loss: 1.2136 - val_acc: 0.7430\n",
      "Epoch 93/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6259 - acc: 0.8206Epoch 00092: val_acc improved from 0.74721 to 0.74772, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 443s - loss: 0.6258 - acc: 0.8206 - val_loss: 1.1914 - val_acc: 0.7477\n",
      "Epoch 94/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6136 - acc: 0.8242Epoch 00093: val_acc improved from 0.74772 to 0.74808, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 443s - loss: 0.6136 - acc: 0.8242 - val_loss: 1.1886 - val_acc: 0.7481\n",
      "Epoch 95/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.8278Epoch 00094: val_acc improved from 0.74808 to 0.74895, saving model to ../models/label-Mel1-Cho2-FC1_150ep.h5\n",
      "266784/266784 [==============================] - 443s - loss: 0.6016 - acc: 0.8278 - val_loss: 1.1899 - val_acc: 0.7490\n",
      "Epoch 96/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6929 - acc: 0.8052Epoch 00095: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.6929 - acc: 0.8052 - val_loss: 1.3045 - val_acc: 0.7217\n",
      "Epoch 97/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7343 - acc: 0.7938Epoch 00096: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7343 - acc: 0.7938 - val_loss: 1.2663 - val_acc: 0.7312\n",
      "Epoch 98/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7151 - acc: 0.7979Epoch 00097: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7151 - acc: 0.7979 - val_loss: 1.2712 - val_acc: 0.7264\n",
      "Epoch 99/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7076 - acc: 0.7998Epoch 00098: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7076 - acc: 0.7998 - val_loss: 1.2498 - val_acc: 0.7318\n",
      "Epoch 100/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7017 - acc: 0.8009Epoch 00099: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7017 - acc: 0.8009 - val_loss: 1.2471 - val_acc: 0.7328\n",
      "Epoch 101/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6981 - acc: 0.8021Epoch 00100: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6981 - acc: 0.8021 - val_loss: 1.2519 - val_acc: 0.7343\n",
      "Epoch 102/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7096 - acc: 0.7997Epoch 00101: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7096 - acc: 0.7997 - val_loss: 1.2539 - val_acc: 0.7300\n",
      "Epoch 103/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7031 - acc: 0.8007Epoch 00102: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7031 - acc: 0.8007 - val_loss: 1.2463 - val_acc: 0.7329\n",
      "Epoch 104/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6946 - acc: 0.8022Epoch 00103: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.6946 - acc: 0.8022 - val_loss: 1.2331 - val_acc: 0.7338\n",
      "Epoch 105/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6881 - acc: 0.8043Epoch 00104: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.6881 - acc: 0.8043 - val_loss: 1.2318 - val_acc: 0.7359\n",
      "Epoch 106/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6851 - acc: 0.8046Epoch 00105: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.6852 - acc: 0.8046 - val_loss: 1.2404 - val_acc: 0.7318\n",
      "Epoch 107/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.8022Epoch 00106: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.6931 - acc: 0.8023 - val_loss: 1.2407 - val_acc: 0.7337\n",
      "Epoch 108/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7406 - acc: 0.7919Epoch 00107: val_acc did not improve\n",
      "266784/266784 [==============================] - 443s - loss: 0.7407 - acc: 0.7919 - val_loss: 1.2783 - val_acc: 0.7253\n",
      "Epoch 109/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7678 - acc: 0.7852Epoch 00108: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7678 - acc: 0.7852 - val_loss: 1.3192 - val_acc: 0.7174\n",
      "Epoch 110/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7875 - acc: 0.7820Epoch 00109: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7875 - acc: 0.7820 - val_loss: 1.2988 - val_acc: 0.7215\n",
      "Epoch 111/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7544 - acc: 0.7882Epoch 00110: val_acc did not improve\n",
      "266784/266784 [==============================] - 443s - loss: 0.7545 - acc: 0.7882 - val_loss: 1.2756 - val_acc: 0.7290\n",
      "Epoch 112/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7353 - acc: 0.7922Epoch 00111: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7354 - acc: 0.7922 - val_loss: 1.2447 - val_acc: 0.7286\n",
      "Epoch 113/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7387 - acc: 0.7921Epoch 00112: val_acc did not improve\n",
      "266784/266784 [==============================] - 446s - loss: 0.7387 - acc: 0.7921 - val_loss: 1.2868 - val_acc: 0.7240\n",
      "Epoch 114/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7639 - acc: 0.7854Epoch 00113: val_acc did not improve\n",
      "266784/266784 [==============================] - 446s - loss: 0.7640 - acc: 0.7854 - val_loss: 1.3039 - val_acc: 0.7192\n",
      "Epoch 115/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7694 - acc: 0.7847Epoch 00114: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7695 - acc: 0.7847 - val_loss: 1.2799 - val_acc: 0.7243\n",
      "Epoch 116/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7731 - acc: 0.7838Epoch 00115: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266784/266784 [==============================] - 444s - loss: 0.7731 - acc: 0.7838 - val_loss: 1.2854 - val_acc: 0.7227\n",
      "Epoch 117/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7630 - acc: 0.7860Epoch 00116: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7630 - acc: 0.7860 - val_loss: 1.3546 - val_acc: 0.7099\n",
      "Epoch 118/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7988 - acc: 0.7784Epoch 00117: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7988 - acc: 0.7784 - val_loss: 1.3023 - val_acc: 0.7197\n",
      "Epoch 119/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7907 - acc: 0.7806Epoch 00118: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7908 - acc: 0.7806 - val_loss: 1.3031 - val_acc: 0.7195\n",
      "Epoch 120/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7795 - acc: 0.7825Epoch 00119: val_acc did not improve\n",
      "266784/266784 [==============================] - 446s - loss: 0.7795 - acc: 0.7825 - val_loss: 1.2989 - val_acc: 0.7182\n",
      "Epoch 121/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7786 - acc: 0.7831Epoch 00120: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7786 - acc: 0.7831 - val_loss: 1.3002 - val_acc: 0.7215\n",
      "Epoch 122/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7815 - acc: 0.7827Epoch 00121: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7815 - acc: 0.7827 - val_loss: 1.3001 - val_acc: 0.7205\n",
      "Epoch 123/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7759 - acc: 0.7831Epoch 00122: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7759 - acc: 0.7831 - val_loss: 1.2861 - val_acc: 0.7232\n",
      "Epoch 124/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7653 - acc: 0.7852Epoch 00123: val_acc did not improve\n",
      "266784/266784 [==============================] - 446s - loss: 0.7653 - acc: 0.7853 - val_loss: 1.2953 - val_acc: 0.7220\n",
      "Epoch 125/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7644 - acc: 0.7851Epoch 00124: val_acc did not improve\n",
      "266784/266784 [==============================] - 447s - loss: 0.7645 - acc: 0.7851 - val_loss: 1.2750 - val_acc: 0.7250\n",
      "Epoch 126/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7577 - acc: 0.7864Epoch 00125: val_acc did not improve\n",
      "266784/266784 [==============================] - 446s - loss: 0.7577 - acc: 0.7864 - val_loss: 1.2738 - val_acc: 0.7260\n",
      "Epoch 127/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7510 - acc: 0.7881Epoch 00126: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7510 - acc: 0.7880 - val_loss: 1.2675 - val_acc: 0.7220\n",
      "Epoch 128/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7672 - acc: 0.7841Epoch 00127: val_acc did not improve\n",
      "266784/266784 [==============================] - 446s - loss: 0.7671 - acc: 0.7842 - val_loss: 1.3037 - val_acc: 0.7179\n",
      "Epoch 129/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7948 - acc: 0.7781Epoch 00128: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7948 - acc: 0.7781 - val_loss: 1.3363 - val_acc: 0.7122\n",
      "Epoch 130/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8153 - acc: 0.7737Epoch 00129: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.8153 - acc: 0.7737 - val_loss: 1.3007 - val_acc: 0.7188\n",
      "Epoch 131/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7969 - acc: 0.7776Epoch 00130: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7970 - acc: 0.7775 - val_loss: 1.3068 - val_acc: 0.7165\n",
      "Epoch 132/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8035 - acc: 0.7766Epoch 00131: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.8035 - acc: 0.7765 - val_loss: 1.3147 - val_acc: 0.7170\n",
      "Epoch 133/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7982 - acc: 0.7777Epoch 00132: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7981 - acc: 0.7777 - val_loss: 1.3591 - val_acc: 0.7105\n",
      "Epoch 134/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8450 - acc: 0.7691Epoch 00133: val_acc did not improve\n",
      "266784/266784 [==============================] - 447s - loss: 0.8450 - acc: 0.7691 - val_loss: 1.3372 - val_acc: 0.7143\n",
      "Epoch 135/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.8133 - acc: 0.7763Epoch 00134: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.8133 - acc: 0.7763 - val_loss: 1.3278 - val_acc: 0.7163\n",
      "Epoch 136/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7991 - acc: 0.7786Epoch 00135: val_acc did not improve\n",
      "266784/266784 [==============================] - 446s - loss: 0.7991 - acc: 0.7786 - val_loss: 1.3119 - val_acc: 0.7187\n",
      "Epoch 137/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7894 - acc: 0.7799Epoch 00136: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7894 - acc: 0.7799 - val_loss: 1.2958 - val_acc: 0.7208\n",
      "Epoch 138/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7824 - acc: 0.7805Epoch 00137: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7823 - acc: 0.7805 - val_loss: 1.2959 - val_acc: 0.7221\n",
      "Epoch 139/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7755 - acc: 0.7816Epoch 00138: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7755 - acc: 0.7816 - val_loss: 1.3019 - val_acc: 0.7186\n",
      "Epoch 140/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7693 - acc: 0.7832Epoch 00139: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7693 - acc: 0.7832 - val_loss: 1.2851 - val_acc: 0.7242\n",
      "Epoch 141/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7634 - acc: 0.7844Epoch 00140: val_acc did not improve\n",
      "266784/266784 [==============================] - 446s - loss: 0.7634 - acc: 0.7844 - val_loss: 1.2914 - val_acc: 0.7215\n",
      "Epoch 142/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7611 - acc: 0.7850Epoch 00141: val_acc did not improve\n",
      "266784/266784 [==============================] - 446s - loss: 0.7611 - acc: 0.7850 - val_loss: 1.2856 - val_acc: 0.7248\n",
      "Epoch 143/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7580 - acc: 0.7856Epoch 00142: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7580 - acc: 0.7856 - val_loss: 1.2916 - val_acc: 0.7213\n",
      "Epoch 144/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7584 - acc: 0.7856Epoch 00143: val_acc did not improve\n",
      "266784/266784 [==============================] - 445s - loss: 0.7584 - acc: 0.7856 - val_loss: 1.2923 - val_acc: 0.7209\n",
      "Epoch 145/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7587 - acc: 0.7853Epoch 00144: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7587 - acc: 0.7854 - val_loss: 1.2884 - val_acc: 0.7234\n",
      "Epoch 146/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7575 - acc: 0.7860Epoch 00145: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7576 - acc: 0.7860 - val_loss: 1.2883 - val_acc: 0.7211\n",
      "Epoch 147/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7626 - acc: 0.7846Epoch 00146: val_acc did not improve\n",
      "266784/266784 [==============================] - 444s - loss: 0.7626 - acc: 0.7846 - val_loss: 1.2919 - val_acc: 0.7228\n",
      "Epoch 148/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7726 - acc: 0.7826Epoch 00147: val_acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266784/266784 [==============================] - 445s - loss: 0.7726 - acc: 0.7826 - val_loss: 1.3015 - val_acc: 0.7187\n",
      "Epoch 149/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7691 - acc: 0.7838Epoch 00148: val_acc did not improve\n",
      "266784/266784 [==============================] - 447s - loss: 0.7691 - acc: 0.7838 - val_loss: 1.2991 - val_acc: 0.7207\n",
      "Epoch 150/150\n",
      "266752/266784 [============================>.] - ETA: 0s - loss: 0.7848 - acc: 0.7799Epoch 00149: val_acc did not improve\n",
      "266784/266784 [==============================] - 446s - loss: 0.7848 - acc: 0.7799 - val_loss: 1.3119 - val_acc: 0.7171\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 256\n",
    "epochs = 150\n",
    "\n",
    "history = model.fit([X_melody_train, X_chords_train], Y_train, epochs=epochs, validation_data=([X_melody_valid, X_chords_valid], Y_valid,), batch_size=batch_size, callbacks=[bp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ebeff9be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFkCAYAAADWs8tQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERERERkX7v/wPcnZ+LdCaWQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ebeff4438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize model learning\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Training history of root model\", fontsize=16)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best performance model\n",
    "model = load_model(\"../models/label-Mel1-Cho2-FC1_150ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord label prediction: 0.7461\n",
      "Kappa score of combined chord label prediction: 0.7398\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of labels\n",
    "\n",
    "# Predict chords from each test sample melody\n",
    "Y_pred = model.predict([X_melody_test, X_chords_test])\n",
    "\n",
    "# Compute accuracy and kappa score\n",
    "print(\"Categorical accuracy of combined chord label prediction: {0:.4f}\".format(harmoutil.compute_accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Kappa score of combined chord label prediction: {0:.4f}\".format(harmoutil.compute_kappa_score(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical accuracy of combined chord pitch prediction: 0.8966\n",
      "TP: 109752 TN: 249026 FP: 21024 FN: 20374\n",
      "Kappa score of combined chord pitch prediction: 0.7646\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions in terms of pitches\n",
    "\n",
    "def label_to_pitch_tensors(predictions):\n",
    "    predicted_chords = [int_to_chord[np.argmax(ch)] for ch in predictions]\n",
    "    pitch_chords = [harmoutil.chord_to_notes(label) for label in predicted_chords]\n",
    "    \n",
    "    Y_pitches = np.zeros((predictions.shape[0], 12), dtype='float32')\n",
    "    for i, chord_pitches in enumerate(pitch_chords):\n",
    "        for j, pitch_presence in enumerate(chord_pitches):\n",
    "            Y_pitches[i, j] = pitch_presence\n",
    "\n",
    "    return Y_pitches\n",
    "    \n",
    "    \n",
    "Y_pred_pitch = label_to_pitch_tensors(Y_pred)\n",
    "Y_test_pitch = label_to_pitch_tensors(Y_test)\n",
    "\n",
    "print(\"Categorical accuracy of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_accuracy_score(Y_test_pitch, Y_pred_pitch)))\n",
    "print(\"Kappa score of combined chord pitch prediction: {0:.4f}\".format(harmoutil.compute_multiclass_binary_kappa_score(Y_test_pitch, Y_pred_pitch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"F-score: {0:.4f}\".format(harmoutil.compute_binary_fscore(Y_test_pitch, Y_pred_pitch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
