{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../src')\n",
    "import harmoutil\n",
    "import midigen\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sections: 28836\n",
      "\n",
      "Number of sections: 28416\n",
      "\n",
      "Number of distinct melody notes: 14\n",
      "Number of distinct chord labels: 194\n",
      "Maximum length of melody sequences for one chord: 115\n",
      "Number of past chords given as input: 7\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "raw_data = harmoutil.load_pickled_data(\"../../data/refined_data.pkl\") # lists of (chord label, melody seqs) by sections\n",
    "augmented_data = harmoutil.transpose_and_augment_data(raw_data)\n",
    "data = [harmoutil.to_sevenths(section) for section in augmented_data]\n",
    "data = [harmoutil.melody_to_octave_range(section) for section in data]\n",
    "\n",
    "\n",
    "# Isolate meaningful data\n",
    "def get_notes_by_chord(beats):\n",
    "    return [note for beat in beats for note in beat]\n",
    "\n",
    "def get_chords_by_section(section):\n",
    "    return [chord_info[0] for chord_info in section]\n",
    "\n",
    "chords_by_sections = [get_chords_by_section(section) for section in data]\n",
    "chords = [chord_info[0] for section in data for chord_info in section]\n",
    "unique_chords = sorted(list(set(chords)))\n",
    "\n",
    "notes_by_chords = [get_notes_by_chord(chord_info[1]) for section in data for chord_info in section]\n",
    "notes = [note for chord_notes in notes_by_chords for note in chord_notes]\n",
    "unique_notes = sorted(list(set(notes)))\n",
    "\n",
    "\n",
    "# Create categorical data mappings\n",
    "note_to_int = dict([(c, i) for i, c in enumerate(unique_notes[1:])])\n",
    "note_to_int[-1] = len(note_to_int)\n",
    "note_to_int['<pad>'] = len(note_to_int)\n",
    "\n",
    "int_to_note = dict([(k, v) for v, k in note_to_int.items()])\n",
    "\n",
    "chord_to_int = dict([(c, i) for i, c in enumerate(unique_chords)])\n",
    "chord_to_int['<bos>'] = len(chord_to_int)\n",
    "\n",
    "int_to_chord = dict([(k, v) for v, k in chord_to_int.items()])\n",
    "\n",
    "\n",
    "\n",
    "# Refine data that will actually be used\n",
    "def check_if_augmented_major(section):\n",
    "    section_chords = get_chords_by_section(section)\n",
    "    for ch in section_chords:\n",
    "        if \"+j7\" in ch:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_if_NC(section):\n",
    "    section_chords = get_chords_by_section(section)\n",
    "    for ch in section_chords:\n",
    "        if \"NC\" in ch:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Remove sections that involve augmented major chords (since not enough data to even allow StratifiedShuffleSplit)\n",
    "section_data = [section for section in data if not check_if_augmented_major(section)]\n",
    "print(\"Number of sections: {}\\n\".format(len(section_data)))\n",
    "\n",
    "section_data = [section for section in section_data if not check_if_NC(section)]\n",
    "print(\"Number of sections: {}\\n\".format(len(section_data)))\n",
    "\n",
    "chords_by_sections = [get_chords_by_section(section) for section in section_data]\n",
    "chords_data = [chord_info[0] for section in section_data for chord_info in section]\n",
    "notes_by_chords = [get_notes_by_chord(chord_info[1]) for section in section_data for chord_info in section]\n",
    "\n",
    "\n",
    "# Define numerical variables\n",
    "n_chords = len(chord_to_int)\n",
    "n_notes = len(note_to_int)\n",
    "max_mel_len = max([len(mel) for mel in notes_by_chords])\n",
    "chord_context_len = 7\n",
    "\n",
    "print(\"Number of distinct melody notes: {}\".format(n_notes))\n",
    "print(\"Number of distinct chord labels: {}\".format(n_chords))\n",
    "print(\"Maximum length of melody sequences for one chord: {}\".format(max_mel_len))\n",
    "print(\"Number of past chords given as input: {}\".format(chord_context_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:304: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model_file = \"../../harmonization_models_training/embeddings_model/final/Embed_depth3.h5\"\n",
    "model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load embedding vectors\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU, concatenate\n",
    "\n",
    "num_dim = 32\n",
    "num_ch = 192\n",
    "num_notes = 12\n",
    "\n",
    "# Define embedding training model and load weights\n",
    "input_layer = Input(shape=(num_ch,)) \n",
    "embeddings_layer = Dense(num_dim, activation='linear', name=\"embeddings\")(input_layer)\n",
    "root_output_layer = Dense(num_notes, activation='softmax')(embeddings_layer)\n",
    "interval_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "pitch_output_layer = Dense(num_notes, activation='sigmoid')(embeddings_layer)\n",
    "melody_output_layer = Dense(num_notes, activation='relu')(embeddings_layer)\n",
    "embeddings_model = Model(input_layer, [root_output_layer, interval_output_layer, pitch_output_layer, melody_output_layer])\n",
    "\n",
    "embeddings_model.load_weights(\"../../chord_embeddings_training/combined_embeddings/combined_weights_dim32.h5\")\n",
    "\n",
    "X_chords_embeddings = embeddings_model.layers[1].get_weights()[0]\n",
    "print(X_chords_embeddings.shape)\n",
    "\n",
    "\n",
    "n_dimensions = X_chords_embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor building functions for single entry\n",
    "def build_mel_tensor(in_mel):\n",
    "    padded_mel = in_mel + ['<pad>']*(max_mel_len - len(in_mel))\n",
    "    X_mel = np.zeros((1, max_mel_len, n_notes), dtype='float32')\n",
    "    for k, note in enumerate(padded_mel):\n",
    "        X_mel[0, k, note_to_int[note]] = 1\n",
    "    return X_mel\n",
    "\n",
    "def build_ch_tensor(in_ch):\n",
    "    X_ch = np.zeros((1, chord_context_len, n_dimensions), dtype='float32')\n",
    "    for j, ch in enumerate(in_ch):\n",
    "        chord_index = chord_to_int[ch]\n",
    "        if (chord_index < num_ch):\n",
    "            X_ch[0, j, :] = X_chords_embeddings[chord_index, :]\n",
    "    return X_ch\n",
    "\n",
    "# Harmony predicting function updating tensors at every prediction\n",
    "def predict_harmony(mel):\n",
    "    harmony = []\n",
    "    past_chords = ['<bos>']*(chord_context_len) # initial chord input\n",
    "    \n",
    "    for mel_notes in mel:\n",
    "        input_mel = build_mel_tensor([harmoutil.root_index(note) for note in mel_notes])\n",
    "        input_ch = build_ch_tensor(past_chords)\n",
    "        next_pred = model.predict([input_mel, input_ch])\n",
    "        next_chord = int_to_chord[np.argmax(next_pred)]\n",
    "        past_chords = past_chords[1:] + [next_chord]\n",
    "        harmony.append(next_chord)\n",
    "    return harmony\n",
    "\n",
    "\n",
    "# save harmony in same format as original harmony\n",
    "def format_output_harmony(original, predicted):    \n",
    "    harmo = []\n",
    "    for bar in original:\n",
    "        b = []\n",
    "        for ch in bar:\n",
    "            b.append(predicted[0])\n",
    "            predicted = predicted[1:]\n",
    "        harmo.append(b)\n",
    "    return harmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Generate harmony for each melody file\n",
    "input_melody_dir = \"../input_data/melody_files/\"\n",
    "truth_harmony_dir = \"../input_data/truth_harmony_files/\"\n",
    "input_signature_dir = \"../input_data/time_signature_files/\"\n",
    "output_harmony_dir = \"embeddings_harmony_files/\"\n",
    "\n",
    "for song_file in os.listdir(input_signature_dir):\n",
    "    if not \".signature\" in song_file:\n",
    "        continue\n",
    "    song_name = midigen.get_song_name(song_file)\n",
    "    input_melody_file = input_melody_dir + song_name + \".melody\"\n",
    "    truth_harmony_file = truth_harmony_dir + song_name + \".chords\"\n",
    "    \n",
    "    # load input melody and original harmony\n",
    "    in_melody = midigen.read_melody_file_by_chord(input_melody_file)\n",
    "    in_harmony = midigen.read_chords_file_by_bar(truth_harmony_file)\n",
    "\n",
    "    # generate harmony\n",
    "    predicted_harmony = predict_harmony(in_melody)        \n",
    "    harmony = format_output_harmony(in_harmony, predicted_harmony)\n",
    "\n",
    "    output_harmony_file = output_harmony_dir + song_name + \".pkl\"\n",
    "    with open(output_harmony_file, 'wb') as f:\n",
    "        pkl.dump(harmony, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
